{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3e9bda",
   "metadata": {},
   "source": [
    "(ch:unsupervisedLearning)=\n",
    "# 비지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be2bbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**감사의 글**\n",
    "\n",
    "자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9d3ac",
   "metadata": {},
   "source": [
    "**소스코드**\n",
    "\n",
    "본문 내용의 일부를 파이썬으로 구현한 내용은 \n",
    "[(구글코랩) 비지도 학습](https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/notebooks/code_unsupervised_learning.ipynb)에서 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3701d3",
   "metadata": {},
   "source": [
    "**슬라이드**\n",
    "\n",
    "본문 내용을 요약한\n",
    "[슬라이드 1부](https://github.com/codingalzi/handson-ml3/raw/master/slides/slides-unsupervised_learning-1.pdf)와\n",
    "[슬라이드 2부](https://github.com/codingalzi/handson-ml3/raw/master/slides/slides-unsupervised_learning-2.pdf)를\n",
    "다운로드할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a898c1",
   "metadata": {},
   "source": [
    "**소개**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e65447",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "비지도 학습은 레이블이 없는 데이터를 학습하는 기법이다.\n",
    "{numref}`%s장 <ch:dimensionalityReduction>`에서 다룬 차원 축소 기법도 비지도 학습의 전형적인 예제이다.\n",
    "여기서는 다음 주제와 관련된 비지도 학습을 다룬다.\n",
    "\n",
    "- 군집화: 비슷한 샘플끼리의 군집 형성\n",
    "    * 고객 분류\n",
    "    * 추천 시스템\n",
    "    * 데이터 분석\n",
    "    * 차원 축소\n",
    "    * 특성 공학\n",
    "    * 준지도 학습\n",
    "    * 검색 엔진\n",
    "    * 이미지 분할\n",
    "\n",
    "- 이상치 탐지: 정상 테이터와 이상치 구분\n",
    "    * 생산라인에서 결함 제품 탐지\n",
    "    * 시계열데이터에서 새로운 트렌드 찾기\n",
    "\n",
    "- 데이터 밀도 추정: 데이터셋의 확률 밀도를 추정\n",
    "    * 이상치 분류: 밀도가 낮은 지역에 위치한 샘플\n",
    "    * 데이터 시각화\n",
    "    * 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026edc7c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 분류 대 군집화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855d48f",
   "metadata": {},
   "source": [
    "**군집**<font size='2'>cluster</font>은 유사한 대상들의 모음을 가리킨다.\n",
    "예를 들어, 산이나 공원에서 볼 수 있는 이름 모르는 동일 품종의 꽃으로 이루어진 군집을 생각할 수 있다.\n",
    "**군집화**<font size='2'>clustering</font>는 특정 기준으로 대상을 여러 개의 군집으로\n",
    "나누는 과정을 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842f106",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "분류와 군집화는 각 샘플에 하나의 그룹을 할당한다는 점에서 유사하다.\n",
    "하지만 분류는 미리 지정된 레이블(타깃)을 최대한 정확하게 예측하는 과정을 의미하는 반면에,\n",
    "군집화는 미리 지정된 레이블(타깃)이 없음에도 불구하고 예측기 스스로 찾아낸 특정 기준을 이용해서\n",
    "여러 개의 군집으로 나누는 과정을 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20709cc7",
   "metadata": {},
   "source": [
    "다음 세 종류의 군집화 알고리즘을 자세히 소개한다.\n",
    "알고리즘에 따라 생성되는 군집의 특성과 모양이 다르다.\n",
    "\n",
    "* k-평균: 센트로이드(중심)라는 특정 샘플을 중심으로 모인 샘플들의 집합\n",
    "* DBSCAN: 밀집된 샘플들의 연속으로 이루어진 집합\n",
    "* 가우스 혼합: 특정 가우스 분포를 따르는 샘플들의 집합\n",
    "\n",
    "이외에 군집의 군집 등 다양한 군집의 모양과 특성이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68cf824",
   "metadata": {},
   "source": [
    "**예제: 붓꽃 데이터셋 군집화**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c196c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "아래 왼쪽 그림은 붓꽃의 꽃잎 길이와 너비를 특성으로 사용해서 품종을 분류한 결과를\n",
    "보여주지만, 오른쪽 그림은 어떤 품종인지는 모르지만\n",
    "노랑 동그라미아 검정 별표로 구분된 두 개의 군집을 보여준다. \n",
    "분류는 세 개의 품종을 매우 잘 분류하지만 군집은 세토사 군집과 나머지 군집으로 구분할 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c780ea",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-01.png\" width=\"80%\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee358d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "반면에 **가우스 혼합 모델**<font size='2'>Gaussian Mixture Model</font>(GMM)을 \n",
    "꽃잎의 길이와 너비 뿐만 아니라\n",
    "꽃받침의 길이와 너비 특성까지 특성으로 사용하는 붓꽃 데이터셋에 대해 적용하면\n",
    "세 개의 군집을 매우 정확하게 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281263a4",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-02.png\" width=\"450\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99013cc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-평균"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f82fa",
   "metadata": {},
   "source": [
    "군집의 중심인 센트로이드<font size='2'>centroid</font> 몇 개를 찾은 다음 \n",
    "각 센트로이드에 가깝게 위치한 샘플들로 구성된 군집을 형성하는 기법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833ce32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**사이킷런의 `KMeans` 모델** \n",
    "\n",
    "아래 그림은 다섯 개의 샘플 덩어리로 이루어진 데이터셋을 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f8665",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-03.png\" width=\"450\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d22779",
   "metadata": {},
   "source": [
    "위 데이터셋에 대해 다섯 개의 군집을 형성하는 k-평균 알고리즘은 다음과 같이 적용한다.\n",
    "군집 수를 몇 개로 지정하는 게 가장 좋은지는 미리 알 수 없다. \n",
    "나중에 몇 개의 군집이 적절한가를 판단하는 여러 방식을 살펴볼 것이다. \n",
    "\n",
    "아래 코드에서 `X`는 위 산점도에 포함된 데이터 샘플들로 구성된 훈련셋을 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86331b25",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7514f3",
   "metadata": {},
   "source": [
    "**예측값**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf153e5",
   "metadata": {},
   "source": [
    "`predict()` 함수의 반환값은 0, 1, 2, 3, 4 등 정수로 구성된다.\n",
    "하지만 이는 임의로 지정된 군집의 인덱스를 가리킬 뿐이며 클래스 분류와는 아무 상관 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219877b",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> y_pred\n",
    "array([4, 0, 1, ..., 2, 1, 0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae175232",
   "metadata": {},
   "source": [
    "**센트로이드 정보**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183001cd",
   "metadata": {},
   "source": [
    "`KMeans` 모델이 찾아낸 센트로이드 정보는 `cluster_centers_` 속성에 저장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603fccf",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> kmeans.cluster_centers_\n",
    "array([[-2.80389616,  1.80117999],\n",
    "       [ 0.20876306,  2.25551336],\n",
    "       [-2.79290307,  2.79641063],\n",
    "       [-1.46679593,  2.28585348],\n",
    "       [-2.80037642,  1.30082566]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac0d243",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**보로노이 다이어그램**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231dde44",
   "metadata": {},
   "source": [
    "**보로노이 다이어그램**<font size='2'>Voronoi diagram</font>은\n",
    "평면을 특정 점(센트로이드)까지의 거리가 가장 가까운 점들의 집합으로 분할한 그림이다. \n",
    "점들이 군집을 잘 구성하는지 여부를 쉽게 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc075627",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-04.png\" width=\"450\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4537f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "왼쪽 상단 군집에 포함된 샘플들 중에서  군집 경계 근처에 있는 샘플들의 군집이 잘못 지정됐다.\n",
    "이유는 그 오른편에 위치한 군집의 직경이 보다 크기에 사실\n",
    "그 군집에 속해야 하는 샘플이 왼쪽 센트로이드와의 거리가 단지 보다 가깝다는 이유로 왼쪽 군집으로 판정되었다.\n",
    "이렇듯 군집의 직경이 서로 많이 다르면 군집화가 잘 작동하지 않을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccef58c",
   "metadata": {},
   "source": [
    "**하드 군집화 대 소프트 군집화**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b9863f",
   "metadata": {},
   "source": [
    "지금까지 살펴 보았듯이 k-평균 모델 객체의 labels_ 속성은 각 샘플에 대해 가장 가까운 센트로이드를 중심으로 하는 군집의 (작위적으로 지정된) 인덱스를 저장하며, 이를 이용하여 predict() 메서드는 샘플이 속하는 군집의 인덱스를 반환한다. 이런 방식의 군집화가 **하드 군집화**(hard clustering)이다.\n",
    "\n",
    "**소프트 군집화**(soft clustering)는 샘플과 각 군집 사이의 관계를 점수로 부여한다. 점수는 예를 들어 각 군집과 샘플사이의 거리 또는 {numref}`%s장 <ch:end2end>`과 {numref}`%s장 <ch:svm>`에서 활용한 가우스 방사 기저 함수를 이용한 유사도 점수 등이 사용될 수 있다. \n",
    "생성된 점수는 데이터셋의 새로운 특성으로 지정되어 모델 훈련에 활용되기도 한다.\n",
    "\n",
    "여기서 사용하는 사이킷런의 `KMeans` 모델의 `transform()` 메서드는 샘플과 각 센트로이드 사이의 (유클리드) 거리를 점수로 사용한다 (아래 코드 참고)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26f284",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> kmeans.transform(X_new).round(2)\n",
    "array([[2.81, 0.33, 2.9 , 1.49, 2.89],\n",
    "       [5.81, 2.8 , 5.85, 4.48, 5.84],\n",
    "       [1.21, 3.29, 0.29, 1.69, 1.71],\n",
    "       [0.73, 3.22, 0.36, 1.55, 1.22]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef62fe3",
   "metadata": {},
   "source": [
    "반면에 {numref}`%s장 <ch:end2end>`에서 `Kmeans` 모델을 상속하는 형식으로 정의된 `ClusterSimilarity` 클래스의\n",
    "`transform()` 메서드는 가우스 방사 기저 함수인 `rbf_kernel()` 함수를 이용하여 각 샘플에 대해 모든 센트로이드들과의 \n",
    "유사도 점수를 계산한다.\n",
    "계산된 점수는 캘리포니아 주택 가격 예측 모델의 훈련에 사용되도록 새로운 특성으로 추가되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba059f3",
   "metadata": {},
   "source": [
    "```python\n",
    "class ClusterSimilarity(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=10, gamma=1.0, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None): # sample_weight: 샘플별로 가중치 적용\n",
    "        self.kmeans_ = KMeans(self.n_clusters, n_init=10, random_state=self.random_state)\n",
    "        self.kmeans_.fit(X, sample_weight=sample_weight)\n",
    "        return self  # 항상 self 반환\n",
    "\n",
    "    # 구역 데이터 샘플과 각 센트로이드 사이의 유사도 측정\n",
    "    def transform(self, X):\n",
    "        return rbf_kernel(X, self.kmeans_.cluster_centers_, gamma=self.gamma)\n",
    "    \n",
    "cluster_simil = ClusterSimilarity(n_clusters=10, gamma=1., random_state=42)\n",
    "\n",
    "# 구역별 중앙 주택 가격을 샘플 가중치로 지정한 후에 군집화 실행. \n",
    "# 즉, 비싼 주택 가격을 갖는 구역을 중요시하며 따라서 센트로이드로 지정될 가능성을 높임.\n",
    "# transform() 메서드는 각 샘플과 10개의 센트로이드 사이의 유사도 계산\n",
    "\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() # 중앙 주택 가격\n",
    "similarities = cluster_simil.fit_transform(housing[[\"latitude\", \"longitude\"]], \n",
    "                                           sample_weight=housing_labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc6b0a2",
   "metadata": {},
   "source": [
    "처음 5 개 샘플과 각 센트로이드에 대한 유사도 점수는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc2efc",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> similarities[:5].round(2)\n",
    "array([[0.  , 0.14, 0.  , 0.  , 0.  , 0.08, 0.  , 0.99, 0.  , 0.6 ],\n",
    "       [0.63, 0.  , 0.99, 0.  , 0.  , 0.  , 0.04, 0.  , 0.11, 0.  ],\n",
    "       [0.  , 0.29, 0.  , 0.  , 0.01, 0.44, 0.  , 0.7 , 0.  , 0.3 ],\n",
    "       [0.65, 0.  , 0.21, 0.  , 0.  , 0.  , 0.51, 0.  , 0.  , 0.  ],\n",
    "       [0.86, 0.  , 0.89, 0.  , 0.  , 0.  , 0.14, 0.  , 0.03, 0.  ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec440ae",
   "metadata": {},
   "source": [
    "아래 그림에서 &#128473;는 각 군집의 중심 구역을 나타내며,\n",
    "색상은 센트로이드 구역과의 유사도를 가리킨다. \n",
    "빨강색의 구역이 센트로이드 구역과의 유사도가 1에 가깝다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c41ce0",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch02/homl02-cluster.jpg\" width=\"550\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9121f9",
   "metadata": {},
   "source": [
    ":::{admonition} 가우스 방사 기저 함수\n",
    ":class: info\n",
    "\n",
    "`rbf_kernel()` 는 **가우스 방사 기저 함수**<font size='2'>Gaussian radial basis function</font>를 \n",
    "가리키며 다음과 같이 정의된다.\n",
    "특정 지점을 가리키는 랜드마크<font size='2'>landmark</font>인 $\\mathbf{m}$으로부터 조금만 멀어져도 \n",
    "함숫값이 급격히 작아진다. \n",
    "\n",
    "$$\n",
    "\\phi(\\mathbf{x},\\mathbf{m}) = \\exp \\left( -\\gamma \\|\\mathbf{x} - \\mathbf{m} \\|^2 \\right)\n",
    "$$\n",
    "\n",
    "하이퍼파라미터인 **감마**($\\gamma$, gamma)는 데이터 샘플이 랜드마크로부터 멀어질 때\n",
    "가우스 RBF 함수의 반환값이 얼마나 빠르게 0에 수렴하도록 하는가를 결정한다.\n",
    "감마 값이 클 수록 랜드마크로부터 조금만 멀어져도 보다 빠르게 0에 수렴한다.\n",
    "따라서 가우스 RBF 함수의 그래프가 보다 좁은 종 모양을 띤다.\n",
    "\n",
    "아래 그래프는 감마가 1일 때와 0.01 때의 차이를 명확하게 보여준다.\n",
    "즉 랜드마크인 $\\mathbf{m}=$ 0으로부터 거리가 멀어질 때 감마가 1이면 매우 급격하게 함숫값이 0으로 줄어든다.\n",
    "즉, 랜드마크로부터 조금만 멀어저도 유사도가 매우 약해진다.\n",
    "\n",
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/rbf_kernel.png\" width=\"400\"></div>\n",
    "<br>\n",
    "\n",
    "예를 들어, 유사도를 도심 상권의 발달 정도로 해석할 때 도시 중심으로 조금만 멀어져도\n",
    "상권이 좋지 않음을 의미한다. 대표적으로 소도시의 상권을 잘 반영한다.\n",
    "반면에 서울의 경우 도시 중심으로부터 조금 떨어져 있다 하더라도 상권이 충분히 잘 발달되어 있을 수 있다.\n",
    "따라서 그런 경우에는 감마를 0.01처럼 작게 지정해야 한다.\n",
    "\n",
    "`ClusterSimilarity` 클래스의 `transform()` 메서드 또한 비슷한 방식으로 유사도를 계산한다.\n",
    "이유는 샘플과 주택 가격이 비싼 센트로이드 구역 사이의 가우스 방사 기저 함숫값을 유사도로 사용하기 때문이다.\n",
    "\n",
    "실제로 `fit()` 함수를 이용하여 군집화 정보를 계산할 때 비싼 가격의 주택이 모여 있는 구역에 \n",
    "보다 높은 가중치를 주기에 그런 구역이 군집의 센트로이드로 선택될 가능성이 높아진다.\n",
    "각각의 센트로이드를 랜드마크로 보았을 때 주택 가격이 높은 센트로이드에 가깝게 위치한 구역일 수록 \n",
    "주택 가격이 상대적으로 비싼 게 일반적이다. 즉, 유사도가 높다고 볼 수 있다.\n",
    "그런데 위 코드에서는 감마(`gamma`)를 1로 지정하였기에 센트로이드에 정말로 가까운 구역에 대해서만 \n",
    "높은 유사도를 부여한다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18f732",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### k-평균 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da068a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "먼저 몇 개의 군집으로 분류할지를 정하기 위해 k 값을 지정한다.\n",
    "그런 다음 k 개의 센트로이드를 무작위로 선택한 다음에 \n",
    "센트로이드들의 위치가 수렴할 때까지 아래 과정을 반복한다.\n",
    "\n",
    "* 각 샘플을 가장 가까운 센트로이드에 할당한다.\n",
    "* 군집별로 샘플의 평균을 계산하여 새로운 해당 군집의 센트로이드로 지정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca8cac8",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-05.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7981dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**무작위 초기화 문제**\n",
    "\n",
    "임의로 선택된 초기 센트로이드에 따라 매우 다른 모양과 성질의 군집이 생성될 수 있다.\n",
    "아래 오른쪽 그림은 센트로이드 초기화가 다르면 최종 결과가 많이 다를 수 있음을 잘 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce760f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-06.png\" width=\"750\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1245c36f",
   "metadata": {},
   "source": [
    "### 센트로이드 초기화 문제 해결 방안"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02b305",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**관성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e0f43",
   "metadata": {},
   "source": [
    "**관성**<font size='2'>intertia</font>은 각 샘플과 가장 가까운 센트로이드와의 거리의 제곱의 합이며,\n",
    "각 군집이 센트로이드에 얼마나 가까이 모여있는가를 측정한다.\n",
    "따라서 관성이 작을 수록 군집이 잘 구성되었다고 평가한다.\n",
    "\n",
    "훈련된 KMeans 모델의 경우 `inertia_` 속성에 관성 값이 저징되며,\n",
    "`score()` 메서드가 관성의 음숫값을 반환한다. \n",
    "이유는 점수(score)는 높을 수록 좋은 모델을 나타내도록 해야 하기 때문이다. \n",
    "KMeans 모델은 훈련 과정 중에 다양한 초기화 과정을 실험하고 그 중에 \n",
    "관성이 가장 작은 값이 되는 센트로이드를 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a1be1b",
   "metadata": {},
   "source": [
    "**센트로이드 초기화 반복 횟수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f7f70",
   "metadata": {},
   "source": [
    "무작위 초기와 문제를 해결하기 위해 k-평균 알고리즘의 초기화를 여러 번 실행한 다음에 가장 낮은 \n",
    "관성을 보이는 모델을 최종 모델로 선택한다.\n",
    "이전 코드에서 `n_init=10`으로 지정되어 있어서 센트로이드 초기화를 10번 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2edec5",
   "metadata": {},
   "source": [
    "**k-평균++ 초기화 알고리즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a96b48",
   "metadata": {},
   "source": [
    "센트로이드 무작위 초기화 문제의 보다 근본적인 해결책이 \n",
    "아서(David Arthur)와 바실비츠키(Sergei Vassilvitskii)의 논문\n",
    "[k-means++: the advantages of careful seeding](https://www.semanticscholar.org/paper/k-means%2B%2B%3A-the-advantages-of-careful-seeding-Arthur-Vassilvitskii/5e0c61b7ee4a2de183a197f32c5013ad109531fa)에서 제시되었다. \n",
    "\n",
    "k-평균++ 초기화 알고리즘은 기존에 선택된\n",
    "센트로이드들과의 거리가 먼 샘플일 수록 다음 센트로이드로 선택될 확률이 높아지도록 한다.\n",
    "보다 구체적으로 다음 과정을 따른다.\n",
    "\n",
    "1. 임의로 하나의 센트로이드 $c_1$ 선택 후 $k$ 개의 센트로이드를 지정할 때까지 아래 과정을 반복한다.\n",
    "1. $c_1, \\dots, c_{i-1}$이 이미 선택되었가고 가정했을 대, \n",
    "    각 샘플  $\\mathbf{x}_j$가 아래의 확률로 새로운 센트로이드 $c_i$로 선택되도록 한다.\n",
    "    \n",
    "    $$\\frac{D(\\mathbf{x}_j)^2}{\\sum\\limits_{j=1}^{m}{D(\\mathbf{x}_j)}^2}$$\n",
    "    \n",
    "    단, $m$은 훈련셋의 크기를, $D(\\mathbf{x}_j)$는 $\\mathbf{x}_j$와 이미 선택된 $c_1, \\dots, c_{i-1}$ 중에서 \n",
    "    가장 가까운 센트로이드 사이의 거리를 가리킨다.\n",
    "        \n",
    "    $$D(\\mathbf{x}_j) = \\min_{p<i} \\| x_j - c_p \\|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feedc6b",
   "metadata": {},
   "source": [
    "확률 계산으로 인해 초기화 비용이 좀 더 많이 들어가긴 하지만 결과적으로 초기화 횟수(`n_init`)를\n",
    "획기적으로 줄일 수 있는 장점이 보다 크다.\n",
    "따라서 사이킷런의 `KMeans` 모델의 기본 초기화 알고리즘으로 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d5893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**미니배치 k-평균**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768bf0e",
   "metadata": {},
   "source": [
    "미니배치를 사용해서 센트로이드를 조금씩 이동하는 k-평균 알고리즘이다. \n",
    "사이킷런의 `MiniBatchMeans` 모델이 지원한다. \n",
    "\n",
    "```python\n",
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=10, batch_size=10,\n",
    "                                   random_state=42)\n",
    "minibatch_kmeans.fit(X_memmap)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d865155",
   "metadata": {},
   "source": [
    "군집수가 많아질 수록 k-평균보다 서너 배 정도 빠르게 훈련되지만, 성능은 조금 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa4e41",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-07.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8382741",
   "metadata": {},
   "source": [
    ":::{admonition} `MiniBatchKMeans`와 `memmap` 클래스\n",
    ":class: info\n",
    "\n",
    "{numref}`%s장 <ch:dimensionalityReduction>`에서 점진적 PCA를 소개하면서 언급한\n",
    "넘파이 `memmap` 클래스를 이용하여 매우 큰 데이터셋을 조금씩 모델에 제공할 수 있다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444481e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 최적의 군집수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be75b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "군집수가 적절하지 않으면 좋지 않은 모델로 수렴할 수 있다.\n",
    "5개의 군집이 적절한 데이터셋에 대해 왼쪽 그림처럼 3개의 센트로이다만 사용하거나,\n",
    "오른쪽 그램처럼 너무 많은 8개의 센트로이드를 사용하면 군집화가 적절하게\n",
    "진행되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d7baa",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-08.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13c5cc",
   "metadata": {},
   "source": [
    "**방법 1: 관성과 군집수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cea8a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "군집수 k가 증가할 수록 관성은 기본적으로 줄어들기에 관성만으로 모델을 평가하기엔 부족하다.\n",
    "하지만 관성이 더 이상 획기적으로 줄어들지 않는 지점을 군집수 후보로 선정할 수는 있다.\n",
    "예를 들어 아래 그래프는 k가 1부터 9까지 변하는 동안 훈련된 모델의 관성을 측정하며,\n",
    "관성이 현격하게 줄어드는 현상이 약화되기 시작하는 k=4가 군집수 후보로 괜찮아 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a8075",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-09.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab846de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "이유는 군집이 네 개보다 작으면 별로이고, 4개보다 많아도 훨씬 좋아진다고 보기 어렵기 때문이다.\n",
    "하지만 4개의 군집으로 구성하려 하면 아래 그림과 같이 왼쪽 하단 두 개의 군집이 하나의 군집으로 처리될 수 있기에\n",
    "가장 좋은 군집화라고 말하기 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65155b",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-10.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69624b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**방법 2: 실루엣 점수와 군집수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff986bf",
   "metadata": {},
   "source": [
    "**실루엣 점수**<font size='2'>silhouette score</font> 샘플별 실루엣 계수의 평균값이다. \n",
    "샘플의 **실루엣 계수**<font size='2'>silhouette coefficient</font>는 \n",
    "다음 식으로 계산된다.\n",
    "\n",
    "$$\\frac{b - a}{\\max(a, b)}$$\n",
    "\n",
    "- $a$: 동일 군집 내의 다른 샘플들과의 거리의 평균값\n",
    "- $b$: 가장 가까운 타 군집에 속하는 샘플들과의 거리의 평균값\n",
    "\n",
    "실루엣 계수는 -1과 1사이의 값이며, 다음 특성을 보여준다.\n",
    "\n",
    "* 1에 가까운 값: 적절한 군집에 포함됨. 이유는 $b$가 $a$보다 월등이 크기에 $\\frac{b - a}{\\max(a, b)}$가 $\\frac{b}{b}$에 가까워짐.\n",
    "* 0에 가까운 값: 군집 경계에 위치. 이유는 $a \\simeq b$ 이기에 $\\frac{b - a}{\\max(a, b)}$가 $0$에 가까워짐.\n",
    "* -1에 가까운 값: 잘못된 군집에 포함됨. 이유는 $a$가 $b$보다 월등이 크기에 $\\frac{b - a}{\\max(a, b)}$가 $\\frac{-a}{a}$에 가까워짐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e5c45",
   "metadata": {},
   "source": [
    "k=4가 여전히 매우 좋아 보인다. \n",
    "하지만 관성의 경우와는 달리 k=5도 역시 꽤 좋다는 것을 알 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee7ace",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-11.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07d3f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**방법 3: 실루엣 다이어그램과 군집수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520fefbd",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**실루엣 다이어그램**은 군집별로 실루엣 계수들을 모아 놓은 그래프다.\n",
    "군집별로 실루엣 계수를 내림차순으로 정렬하면 아래 그림에서처럼 여러 개의 칼날 모양이 군집별로 형성된다.\n",
    "\n",
    "- 칼날 두께: 군집에 포함된 샘플 수\n",
    "- 칼날 길이: 군집에 포함된 각 샘플의 실루엣 계수\n",
    "- 빨강 파선: 실루엣 점수, 즉 실루엣 계수의 평균값이다. \n",
    "\n",
    "좋은 군집 모델은 대부분의 칼날이 빨간 파선보다 길어야 하며,\n",
    "칼날의 두께가 서로 비슷해야 한다. \n",
    "즉, 군집별 크기가 비슷해야 좋은 모델이다.\n",
    "이런 기준으로 볼 때 `k=5` 가 가장 좋은 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d975e1d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-12.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0f39b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### k-평균의 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91864659",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "첫째, 최적의 모델을 구하기 위해 여러 번 학습해야 한다.\n",
    "\n",
    "둘째, 군집수를 미리 지정해야 한다.\n",
    "\n",
    "셋째, 군집의 크기나, 샘플의 밀도가 다르거나, 원형이 아닐 경우 잘 작동하지 않는다.\n",
    "예를 들어, 아래 그림에 사용된 데이터 샘플들의 분포가 원형이 아니기에 \n",
    "양쪽 그림에서 보여지는 군집화 모두 적절하지 않다.\n",
    "그리고 오른쪽 군집의 관성이 왼쪽 보다 작지만 군집화는 오히려 훨씬 나쁘다.\n",
    "데이터 분포가 타원형인 경우 이어서 소개하는 가우스 혼합 모델(GMM)이 매우 잘 작동한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e127a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-13.png\" width=\"800\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f561902",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 군집화 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532f937",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이미지 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10538974",
   "metadata": {},
   "source": [
    "이미지 분할은 보통 다음 세 가지 중에 하나를 가리킨다.\n",
    "\n",
    "- 시맨틱 분할\n",
    "- 인스턴스 분할\n",
    "- 색상 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141c978",
   "metadata": {},
   "source": [
    "**시맨틱 분할**<font size='2'>semantic segmentation</font>은\n",
    "사진에 들어 있는 사물들을 클래스별로 분할한다.\n",
    "예를 들어 아래 왼쪽 사진에서 배경과 구분된 고양이들을 묶어서 cat 클래스로 분류한다.\n",
    "다만 고양의 종류와 개수는 따지지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf5f74",
   "metadata": {},
   "source": [
    "**인스턴스 분할**<font size='2'>instance segmentation</font>은 클래스 뿐만 아니라 객체도 분할한다.\n",
    "예를 들어 아래 오른쪽 사진에서 배경과 구분된 각각의 고양이를 cat1, cat2 등으로 구별한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a2e37",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://drek4537l1klr.cloudfront.net/chollet2/v-7/Figures/instance_segmentation.png\" style=\"width:80%;\"></div>\n",
    "\n",
    "<p><div style=\"text-align: center\">&lt;그림 출처: <a href=\"https://www.manning.com/books/deep-learning-with-python-second-edition\">Deep Learning with Python(2판)</a>&gt;</div></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a36edc",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**색상 분할**<font size='2'>color segmentation</font>은 유사 색상으로 이루어진 군집으로 분할하는 것을 의미한다.\n",
    "아래 그림은 무당벌레가 포함된 이미지를 대상으로 색상 수를 다르게 하면서\n",
    "색상 분할을 시도한 결과를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33f9af",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-14.png\" width=\"80%\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8606363",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 준지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd9025",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "**준지도 학습**<font size='2'>semi-supervised learning</font>은 \n",
    "레이블이 있는 데이터가 적고, 레이블이 없는 데이터가 많을 때 활용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84d72b",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    ":::{prf:example} 미니 MNIST 데이터셋\n",
    "\n",
    "미니 MNist 데이터셋은 1,797 개의 8x8 크기의 손글씨 이미지로 구성된다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67425383",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "예를 들어, 미니 MNIST 데이터셋을 50개의 군집으로 나눈 후 각 군집에서 \n",
    "센트로이드에 가장 가까운 샘플 50개를 대표 이미지로 선정한다.\n",
    "그러면 선정된 50개 샘플만을 이용하여 분류 모델을 훈련해도 84.9%의 정확도가 달성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321ddd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**레이블 전파**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eeb810",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "대표 이미지의 레이블을 해당 군집의 모든 샘플로 전파하는\n",
    "기법을 **레이블 전파**<font size='2'>label propagation</font>라 한다.\n",
    "레이블 전파를 이용하여 예를 들어 미니 MNIST 데이터셋의 50개 군집의 대표 이미지의 레이블을 각 군집의 전체 샘플에 전파한 다음에\n",
    "전체 훈련셋을 대상으로 분류 모델을 훈련하면 89% 이상으로 정확도가 올라간다.\n",
    "\n",
    "또한 센트로이드에 가장 멀리 떨어진 1%의 데이터를 이상치로 취급하여 각 군집에서 제외시킨 \n",
    "다음에 레이블 전파된 훈련셋을 이용하면 분류 모델의 성능이 조금이나마 향상된다.\n",
    "\n",
    "`sklearn.semi_supervised` 패키지는 다양한 레이블 전파 클래스를 제공한다. \n",
    "\n",
    "- `LabelSpreading`\n",
    "- `LabelPropagation`\n",
    "- `SelfTrainingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed02e0",
   "metadata": {},
   "source": [
    "**준지도 학습과 능동 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7295a3c2",
   "metadata": {},
   "source": [
    "모델의 성능을 보다 높이기 위한 다음 단계로 \n",
    "**능동 학습**<font size='2'>Active Learning</font> 기법을 적용할 수 있다.\n",
    "능동 학습은 기존에 훈련된 모델의 약점을 보완하려는 목적으로\n",
    "모델이 예측에 어려움을 겪는 일부 샘플의 라벨을 새롭게 지정해서 모델의 성능을 개선하는 기법이다.\n",
    "또한 이 과정을 모델의 성능이 더 이상 개선되지 않을 때까지 반복한다.\n",
    "\n",
    "다양한 샘플 선택 전략이 알려져 있지만 **불확실성 샘플링**<font size='2'>uncertainty sammpling</font> 전략이\n",
    "가장 많이 사용되며, 아래 과정을 훈련 성능이 더 이상 개선되지 않을 때까지 반복한다.\n",
    "\n",
    "1. 기존에 정리된 훈련셋을 이용하여 모델을 학습시킨다.\n",
    "1. 훈련된 모델이 예측에 대해 가장 불확실해 하는 샘플들을 대상으로 사람이 직접 라벨을 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60261580",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191759d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DBSCAN(density-based spatial clustering of applications with noise) 알고리즘은 \n",
    "데이터 샘플들의 밀도가 높게 연속적으로 이어진 지역을 군집으로 지정한다.\n",
    "알고리즘이 작동하는 방식은 다음과 같다.\n",
    "\n",
    "- 각 샘플에 대해 $\\varepsilon$-**이웃**에 자신을 포함하여 몇 개의 샘플이 있는지 확인한다.\n",
    "    $\\varepsilon$-**이웃**은 샘플을 중심으로 반경이 $\\varepsilon$인 지역을 가리킨다.\n",
    "- 어떤 샘플의 $\\varepsilon$-이웃 안에 `min_samples` 개수 이상의 샘플이 존재한다는 해당 샘플을 \n",
    "    **핵심 샘플**<font size='2'>core instance</font>라 부른다.\n",
    "- 핵심 샘플의 $\\varepsilon$-이웃에 포함된 샘플은 모두 동일한 군집에 속한다.\n",
    "    $\\varepsilon$-이웃에 포함된 다른 샘플 또한 핵심 샘플인 경우 해당 샘플의 $\\varepsilon$-이웃에\n",
    "    포함된 샘플도 모두 동일한 군집에 속한다.\n",
    "    즉, 군집이 핵심 샘플들의 $\\varepsilon$-이웃으로 이뤄진다.\n",
    "- 핵심 샘플이 아니면서 동시에 $\\varepsilon$-이웃에 자신 이외의 다른 샘플이 없다면\n",
    "    그런 샘플은 이상치로 간주된다.\n",
    "    \n",
    "DBSCAN 알고리즘은 모든 군집이 밀도가 낮은 지역으로 구분될 때 잘 작동한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257d04f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 사이킷런의 DBSCAN 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a5c20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "앞서 설명한 $\\varepsilon$-이웃의 반경과 `min_samples` 두 개의 하이퍼파라미터를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71274c52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**예제: 초승달 데이터 군집화**\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.05)\n",
    "dbscan = DBSCAN(eps=0.05, min_samples=5)\n",
    "dbscan.fit(X)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc0cbe",
   "metadata": {},
   "source": [
    "**군집 라벨**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30501741",
   "metadata": {},
   "source": [
    "DBSCAN 모델이 찾은 군집 정보는 0, 1, 2, ... 등 정수 인덱스로 표기되며\n",
    "각 샘들의 군집 정보는 `labels_` 속성에 저장된다.\n",
    "\n",
    "```python\n",
    ">>> dbscan.labels_[:10]\n",
    "array([ 0,  2, -1, -1,  1,  0,  0,  0,  2,  5])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8a36f",
   "metadata": {},
   "source": [
    "핵심 샘플들의 인덱스는 `core_sample_indices_` 속성에 저장된다.\n",
    "\n",
    "```python\n",
    ">>> dbscan.core_sample_indices_[:10]\n",
    "array([ 0,  4,  5,  6,  7,  8, 10, 11, 12, 13])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86158b42",
   "metadata": {},
   "source": [
    "핵심 샘플로 구성된 데이터셋은 `components_` 속성에 저장된다.\n",
    "\n",
    "```python\n",
    ">>> dbscan.components_\n",
    "array([[-0.02137124,  0.40618608],\n",
    "       [-0.84192557,  0.53058695],\n",
    "       [ 0.58930337, -0.32137599],\n",
    "       ...,\n",
    "       [ 1.66258462, -0.3079193 ],\n",
    "       [-0.94355873,  0.3278936 ],\n",
    "       [ 0.79419406,  0.60777171]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4686c5e",
   "metadata": {},
   "source": [
    "**군집화 결과**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0c9b4",
   "metadata": {},
   "source": [
    "아래 그림은 $\\varepsilon$-이웃의 반경을 0.05로 할 때(왼쪽)와 0.2로 할 때(오른쪽)의 차이를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249bb7da",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-16.png\" width=\"800\"/></div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757e790",
   "metadata": {},
   "source": [
    "| 특징| 왼쪽 그림(이웃 반경 0.05) | 오른쪽 그림(이웃 반경 0.2) |\n",
    "| :---: | :---: | :---: |\n",
    "| 군집수 | 2개 초과 | 2개 |\n",
    "| 이상치(빨강 &#128473;) | 많음 | 없음 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ca72c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**DBSCAN과 예측**\n",
    "\n",
    "DBSCAN 모델은 `predict()` 메서드를 지원하지 않는다. 즉, 새로운 샘플에 대한 군집 예측을 지원하지 않는다.\n",
    "반면에 `fit_predict()` 메서드는 지원하여 훈련셋에 대한 군집 인덱스는 예측한다.\n",
    "`predict()` 메서드를 지원하지 않는 이유는\n",
    "더 좋은 성능의 분류기를 대신 이용할 수 있기 때문이다.\n",
    "예를 들어 아래 코드는 `KNeighborsClassifier` 분류 모델을 핵심 샘플들을 이용하여\n",
    "지도학습을 진행한다.\n",
    "\n",
    "아래 코드에서 `dbscan`은 `eps=0.2`로 훈련된 모델을 가리킨다.\n",
    "즉, 위 오른쪽 그림에서 사용된 DBSCAN 모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d68d52",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feeddd2",
   "metadata": {},
   "source": [
    "주의사항: 위 코드는 핵심 샘플만 이용해서 훈련하지만 당연히 모든 샘플을 이용할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b499c",
   "metadata": {},
   "source": [
    "`knn`은 분류 모델이기에 당연히 새로운 데이터 샘플에 대해 클래스를 예측하거나\n",
    "클래스별 확률을 예측할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6bd09",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])\n",
    ">>> knn.predict(X_new)\n",
    "array([1, 0, 1, 0])\n",
    ">>> knn.predict_proba(X_new)\n",
    "array([[0.18, 0.82],\n",
    "       [1. , 0. ],\n",
    "       [0.12, 0.88],\n",
    "       [1. , 0. ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bbc92",
   "metadata": {},
   "source": [
    "**결정 경계**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67188b60",
   "metadata": {},
   "source": [
    "아래 그림은 `knn` 모델을 이용하여 두 개의 그룹을 분류하는 결정 경계를 보여준다.\n",
    "파랑 덧셈 기호 &#43;는 이전 코드에서 지정한 새 데이터 샘플 4 개를 가리킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e66499",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-17a.png\" width=\"450\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a8d42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "그런데 빨강 동그라미로 감싸진 두 샘플은 사실 이상치로 취급되어야 한다.\n",
    "이유는 다른 데이터들로부터 너무 멀리 떨어져 있기 때문이다.\n",
    "\n",
    "그런데 앞서 이웃 반경 하이퍼파라미터를 `eps=0.2`로 훈련된 DBSCAN 모델은\n",
    "이상치를 전혀 지정하지 않는다.\n",
    "이런 경우 `knn` 모델의 `kneighbors()` 메서드를 이용하여 예측값을 수정할 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645754e",
   "metadata": {},
   "source": [
    "```python\n",
    "# 가장 가까운 훈련셋 샘플 하나씩 선택\n",
    ">>> y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1)\n",
    "\n",
    "# 선택된 훈련셋 샘플과 동일한 군집으로 지정\n",
    ">>> y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]\n",
    "\n",
    "# 선택된 훈련세 샘플과의 거리가 0.2보다 큰 경우 이상치로 지정. -1은 이상치를 가리킴.\n",
    ">>> y_pred[y_dist > 0.2] = -1\n",
    ">>> y_pred.ravel()\n",
    "array([-1, 0, 1, -1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b94ad9",
   "metadata": {},
   "source": [
    "- `kneighbors()` 메서드의 반환값: `X_new`에 속한 4개의 데이터 샘플 각각에 대해\n",
    "    가장 가까운 훈련셋 샘플 하나씩 선택한 다음 거리와 훈련셋 샘플의 인덱스를 반환한다.\n",
    "    훈련셋 샘플을 하나씩만 선택하는 이유는 `n_neighbors=1` 키워드 인자가 사용됐기 때문이다.\n",
    "- `X_new`에 속한 4개의 데이터 샘플 각각을 선택된 훈련셋 샘플과 동일한 군집으로 할당한다.\n",
    "    단, 훈련셋 샘플과의 거리가 0.2 보다 크면 이상치로 처리한다.\n",
    "    군집 인덱스가 -1이면 이상치로 처리된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc66a905",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**DBSCAN의 장단점**\n",
    "\n",
    "장점은 다음과 같다.\n",
    "\n",
    "- 단 2개의 하이퍼파라미터만을 사용하는 단순하지만 매우 강력한 알고리즘이다. \n",
    "- 군집의 모양과 개수에 상관없이 일반적으로 잘 작동한다.\n",
    "- 이상치에 별로 민감하지 않다. 즉, 이상치가 있어도 군집을 잘 생성한다.\n",
    "\n",
    "반면에 단점은 다음과 같다.\n",
    "\n",
    "- 군집들의 밀도가 서로 크게 다르거나 두 군집 사이의 영역의 밀도가 충분히 낮지 않으면\n",
    "    서로 다른 군집을 제대로 분리하지 못할 수도 있다.\n",
    "- 알고리즘의 시간복잡도가 $O(m^2 n)$이기에 대용량 훈련셋을 이용한 훈련은 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d448af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 기타 군집 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061ff746",
   "metadata": {},
   "source": [
    "군집의 밀도가 서로 다른 경우 계층 DBSCAN 군집화를 지원하는 `HDBSCAN` 모델이 보다 잘 작동한다.\n",
    "그런데 `HDBSCAN` 모델은 사이킷런에서 정식으로 지원되지 않기에 추가 설치해서 사용해야 한다.\n",
    "보다 자세한 사항은 [HDBSCAN 군집화 라이브러리 공식 문서](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html)를\n",
    "참고한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d00860",
   "metadata": {},
   "source": [
    "사이킷런 라이브러리가 제공하는 기타 군집 알고리즘은 다음과 같다.\n",
    "각 모델의 사용법은 공식 문서를 참고한다.\n",
    "\n",
    "- [Agglomerative clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)\n",
    "- [BIRCH](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html)\n",
    "- [Mean-shift](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html)\n",
    "- [Affinity propagation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html)\n",
    "- [Spectral clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e88384",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 가우스 혼합 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78c1937",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 데이터셋이 여러 개의 혼합된 가우스 분포를 따르는 샘플들로 구성되었다고 가정.\n",
    "\n",
    "* 가우스 분포 = 정규분포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65201f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**정규분포 소개**\n",
    "\n",
    "* 종 모양의 확률밀도함수를 갖는 확률분포"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f968069",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-18.png\" width=\"400\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cdbae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**군집**\n",
    "\n",
    "* 하나의 가우스 분포에서 생생된 모든 샘플들의 그룹\n",
    "* 일반적으로 타원형 모양."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61285075",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**예제**\n",
    "\n",
    "* 아래 그림에서처럼 일반적으로 모양, 크기, 밀집도, 방향이 다름.\n",
    "* 따라서 각 샘플이 어떤 정규분포를 따르는지를 파악하는 게 핵심."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54009906",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-13.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5942c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**GMM 활용**\n",
    "\n",
    "* 위 데이터셋에 `GaussianMixture` 모델 적용\n",
    "\n",
    "* `n_components`: 군집수 지정\n",
    "\n",
    "* `n_init`: 모델 학습 반복 횟수. \n",
    "    * 파라미터(평균값, 공분산 등)를 무작위로 추정한 후 수렴할 때까지 학습시킴."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c7672",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "---\n",
    "```python\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gm = GaussianMixture(n_components=3, n_init=10, random_state=42)\n",
    "gm.fit(X)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d2dea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 아래 그림은 학습된 모델을 보여줌.\n",
    "    * 군집 평균, 결정 경계, 밀도 등고선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e89fad",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-19.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7bc27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**GMM 모델 규제**\n",
    "\n",
    "* 특성수가 크거나, 군집수가 많거나, 샘플이 적은 경우 최적 모델 학습 어려움.\n",
    "* 공분산(covariance)에 규제를 가해서 학습을 도와줄 수 있음.\n",
    "    * `covariance_type` 설정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af694b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**covariance_type 옵션값**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099e0b67",
   "metadata": {},
   "source": [
    "* full\n",
    "    * 아무런 제한 없음.\n",
    "    * 기본값임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c588007",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* spherical\n",
    "    * 군집이 원형이라 가정. \n",
    "    * 지름(분산)은 다를 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6052e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* diag\n",
    "    * 어떤 타원형도 가능.\n",
    "    * 단. 타원의 축이 좌표축과 평행하다고 가정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d046a",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* tied\n",
    "    * 모든 군집의 동일 모양, 동일 크기, 동일 방향을 갖는다고 가정."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb57326",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-20.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a61ade",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 가우스 혼합 모델 활용: 이상치 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0a5bb",
   "metadata": {},
   "source": [
    "* 밀도가 임곗값보다 낮은 지역에 있는 샘플을 이상치로 간주 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b8407",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-21.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8650344",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 가우션 혼합모델 군집수 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec51b5",
   "metadata": {},
   "source": [
    "* k-평균에서 사용했던 관성 또는 실루엣 점수 사용 불가.\n",
    "    * 군집이 타원형일 때 값이 일정하지 않기 때문."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d13105",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* 대신에 __이론적 정보 기준__ 을 최소화 하는 모델 선택 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefafe8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**이론적 정보 기준**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60538099",
   "metadata": {},
   "source": [
    "* BIC: Bayesian information criterion\n",
    "\n",
    "    $$ \\log(m)\\, p - 2 \\log (\\hat L)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49468e9d",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "* AIC: Akaike information criterion\n",
    "\n",
    "    $$ 2\\, p - 2 \\log (\\hat L)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7aee5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $m$: 샘플 수\n",
    "* $p$: 모델이 학습해야 할 파라미터 수\n",
    "* $\\hat L$: 모델의 가능도 함수의 최댓값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c456459",
   "metadata": {},
   "source": [
    "* 학습해야 할 파라미터가 많을 수록 벌칙이 가해짐.\n",
    "* 데이터에 잘 학습하는 모델일 수록 보상을 더해줌."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380da84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**군집수와 정보조건**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef65227",
   "metadata": {},
   "source": [
    "* 아래 그림은 군집수 $k$와 AIC, BIC의 관계를 보여줌.\n",
    "* $k=3$이 최적으로 보임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97935fdf",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-22.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f565eb17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 베이즈 가우스 혼합 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e0664",
   "metadata": {},
   "source": [
    "* 베이즈 확률통계론 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b19d42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**BayesianGaussianMixture 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df1849",
   "metadata": {},
   "source": [
    "* 최적의 군집수를 자동으로 찾아줌.\n",
    "* 단, 최적의 군집수보다 큰 수를 `n_components`에 전달해야 함.\n",
    "    * 즉, 군집에 대한 최소한의 정보를 알고 있다고 가정.\n",
    "* 자동으로 불필요한 군집 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958ecbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "```python\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "bgm = BayesianGaussianMixture(n_components=10, n_init=10, random_state=42)\n",
    "bgm.fit(X)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5308a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* 결과는 군집수 3개를 사용한 이전 결과와 거의 동일.\n",
    "* 군집수 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36618990",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> np.round(bgm.weights_, 2)\n",
    "array([0.4 , 0.21, 0.4 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38287c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**사전 믿음**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e13e5d",
   "metadata": {},
   "source": [
    "* 군집수가 어느 정도일까를 나타내는 지수\n",
    "* `weight_concentration_prior` 하이퍼파라미터\n",
    "    * `n_components`에 설정된 군집수에 대한 규제로 사용됨.\n",
    "    * 작은 값이면 특정 군집의 가중치를 0에 가깝게 만들어 군집수를 줄이도록 함.\n",
    "    * 즉, 큰 값일 수록 `n_components`에 설정된 군집수가 유지되도록 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47c55f",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-24.png\" width=\"600\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16879977",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**가우스 혼합 모델의 장단점**\n",
    "\n",
    "* 타원형 군집에 잘 작동.\n",
    "\n",
    "* 하지만 다른 모양을 가진 데이터셋에서는 성능 좋지 않음.\n",
    "\n",
    "* 예제: 달모양 데이터에 적용하는 경우\n",
    "    * 억지로 타원을 찾으려 시도함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce41c5",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-23.png\" width=\"700\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ddbb4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 이상치 탐지와 특이치 탐지를 위한 다른 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c238fc",
   "metadata": {},
   "source": [
    "* PCA\n",
    "* Fast-MCD\n",
    "* 아이솔레이션 포레스트\n",
    "* LOF\n",
    "* one-class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e4496",
   "metadata": {},
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca5562",
   "metadata": {},
   "source": [
    "1. [2장](https://codingalzi.github.io/handson-ml3/end2end_ml_project.html#id18)에서 정의한 \n",
    "    `ClusterSimilarity`에 사용된 `KMeans` 모델의 `n_cluster` 인자의 최적값을 확인하라."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
