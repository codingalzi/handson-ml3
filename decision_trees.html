

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>6. 결정트리 &#8212; 핸즈온 머신러닝(3판)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=c5ced968eda925caa686" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=c5ced968eda925caa686"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'decision_trees';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="7. 앙상블 학습과 랜덤 포레스트" href="ensemble_learning_random_forests.html" />
    <link rel="prev" title="5. 서포트 벡터 머신" href="svm.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">핸즈온 머신러닝(3판)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ml_landscape.html">1. 한눈에 보는 머신러닝</a></li>
<li class="toctree-l1"><a class="reference internal" href="end2end_ml_project.html">2. 머신러닝 프로젝트 처음부터 끝까지</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">3. 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_models.html">4. 모델 훈련</a></li>
<li class="toctree-l1"><a class="reference internal" href="svm.html">5. 서포트 벡터 머신</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">6. 결정트리</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_learning_random_forests.html">7. 앙상블 학습과 랜덤 포레스트</a></li>
<li class="toctree-l1"><a class="reference internal" href="dimensionality_reduction.html">8. 차원 축소</a></li>
<li class="toctree-l1"><a class="reference internal" href="unsupervised_learning.html">9. 비지도 학습</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/jupyter-book/decision_trees.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/codingalzi/handson-ml3" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/codingalzi/handson-ml3/issues/new?title=Issue%20on%20page%20%2Fdecision_trees.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/decision_trees.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>결정트리</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">6.1. 결정트리 훈련과 활용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">6.1.1. 결정트리 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">6.1.2. 결정트리 시각화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">6.1.3. 클래스 예측</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">6.1.4. 클래스 확률 추정</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cart">6.2. CART 알고리즘</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">6.2.1. CART 알고리즘의 시간복잡도</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">6.2.2. 지니 불순도 vs. 엔트로피</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">6.2.3. 규제 하이퍼파라미터</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">6.3. 회귀 결정트리</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">6.4. 결정트리 단점</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">6.4.1. 훈련셋  회전 민감도</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">6.4.2. 높은 분산</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">6.5. 연습문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ch-decisiontrees">
<span id="id1"></span><h1><span class="section-number">6. </span>결정트리<a class="headerlink" href="#ch-decisiontrees" title="Permalink to this heading">#</a></h1>
<p><strong>감사의 글</strong></p>
<p>자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>본문 내용의 일부를 파이썬으로 구현한 내용은
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/notebooks/code_decision_trees.ipynb">(구글코랩) 결정트리</a>에서
확인할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>결정트리 훈련과 활용</p></li>
<li><p>CART 알고리즘</p></li>
<li><p>지니 불순도 vs. 엔트로피</p></li>
<li><p>결정트리 규제</p></li>
<li><p>회귀 결정트리</p></li>
<li><p>결정트리 단점</p></li>
</ul>
<p><strong>슬라이드</strong></p>
<p>본문 내용을 요약한
<a class="reference external" href="https://github.com/codingalzi/handson-ml3/raw/master/slides/slides-decision_trees.pdf">슬라이드</a>를
다운로드할 수 있다.</p>
<section id="id2">
<h2><span class="section-number">6.1. </span>결정트리 훈련과 활용<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<section id="id3">
<h3><span class="section-number">6.1.1. </span>결정트리 훈련<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>아래 코드는 붓꽃 데이터셋을 대상으로 사이킷런의 <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> 모델을 훈련시킨다.
특성은 꽃잎의 길이와 너비만을 사용하여 세 개의 품종으로 분류하는 다중 클래스 모델을 훈련시킨다.
<code class="docutils literal notranslate"><span class="pre">max_depth</span></code>는 결정트리의 최대 깊이 지정하는 하이퍼파라미터이며 허용되는 최대 가지치기 횟수를 지정하며,
여기서는 2를 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_iris</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">[[</span><span class="s2">&quot;petal length (cm)&quot;</span><span class="p">,</span> <span class="s2">&quot;petal width (cm)&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_iris</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="n">tree_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_iris</span><span class="p">,</span> <span class="n">y_iris</span><span class="p">)</span>
</pre></div>
</div>
<div class="info admonition">
<p class="admonition-title">결정트리 모델과 데이터 전처리</p>
<p>결정트리는 특별한 경우가 아니면 데이터 전처리를 거의 요구하지 않지만, 잠시 뒤에 전처리가 필요한 경우를 살펴볼 것이다.</p>
</div>
</section>
<section id="id4">
<h3><span class="section-number">6.1.2. </span>결정트리 시각화<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>사이킷런의 <code class="docutils literal notranslate"><span class="pre">export_graphviz()</span></code> 함수를 이용하여 학습된 결정트리를 그래프로 시각화한다.
또한 pdf, png 등 많은 종류의 파일로 변환이 가능하다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-01.png" width="400"/></div><p>결정트리의 각 노드에 포함된 속성은 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gini</span></code>: 해당 노드의 지니 불순도 측정값.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">samples</span></code>: 해당 노드에 속하는 샘플 수</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">value</span></code>: 해당 노드에 속하는 샘플들의 실제 클래스별 개수. 타깃 정보 활용.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">class</span></code>: 각 클래스별 비율을 계산하여 가장 높은 비율에 해당하는 클래스 선정.
동일한 비율이면 낮은 인덱스 선정</p></li>
</ul>
<div class="info admonition">
<p class="admonition-title"><code class="docutils literal notranslate"><span class="pre">graphviz</span></code> 패키지</p>
<p>위 결정트리 그래프를 그리려면 다음 두 패키지를 컴퓨터 설치해야 한다.</p>
<ul>
<li><p>파이썬 graphviz 패키지:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">graphviz</span>
</pre></div>
</div>
</li>
<li><p>우분투 graphviz 패키지:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="o">-</span><span class="n">y</span> <span class="n">install</span> <span class="n">graphviz</span>
</pre></div>
</div>
</li>
</ul>
</div>
<p><strong>지니 불순도</strong></p>
<p>각 노드의 지니 불순도는 다음처럼 계산된다.
아래 수식에서 <span class="math notranslate nohighlight">\(G_i\)</span> 는 <span class="math notranslate nohighlight">\(i\)</span>-번째 노드의 지니 불순도를 가리킨다.</p>
<div class="math notranslate nohighlight">
\[G_i = 1 - \sum_{k=1}^{K} (p_{i,k})^2\]</div>
<p>단, <span class="math notranslate nohighlight">\(p_{i,k}\)</span>는 <span class="math notranslate nohighlight">\(i\)</span> 번째 노드에 있는 훈련 샘플 중 클래스 <span class="math notranslate nohighlight">\(k\)</span>에 속한 샘플의 비율이며,
<span class="math notranslate nohighlight">\(K\)</span>는 클래스의 총 개수이다.
예를 들어, 깊이 2의 왼편 노드 <span class="math notranslate nohighlight">\(G_4\)</span> 의 지니 불순도는 0.168로 계산된다.</p>
<div class="math notranslate nohighlight">
\[G_4 = 1 - (0/54)^2 - (49/54)^2 - (5/54)^2 = 0.168\]</div>
</section>
<section id="id5">
<h3><span class="section-number">6.1.3. </span>클래스 예측<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>트리의 노드<font size='2'>node</font>는 가지 분할이 시작되는 지점이며 세 종류로 나뉜다.</p>
<ul class="simple">
<li><p>노드<font size='2'>node</font>: 가지 분할이 시작되는 지점이며 부모 노드와 자식노드를 가질 수 있다.</p></li>
<li><p>루트<font size='2'>root</font>: 맨 상단에 위치한 노드이며, 따라서 부모 노드를 갖지 않는다.</p></li>
<li><p>리프<font size='2'>leaf</font>: 더 이상의 가지분할이 발생하지 않는 노드이며, 따라서 자식 노드를 갖지 않는다.</p></li>
</ul>
<p><strong>결정트리 예측</strong></p>
<p>결정트리 모델은 <strong>화이트박스</strong><font size='2'>whitebox</font> 모델이다.
즉, 예측값의 계산과정을 명확하게 추적할 수 있다.
반면에 머신러닝, 딥러닝의 대부분의 모델은 예측값의 생성과정을
추적하기 어려운 <strong>블랙박스</strong><font size='2'>blackbox</font> 모델이다.</p>
<p>꽃잎 길이와 너비가 각각 5cm, 1.5cm 인 샘플의 클래스는 아래 과정을 거처
주어진 데이터가 속한 리프 노드의 속성을 확인하여 예측한다.</p>
<ul class="simple">
<li><p>루트에서 시작한다.</p></li>
<li><p>분할 1단계: 꽃잎 길이가 2.45cm 보다 크기에 오른편 자식 노드로 이동한다.</p></li>
<li><p>분할 2단계: 꽃잎 너비가 1.75cm 이하이기에 왼편 자식 노드로 이동한다.
해당 노드가 리프 노드이고 버시컬러의 비율이 가장 높기에 버시컬러 품종으로 예측한다.</p></li>
</ul>
<p><strong>결정경계</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">max_depth=3</span></code>으로 지정해서 학습된 결정트리의 결정경계를 그래프로 그리면 다음과 같다.</p>
<ul class="simple">
<li><p>1차 분할 기준: 꽃잎 길이 2.45cm</p></li>
<li><p>2차 분할 기준: 꽃잎 너비 1.75cm</p></li>
<li><p>3차 분할 기준: 꽃잎 길이 4.85cm와 4.95cm</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-02a.png" width="500"/></div><p>graphviz를 이용한 결과는 다음과 같다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-02c.png" width="630"/></div></section>
<section id="id6">
<h3><span class="section-number">6.1.4. </span>클래스 확률 추정<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>주어진 샘플이 어떤 클래스에 속할 확률은 다음과 같이 계산된다.</p>
<ul class="simple">
<li><p>먼저, 해당 샘플이 포함되는 리프 노드를 확인한다.</p></li>
<li><p>해당 리프 노드에서 각 클래스별 비율을 계산하여 각 클래스에 속할 확률로 사용한다.</p></li>
</ul>
<p>예를 들어, 꽃잎 길이와 너비가 각각 5cm, 1.5cm인 붓꽃은 위 결정트리에서
깊이 2의 왼편 리프 노드에 포함된다.
해당 리프 노드 포함된 샘플들의 클래스별 비율은 다음과 같다.</p>
<div class="math notranslate nohighlight">
\[(0/54, 49/54, 5/54) = (0, 0.907, 0.093) \qquad\qquad (\text{세토사}, \text{버시컬러}, \text{버지니카})\]</div>
<p>따라서 버시컬러에 속할 확률이 90.7%로 가장 높다.
참고로 동일한 노드에 속한 샘플에 대한 추정 확률은 언제나 동일하다.</p>
<p>사이킷런의 결정트리 모델은 <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> 메서드가 지정된 샘플의 클래스별 추정 확률을 계산한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tree_clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go">array([[0.   , 0.907, 0.093]])</span>
</pre></div>
</div>
<p>반면에 <code class="docutils literal notranslate"><span class="pre">predict()</span></code> 메서드는 품종 클래스를 예측하며, 가장 높은 추정 확률을 갖는 품종으로 지정한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tree_clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go">array([1])</span>
</pre></div>
</div>
</section>
</section>
<section id="cart">
<h2><span class="section-number">6.2. </span>CART 알고리즘<a class="headerlink" href="#cart" title="Permalink to this heading">#</a></h2>
<p><strong>CART<font size='2'>Classification and Regression Tree</font> 분류 알고리즘</strong></p>
<p>각 노드에서 아래 비용함수를 최소화 하는 특성 <span class="math notranslate nohighlight">\(k\)</span>와 해당 특성의 임곗값 <span class="math notranslate nohighlight">\(t_k\)</span>를 결정해서 분할하는 과정을
반복한다.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m\)</span>, <span class="math notranslate nohighlight">\(m_\text{left}\)</span>, <span class="math notranslate nohighlight">\(m_\text{right}\)</span>: 각각 부모와 왼쪽, 오른쪽 자식 노드에 속한 샘플 개수</p></li>
<li><p><span class="math notranslate nohighlight">\(G_\text{left}\)</span>, <span class="math notranslate nohighlight">\(G_\text{right}\)</span>: 각각 왼쪽, 오른쪽 자식 노드의 지니 불순도</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(k, t_k) = \frac{m_\text{left}}{m}\, G_\text{left} + \frac{m_\text{right}}{m}\, G_\text{right}
\]</div>
<p>특성 <span class="math notranslate nohighlight">\(k\)</span>는 지정된 횟수 만큼 무작위로 선택되지만 선택된 특성의 임곗값 <span class="math notranslate nohighlight">\(t_k\)</span>는 모든 가능성,
즉 모든 훈련 샘플의 특성값을 대상으로 한다.</p>
<p>즉, 지니 불순도가 낮은 두 개의 부분집합으로 분할되도록 학습된다.
분할은 <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> 등 규제에 의해 조절되거나 더 이상 불순도를 줄이는 분할이 불가능할 때까지 진행된다.</p>
<div class="info admonition">
<p class="admonition-title">탐욕 알고리즘</p>
<p><span class="math notranslate nohighlight">\(J(k, t_k)\)</span>를 가장 작게 하는 <span class="math notranslate nohighlight">\(k\)</span>와 <span class="math notranslate nohighlight">\(t_k\)</span>를 찾는 알고리즘은 탐욕 알고리즘이다.
이유는 대상으로 삼은 노드를 기준으로 지니 불순도가 가장 낮은,
즉 가장 순수한(pure) 두 개의 부분집합으로 분할하지만
이후의 분할에 대해서는 생각하지 않기 때문이다.
하지만 탐욕적 기법은 일반적으로 적절한 성능의 해를 찾아준다.</p>
</div>
<section id="id7">
<h3><span class="section-number">6.2.1. </span>CART 알고리즘의 시간복잡도<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p>최적의 결정트리를 찾는 문제는 <span class="math notranslate nohighlight">\(O(\exp(m))\)</span> 복잡도를 갖는
동시에 NP-완전<font size='2'>NP-complete</font>이다.
따라서 매우 작은 훈련 세트에 대해서도 제대로 적용하기 어렵다.</p>
<p>하지만 탐욕 기법을 사용하는 CART 알고리즘의 시간 복잡도는 다음과 같다.
<span class="math notranslate nohighlight">\(n, m\)</span>은 각각 특성 개수와 샘플 개수를 나타낸다.</p>
<ul class="simple">
<li><p>각 노드에서 분류하는 데 걸리는 시간: <span class="math notranslate nohighlight">\(O(n\cdot m\cdot \log_2(m))\)</span></p></li>
<li><p>결정트리를 완성하는 데 걸리는 시간: <span class="math notranslate nohighlight">\(O(n\cdot m^2\cdot \log_2(m))\)</span></p></li>
</ul>
<p>참고: <span class="math notranslate nohighlight">\(m\cdot log_2(m)\)</span> 은 정렬 후에 각 특성값을 임곗값으로 확인하는 데에 걸리는 시간과 연관된다.</p>
<p>또한 학습된 결정트리가 예측에 필요한 시간은 <span class="math notranslate nohighlight">\(O(\log_2 m)\)</span>으로 매우 빠르다.
이유는 결정트리 모델은 균형 이진탐색트리<font size='2'>balanced binary search tree</font>에
가깝고 따라서 가장 깊은 경로가 <span class="math notranslate nohighlight">\(\log_2(m)\)</span> 정도이기 때문이다.
실제로 각 노드에서 하나의 특성만 분류기준으로 사용되기에 특성 수와 무관하게 이진트리의 경로를 추적할 수 있다.</p>
</section>
<section id="vs">
<h3><span class="section-number">6.2.2. </span>지니 불순도 vs. 엔트로피<a class="headerlink" href="#vs" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>의 <code class="docutils literal notranslate"><span class="pre">criterion</span></code> 하이퍼파라미터의 값을 <code class="docutils literal notranslate"><span class="pre">'entropy'</span></code> 로 지정하면
지니 불순도 대신에 샘플들의 <strong>무질서</strong> 정도를 측정하는 엔트로피<font size='2'>entropy</font>가
노드를 분할하는 기준으로 사용된다.</p>
<p><span class="math notranslate nohighlight">\(i\)</span>-번째 노드의 엔트로피 <span class="math notranslate nohighlight">\(H_i\)</span> 는 다음과 같이 계산된다.</p>
<div class="math notranslate nohighlight">
\[\begin{split}H_i = -\sum_{\substack{k=1\\p_{i,k}\neq 0}}^{K} p_{i,k} \log_2(p_{i,k})\end{split}\]</div>
<p>지니 불순도를 사용할 때와 비교해서 큰 차이가 나지는 않는다.
만약 차이가 난다면 엔트로피 방식이 결정 트리를 보다 좌우 균형이 잡히도록
자식 노드로 분할한다.
하지만 기본적으로 별 차이가 없고 지니 불순도 방식이 보다 빠르게 훈련되기에 기본값으로 지정되었다.</p>
<div class="info admonition">
<p class="admonition-title">엔트로피 방식이 보다 균형 잡힌 이진탐색트리를 만드는 이유</p>
<p>특정 <span class="math notranslate nohighlight">\(k\)</span> 에 대해 <span class="math notranslate nohighlight">\(p_{i,k}\)</span> 가 <span class="math notranslate nohighlight">\(0\)</span> 에 매우 가까우면 <span class="math notranslate nohighlight">\(-\log(p_{i,k})\)</span> 가 매우 커진다.
이는 엔트로피 증가로 이어지기 때문에 결국 비용함수 <span class="math notranslate nohighlight">\(J(k, t_k)\)</span> 가 증가한다.
따라서 <span class="math notranslate nohighlight">\(p_{i, k}\)</span> 가 매우 작게되는 경우는 피하도록 학습하게 되고
결국 보다 균형 잡힌 두 개의 부분집합으로 분할하는 방향으로 유도된다.</p>
</div>
</section>
<section id="id8">
<h3><span class="section-number">6.2.3. </span>규제 하이퍼파라미터<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<p><strong>비파라미터 모델 vs. 파라미터 모델</strong></p>
<p>결정트리 모델은 데이터에 대한 어떤 가정도 하지 않는다.
예를 들어, 노드를 분할할 때 어떤 제한도 가해지지 않으며,
따라서 학습되어야 하는 파라미터의 개수를 미리 알 수 없다.
이유는 노드를 분할 할 때마다 새로운 파라미터가 학습되기 때문이다.
이런 모델을 <strong>비파라미터 모델</strong><font size='2'>nonparametric model</font>이라 부른다.
비파라미터 모델의 자유도가 제한되지 않기에 과대적합될 가능성이 높다.</p>
<p>반면에 선형 모델 등 지금까지 살펴 본 모든 모델은 학습되는 모델에
필요한 파라미터 수가 훈련 시작 전에 규정되며, 이런 이유로 과대적합 가능성이 상대적으로 작아진다.
이런 모델을 <strong>파라미터 모델</strong><font size='2'>parametric model</font>이라 한다.</p>
<p><strong>사이킷런  <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> 규제 하이퍼파라미터</strong></p>
<p>앞서 살펴 본 <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> 이외에 다양한 하이퍼파라미터를 이용해
모델의 과대적합 위험도를 줄이는 규제로 사용한다.
가장 많이 사용되는 규제는 다음과 같다.
<code class="docutils literal notranslate"><span class="pre">min_</span></code> 을 접두사로 갖는 하이퍼파라미터는 값을 키우는 경우,
<code class="docutils literal notranslate"><span class="pre">max_</span></code> 를 접두사로 갖는 하이퍼파라미터는 값을 감소시키는 경우 규제가 강해진다.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>하이퍼파라미터</p></th>
<th class="head text-left"><p>기능</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code></p></td>
<td class="text-left"><p>결정트리의 높이 제한</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code></p></td>
<td class="text-left"><p>노드 분할해 필요한 최소 샘플 개수</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code></p></td>
<td class="text-left"><p>리프에 포함된 최소 샘플 개수</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">min_weight_fraction_leaf</span></code></p></td>
<td class="text-left"><p>샘플 가중치 합의 최솟값</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code></p></td>
<td class="text-left"><p>최대 리프 개수</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><code class="docutils literal notranslate"><span class="pre">max_features</span></code></p></td>
<td class="text-left"><p>분할에 사용되는 특성 개수</p></td>
</tr>
</tbody>
</table>
<div class="note admonition">
<p class="admonition-title">샘플의 가중치</p>
<p>샘플의 가중치가 지정되지 않은 경우 모든 샘플의 가중치가 1이라고 가정한다.
이런 경우 <code class="docutils literal notranslate"><span class="pre">min_weight_fraction_leaf</span></code>는 <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>와 동일한 역할을 수행한다.</p>
</div>
<div class="proof example admonition" id="exp:moons_decision_tree">
<p class="admonition-title"><span class="caption-number">Example 6.1 </span> (초승달 데이터셋(moons 데이터셋)과 결정트리)</p>
<section class="example-content" id="proof-content">
<p>아래 두 그래프는 초승달 데이터셋에 두 개의 결정트리 모델을 적용한 결과를 보여준다.
왼쪽 그래프가 규제 없이 훈련된 결정트리인데 과대적합되었음을 바로 확인할 수 있다.
반면에 오른쪽 그래프는 <code class="docutils literal notranslate"><span class="pre">min_samples_leaf=5</span></code> 를 사용하여 모든 리프가 최소 5개 이상의
데이터를 포함하도록 규제하였다.
결과적으로 일반화 성능이 보다 좋은 결정트리가 생성되었다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-03.png" width="600"/></div>
</section>
</div></section>
</section>
<section id="id9">
<h2><span class="section-number">6.3. </span>회귀 결정트리<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<p>결정트리를 회귀 용도로 사용할 수 있다.
대표적으로 사이킷런의 <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code> 클래스가 예측기 모델 학습에 사용된다.</p>
<p>예를 들어, 잡음이 포함된 2차 함수 형태의 데이터셋을 이용하여 결정트리 회귀 모델을 훈련시켜 보자.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-04a.png" width="300"/></div><p><strong>회귀 결정트리 훈련</strong></p>
<p>아래 코드는 <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code> 회귀 모델을 훈련시킨다.
<code class="docutils literal notranslate"><span class="pre">max_depth</span></code>의 의미는 <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>의 경우와 동일하다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tree_reg</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_quad</span><span class="p">,</span> <span class="n">y_quad</span><span class="p">)</span>
</pre></div>
</div>
<p>훈련된 결정트리는 다음과 같다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-05.png" width="630"/></div><p>결정트리의 각 노드에 포함된 속성은 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">samples</span></code>: 해당 노드에 속하는 훈련 샘플 수</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">value</span></code>: 해당 노드에 속하는 훈련 샘플의 평균 타깃값</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">squared_error</span></code>: 해당 노드에 속하는 훈련 샘플의 평균제곱오차(MSE)</p></li>
</ul>
<p><strong>회귀 결정트리 예측</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">x1=0.2</span></code> 인 경우의 예측값은 아래 과정을 거처
주어진 데이터가 속한 리프 노드의 속성을 확인하여 예측한다.</p>
<ul class="simple">
<li><p>루트에서 시작한다.</p></li>
<li><p>분할 1단계: -0.303 보다 크기에 오른쪽 자식 노드로 이동한다.</p></li>
<li><p>분할 2단계: 0.272 보다 작기에 왼쪽 자식 노드로 이동한다.
해당 노드가 리프 노드이고 <code class="docutils literal notranslate"><span class="pre">value=0.028</span></code> 이기에 0.028을 예측값으로 지정한다.</p></li>
</ul>
<p>아래 왼쪽 그래프는 <code class="docutils literal notranslate"><span class="pre">max_depth=2</span></code>로, 오른쪽 그래프는 <code class="docutils literal notranslate"><span class="pre">max_depth=3</span></code>로 지정해서 훈련된 회귀 결정트리
예측 함수의 그래프이다.</p>
<ul class="simple">
<li><p>검정 실선(Depth=0): 1차 분할 기준</p></li>
<li><p>검정 파선(Depth=1): 2차 분할 기준</p></li>
<li><p>(오른쪽 그래프) 검정 점선(Depth=2): 3차 분할 기준</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-04.png" width="600"/></div><p><strong>회귀용 CART 알고리즘의 비용함수</strong></p>
<p>분류의 경우처럼 탐욕적으로 아래 비용함수를 최소화 하는 특성 <span class="math notranslate nohighlight">\(k\)</span>와 해당 특성의 임곗값 <span class="math notranslate nohighlight">\(t_k\)</span>를
결정해서 분할하는 과정을 반복한다.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{MSE}_\text{node}\)</span>: 해당 노드의 평균제곱오차(MSE).</p></li>
<li><p><span class="math notranslate nohighlight">\(m_\text{node}\)</span>: 해당 노드에 속하는 샘플 수</p></li>
<li><p><span class="math notranslate nohighlight">\(y^{(i)}\)</span>: 샘플 <span class="math notranslate nohighlight">\(i\)</span>에 대한 실제 타깃값</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
J(k, t_k) &amp;= \frac{m_\text{left}}{m}\, \text{MSE}_\text{left} + \frac{m_\text{right}}{m}\, \text{MSE}_\text{right} \\[2ex]
\text{MSE}_\text{node} &amp;= \frac{1}{m_\text{node}} \sum_{i\in \text{node}} (\hat y_{node} - y^{(i)})^2\\[1ex]
\hat y_\text{node} &amp;= \frac{1}{m_\text{node}} \sum_{i\in\text{node}} y^{(i)}
\end{align*}
\end{split}\]</div>
<p><strong>회귀 결정트리 규제</strong></p>
<p>분류의 경우처럼 규제가 없으면 과대적합이 발생한다.
아래 왼쪽 그래프는 규제없이 훈련되어 훈련셋에 과대적합된 결정트리의 예측값을 보여준다.
반면에 오른쪽 그래프는 <code class="docutils literal notranslate"><span class="pre">min_samples_leaf=10</span></code> 규제를 사용한 결과이며,
일반화 성능이 훨씬 결정트리의 예측값을 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-06.png" width="600"/></div></section>
<section id="id10">
<h2><span class="section-number">6.4. </span>결정트리 단점<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h2>
<section id="id11">
<h3><span class="section-number">6.4.1. </span>훈련셋  회전 민감도<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h3>
<p>결정트리 알고리즘은 단순하지만 매우 뛰어난 성능을 갖지만 몇 가지 단점을 갖는다.</p>
<p>먼저 결정트리는 항상 축에 수직인 분할을 사용한다.
따라서 훈련셋에 회전을 조금만 가해도 결정 경계가 많이 달라진다.
예를 들어 아래 오른쪽 그래프는 왼쪽 데이터셋을 45도 회전시킨 훈련셋으로 학습된 결정트리이며
쓸데없이 계단 형식의 굴곡이 있는 결정경계를 갖는다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-07.png" width="600"/></div><p>하지만 예를 들어 (<a class="reference internal" href="dimensionality_reduction.html#ch-dimensionalityreduction"><span class="std std-numref">8장</span></a>에서 배울) 주성분 분석(PCA) 기법 등을
사용하여 훈련 샘플 회전시키는 전처리를 구행한 후에 학습을 시키는 것도 가능하다.</p>
<p>PCA 기법은 간단하게 말해 데이터셋을 회전시켜서 특성들 사이의 연관성을 약화시키며, 이를 통해
결정트리의 학습에 도움을 줄 수 있다는 정도만 여기서는 언급한다.
예를 들어, PCA 기법으로 회전시킨 붓꽃 데이터셋에 분류 결정트리를 훈련시킨 결과는 다음과 같다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">pca_pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">PCA</span><span class="p">())</span>
<span class="n">X_iris_rotated</span> <span class="o">=</span> <span class="n">pca_pipeline</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_iris</span><span class="p">)</span>
<span class="n">tree_clf_pca</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tree_clf_pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_iris_rotated</span><span class="p">,</span> <span class="n">y_iris</span><span class="p">)</span>
</pre></div>
</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-08d.png"/></div></section>
<section id="id12">
<h3><span class="section-number">6.4.2. </span>높은 분산<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h3>
<p>결정트리는 꽤 높은 분산을 갖는다.
즉, 훈련셋이나 하이퍼파라미터가 조금만 달라져도 완전히 다른 결정트리가 훈련될 수 있다.
심지어 동일한 모델을 훈련시켜도 많이 다른 결정트리가 생성되기도 한다.
이는 결정트리가 생성될 때 특성을 무작위로 선택하기 때문이다.
따라서 <code class="docutils literal notranslate"><span class="pre">random_state</span></code> 를 지정하지 않으면 아래 그래프와 같은 많이 다른 결정트리가 생성되기도 한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch06/homl06-08e.png"/></div<p><strong>랜덤 포레스트</strong></p>
<p>높은 분산을 갖는 문제는 여러 개의 결정트리를 동시에 훈련시킨 후 평균값을 랜덤 포레스트 모델을
이용하여 해결할 수 있다.
이에 대해서는 <a class="reference internal" href="ensemble_learning_random_forests.html#ch-ensemble"><span class="std std-numref">7장</span></a>에서 자세히 다룬다.</p>
</section>
</section>
<section id="id13">
<h2><span class="section-number">6.5. </span>연습문제<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h2>
<p>참고: <a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/practices/practice_decision_trees.ipynb">(실습) 결정트리</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="svm.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5. </span>서포트 벡터 머신</p>
      </div>
    </a>
    <a class="right-next"
       href="ensemble_learning_random_forests.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>앙상블 학습과 랜덤 포레스트</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">6.1. 결정트리 훈련과 활용</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">6.1.1. 결정트리 훈련</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">6.1.2. 결정트리 시각화</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">6.1.3. 클래스 예측</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">6.1.4. 클래스 확률 추정</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cart">6.2. CART 알고리즘</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">6.2.1. CART 알고리즘의 시간복잡도</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vs">6.2.2. 지니 불순도 vs. 엔트로피</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">6.2.3. 규제 하이퍼파라미터</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">6.3. 회귀 결정트리</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">6.4. 결정트리 단점</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">6.4.1. 훈련셋  회전 민감도</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">6.4.2. 높은 분산</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">6.5. 연습문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 코딩알지
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=c5ced968eda925caa686"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>