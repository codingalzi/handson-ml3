
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>7. 앙상블 학습과 랜덤 포레스트 &#8212; 핸즈온 머신러닝(3판)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="8. 차원 축소" href="dimensionality_reduction.html" />
    <link rel="prev" title="6. 결정트리" href="decision_trees.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">핸즈온 머신러닝(3판)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ml_landscape.html">
   1. 한눈에 보는 머신러닝
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="end2end_ml_project.html">
   2. 머신러닝 프로젝트 처음부터 끝까지
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classification.html">
   3. 분류
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="training_models.html">
   4. 모델 훈련
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="svm.html">
   5. 서포트 벡터 머신
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="decision_trees.html">
   6. 결정트리
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   7. 앙상블 학습과 랜덤 포레스트
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dimensionality_reduction.html">
   8. 차원 축소
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="unsupervised_learning.html">
   9. 비지도 학습
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/ensemble_learning_random_forests.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/codingalzi/handson-ml3"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/codingalzi/handson-ml3/issues/new?title=Issue%20on%20page%20%2Fensemble_learning_random_forests.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/codingalzi/handson-ml3/master?urlpath=tree/jupyter-book/ensemble_learning_random_forests.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   7.1. 투표식 분류기
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     7.1.1. 직접투표
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     7.1.2. 간접투표
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     7.1.3. 투표식 분류기의 확률적 근거
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     7.1.4. 투표식 분류기 예제
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   7.2. 7.2 배깅/페이스팅
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     7.2.1. 정의
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     7.2.2. 배깅
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     7.2.3. 배깅/페이스팅 예측 방식
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     7.2.4. 앙상블 학습의 편향과 분산
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     7.2.5. 예제: 사이킷런의 배깅/페이스팅
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oob">
     7.2.6. oob 평가
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     7.2.7. 앙상블 모델의 검증과 테스트
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   7.3. 7.3 랜덤 패치와 랜덤 서브스페이스
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#max-features">
     7.3.1.
     <code class="docutils literal notranslate">
      <span class="pre">
       max_features
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bootstrap-features">
     7.3.2.
     <code class="docutils literal notranslate">
      <span class="pre">
       bootstrap_features
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     7.3.3. 랜덤 패치 기법
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     7.3.4. 랜덤 서브스페이스 기법
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id17">
   7.4. 7.4 랜덤 포레스트
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     7.4.1. 랜덤 포레스트 하이퍼파라미터
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     7.4.2. 엑스트라 트리
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id20">
       7.4.2.1. 예제
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     7.4.3. 특성 중요도
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id22">
       7.4.3.1. 예제: 붓꽃 데이터셋
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mnist">
       7.4.3.2. 예제: MNIST
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id23">
   7.5. 7.5 부스팅
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaboost">
     7.5.1. 에이다부스트(AdaBoost)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id24">
       7.5.1.1. 샘플 가중치
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id25">
       7.5.1.2. 에이다부스트 알고리즘 작동 과정
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id26">
       7.5.1.3. 사이키런의 에이다부스트
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id27">
       7.5.1.4. 예제: 에이다부스트 + 결정트리
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id28">
     7.5.2. 그레이디언트 부스팅
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id29">
       7.5.2.1. 사이킷런 그레이디언트 부스팅 모델
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gbrt">
       7.5.2.2. 그레이디언트 부스티드 회귀 나무(GBRT) 예제: 그레이디언트 부스팅 (회귀)+ 결정트리
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#learning-rate">
       7.5.2.3.
       <code class="docutils literal notranslate">
        <span class="pre">
         learning_rate
        </span>
       </code>
       (학습률)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id30">
       7.5.2.4. 최적의 결정트리 수 확인법
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id31">
       7.5.2.5. 확률적 그레이디언트 부스팅
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xgboost">
       7.5.2.6. XGBoost
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id32">
   7.6. 7.6 스태킹
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id33">
     7.6.1. 스태킹 모델 훈련법
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id34">
       7.6.1.1. 1층 훈련
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id35">
       7.6.1.2. 2층 훈련
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stackingregressor">
       7.6.1.3. 사이킷런의
       <code class="docutils literal notranslate">
        <span class="pre">
         StackingRegressor
        </span>
       </code>
       모델 활용법
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stackingclassifier">
       7.6.1.4. 사이킷런의
       <code class="docutils literal notranslate">
        <span class="pre">
         StackingClassifier
        </span>
       </code>
       모델 활용법
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id36">
       7.6.1.5. 스태킹 모델의 예측값
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id37">
     7.6.2. 다층 스태킹
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id38">
       7.6.2.1. 예제: 3층 스태킹 모델 훈련과정
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id39">
   7.7. 연습문제
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>앙상블 학습과 랜덤 포레스트</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   7.1. 투표식 분류기
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     7.1.1. 직접투표
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     7.1.2. 간접투표
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     7.1.3. 투표식 분류기의 확률적 근거
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     7.1.4. 투표식 분류기 예제
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   7.2. 7.2 배깅/페이스팅
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     7.2.1. 정의
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     7.2.2. 배깅
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     7.2.3. 배깅/페이스팅 예측 방식
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     7.2.4. 앙상블 학습의 편향과 분산
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     7.2.5. 예제: 사이킷런의 배깅/페이스팅
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#oob">
     7.2.6. oob 평가
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     7.2.7. 앙상블 모델의 검증과 테스트
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   7.3. 7.3 랜덤 패치와 랜덤 서브스페이스
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#max-features">
     7.3.1.
     <code class="docutils literal notranslate">
      <span class="pre">
       max_features
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bootstrap-features">
     7.3.2.
     <code class="docutils literal notranslate">
      <span class="pre">
       bootstrap_features
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     7.3.3. 랜덤 패치 기법
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     7.3.4. 랜덤 서브스페이스 기법
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id17">
   7.4. 7.4 랜덤 포레스트
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     7.4.1. 랜덤 포레스트 하이퍼파라미터
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     7.4.2. 엑스트라 트리
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id20">
       7.4.2.1. 예제
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     7.4.3. 특성 중요도
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id22">
       7.4.3.1. 예제: 붓꽃 데이터셋
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#mnist">
       7.4.3.2. 예제: MNIST
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id23">
   7.5. 7.5 부스팅
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#adaboost">
     7.5.1. 에이다부스트(AdaBoost)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id24">
       7.5.1.1. 샘플 가중치
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id25">
       7.5.1.2. 에이다부스트 알고리즘 작동 과정
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id26">
       7.5.1.3. 사이키런의 에이다부스트
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id27">
       7.5.1.4. 예제: 에이다부스트 + 결정트리
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id28">
     7.5.2. 그레이디언트 부스팅
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id29">
       7.5.2.1. 사이킷런 그레이디언트 부스팅 모델
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gbrt">
       7.5.2.2. 그레이디언트 부스티드 회귀 나무(GBRT) 예제: 그레이디언트 부스팅 (회귀)+ 결정트리
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#learning-rate">
       7.5.2.3.
       <code class="docutils literal notranslate">
        <span class="pre">
         learning_rate
        </span>
       </code>
       (학습률)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id30">
       7.5.2.4. 최적의 결정트리 수 확인법
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id31">
       7.5.2.5. 확률적 그레이디언트 부스팅
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xgboost">
       7.5.2.6. XGBoost
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id32">
   7.6. 7.6 스태킹
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id33">
     7.6.1. 스태킹 모델 훈련법
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id34">
       7.6.1.1. 1층 훈련
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id35">
       7.6.1.2. 2층 훈련
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stackingregressor">
       7.6.1.3. 사이킷런의
       <code class="docutils literal notranslate">
        <span class="pre">
         StackingRegressor
        </span>
       </code>
       모델 활용법
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stackingclassifier">
       7.6.1.4. 사이킷런의
       <code class="docutils literal notranslate">
        <span class="pre">
         StackingClassifier
        </span>
       </code>
       모델 활용법
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id36">
       7.6.1.5. 스태킹 모델의 예측값
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id37">
     7.6.2. 다층 스태킹
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id38">
       7.6.2.1. 예제: 3층 스태킹 모델 훈련과정
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id39">
   7.7. 연습문제
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="ch-ensemble">
<span id="id1"></span><h1><span class="section-number">7. </span>앙상블 학습과 랜덤 포레스트<a class="headerlink" href="#ch-ensemble" title="Permalink to this headline">¶</a></h1>
<p><strong>감사의 글</strong></p>
<p>자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>본문 내용의 일부를 파이썬으로 구현한 내용은
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/notebooks/code_ensemble_learning_random_forests.ipynb">(구글코랩) 앙상블 학습과 랜덤 포레스트</a>에서
확인할 수 있다.</p>
<p><strong>요약</strong></p>
<p>(1) 편향과 분산의 트레이드오프</p>
<p>앙상블 학습의 핵심은 <strong>편향</strong><font size='2'>bias</font>과
<strong>분산</strong><font size='2'>variance</font>을 줄인 모델을 구현하는 것이다.</p>
<ul class="simple">
<li><p>편향: 예측값과 정답이 떨어져 있는 정도를 나타낸다.
정답에 대한 잘못된 가정으로부터 유발되며
편향이 크면 과소적합이 발생한다.</p></li>
<li><p>분산: 입력 샘플의 작은 변동에 반응하는 정도를 나타낸다.
정답에 대한 너무 복잡한 모델을 설정하는 경우 분산이 커지며,
분산이 크면 과대적합이 발생한다.</p></li>
</ul>
<p>그런데 편향과 분산을 동시에 줄일 수 없다.
이유는 편향과 분산은 서로 트레이드오프 관계를 갖기 때문이다.</p>
<p>예를 들어,
훈련셋을 작게 하면 편향은 커지고, 분산은 작아진다.
반면에 훈련셋을 크게 하면 편향은 작아지고, 분산은 커진다.
그리고 훈련 샘플의 특성 수가 작아지면 편향은 커지고, 분산은 작아지고,
특성 수가 많아지면 편향은 작아지고, 분산은 커진다.</p>
<p>회귀 모델의 평균 제곱 오차는 편향의 제곱과 분산의 합으로 근사되며,
아래 그래프가 회위 모델의 복잡도, 편향, 분산의 관계를 잘 보여준다.</p>
<div class="math notranslate nohighlight">
\[
\text{평균제곱오차} \approx \text{편향}^2 + \text{분산}
\]</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/bagging_boosting02.png" width="600"/></div>
<p>&lt;<a class="reference external" href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">위키백과: 편향-분산 트레이드오프</a>&gt;</p>
<div class="info admonition">
<p class="admonition-title">평균 제곱 오차, 편향, 분산의 관계</p>
<p><a class="reference external" href="http://theanalysisofdata.com/notes/estimators1.pdf">Bias, Variance, and MSE of Estimators</a> 에서
평균 제곱 오차, 분산, 편향의 관계를 수학적으로 잘 설명한다.</p>
</div>
<p>(2) 앙상블 학습</p>
<p><strong>앙상블 학습</strong><font size='2'>ensemble learning</font>은
모델 여러 개를 이용한 훈련과 예측을 진행하는 모델을 구현할 때 사용한다.
결과적으로 분산 또는 편향을 줄이기 사용되며 대표적으로
<strong>배깅</strong><font size='2'>bagging</font> 기법과
<strong>부스팅</strong><font size='2'>boosting</font> 기법이
주로 사용된다.</p>
<ul class="simple">
<li><p>배깅 기법: 독립적으로 학습된 예측기 여러 개의 예측값들의 평균값을 예측값으로
사용하여 분산이 줄어든 모델을 구현한다.</p></li>
<li><p>부스팅 기법: 예측기 여러 개를 순차적으로 쌓아 올려 예측값의 편향를 줄이는
모델을 구현한다.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/bagging_boosting01.png" width="500"/></div><div class="section" id="id2">
<h2><span class="section-number">7.1. </span>투표식 분류기<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>동일한 훈련 세트에 대해 여러 종류의 분류기 이용한 앙상블 학습 적용 후 직접 또는 간접 투표를 통해 예측값 결정.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-01.png" width="500"/></div><div class="section" id="id3">
<h3><span class="section-number">7.1.1. </span>직접투표<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>앙상블에 포함된 예측기들의 예측값들의 다수로 결정</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-02.png" width="500"/></div></div>
<div class="section" id="id4">
<h3><span class="section-number">7.1.2. </span>간접투표<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>앙상블에 포함된 예측기들의 예측한 확률값들의 평균값으로 예측값 결정</p></li>
<li><p>전제: 모든 예측기가 <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> 메서드와 같은 확률 예측 기능을 지원해야 함.</p></li>
<li><p>높은 확률에 보다 비중을 두기 때문에 직접투표 방식보다 성능 좀 더 좋음.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-04.png" width="500"/></div>
<p>&lt;그림출처: <a class="reference external" href="https://www.kaggle.com/fengdanye/machine-learning-6-basic-ensemble-learning">kaggle</a>&gt;</p>
</div>
<div class="section" id="id5">
<h3><span class="section-number">7.1.3. </span>투표식 분류기의 확률적 근거<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>이항분포의 누적분포함수를 이용하여 앙상블 학습의 성능이 향상되는 이유를 설명할 수 있음.</p>
<ul class="simple">
<li><p>p: 예측기 하나의 성능</p></li>
<li><p>n: 예측기 개수</p></li>
<li><p>반환값: 다수결을 따를 때 성공할 확률, 즉 다수결 의견이 보다 정확할 확률. 이항 분포의 누적분포함수 활용.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="k">def</span> <span class="nf">ensemble_win_proba</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    p: 예측기 하나의 성능</span>
<span class="sd">    n: 앙상블 크기, 즉 예측기 개수</span>
<span class="sd">    반환값: 다수결을 따를 때 성공할 확률. 이항 분포의 누적분포함수 활용.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="mf">0.4999</span><span class="p">),</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>적중률 51% 모델 1,000개의 다수결을 따르면 74.7% 정도의 적중률 나옴.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ensemble_win_proba</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mf">0.51</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7467502275563249
</pre></div>
</div>
</div>
</div>
<p>적중률 51% 모델 10,000개의 다수결을 따르면 97.8% 정도의 적중률 나옴.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ensemble_win_proba</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mf">0.51</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9777976478701103
</pre></div>
</div>
</div>
</div>
<p>적중률 80% 모델 10개의 다수결을 따르면 100%에 가까운 성능이 가능함.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ensemble_win_proba</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9936306176
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>주의사항:</strong> 앙상블 학습에 포함된 각각의 모델이 서로 독립인 것을 전제로한 결과임.</p></li>
</ul>
<ul class="simple">
<li><p>동일한 데이터를 사용할 경우 독립성이 보장되지 않으며, 경우에 따라 성능이 하락할 수 있음.</p></li>
</ul>
<ul class="simple">
<li><p>독립성을 높이기 위해 매우 다른 알고리즘을 사용하는 여러 모델을 사용해야 함.</p></li>
</ul>
</div>
<div class="section" id="id6">
<h3><span class="section-number">7.1.4. </span>투표식 분류기 예제<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>사이킷런의 투표식 분류기</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VotingClassifier</span></code>: 투표식 분류기 모델 제공</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">voting='hard'</span></code>: 직접 투표 방식 지정 하이퍼 파라미터</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">voting='soft'</span></code>: 간접 투표 방식 지정 하이퍼 파라미터</p></li>
<li><p>주의: <code class="docutils literal notranslate"><span class="pre">SVC</span></code> 모델 지정할 때 <code class="docutils literal notranslate"><span class="pre">probability=True</span></code> 사용해야 <code class="docutils literal notranslate"><span class="pre">predict_proba()</span></code> 메서드 지원됨.</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">log_clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s2">&quot;lbfgs&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rnd_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">svm_clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># 투표식 분류기: 직접 투표</span>
<span class="n">voting_clf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="n">log_clf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">rnd_clf</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;svc&#39;</span><span class="p">,</span> <span class="n">svm_clf</span><span class="p">)],</span> 
    <span class="n">voting</span><span class="o">=</span><span class="s1">&#39;hard&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id7">
<h2><span class="section-number">7.2. </span>7.2 배깅/페이스팅<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3><span class="section-number">7.2.1. </span>정의<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>여러 개의 동일 모델을 훈련 세트의 다양한 부분집합을 대상으로 학습시키는 방식</p></li>
</ul>
<ul class="simple">
<li><p>부분집합을 임의로 선택할 때 중복 허용 여부에 따라 앙상블 학습 방식이 달라짐</p>
<ul>
<li><p><strong>배깅</strong>: 중복 허용 샘플링</p></li>
<li><p><strong>페이스팅</strong>: 중복 미허용 샘플링</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id9">
<h3><span class="section-number">7.2.2. </span>배깅<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>배깅(bagging): bootstrap aggregation의 줄임말</p></li>
<li><p>통계 분야에서 <strong>부트스트래핑</strong>, 즉, 중복허용 리샘플링으로 불림</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-05.png" width="500"/></div></div>
<div class="section" id="id10">
<h3><span class="section-number">7.2.3. </span>배깅/페이스팅 예측 방식<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>분류 모델: 직접 투표 방식 사용. 즉, 수집된 예측값들 중에서 최빈값(mode) 선택</p></li>
<li><p>회귀 모델: 수집된 예측값들의 평균값 선택</p></li>
</ul>
<p><strong>병렬 훈련 및 예측</strong></p>
<p>배깅/페이스팅 모델의 훈련과 예측은 다른 CPU 또는 심지어 다른 컴퓨터 서버를 이용하여 각 모델을 훈련 또는 예측을 하게 만든 후 병합하여 하나의 예측값을 생성하도록 할 수 있다.</p>
</div>
<div class="section" id="id11">
<h3><span class="section-number">7.2.4. </span>앙상블 학습의 편향과 분산<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>개별 예측기의 경우에 비해 편향은 조금 커지거나 거의 비슷하지만 분산은 줄어듦.
배깅이 표본 샘플링의 다양성을 보다 많이 추가하기 때문임.
배깅이 과대적합의 위험성일 보다 줄어주며, 따라서 배깅 방식이 기본으로 사용됨.</p></li>
</ul>
<ul class="simple">
<li><p>개별 예측기: 배깅/페이스팅 방식으로 학습하면 전체 훈련 세트를 대상으로 학습한 경우에 비해 편향이 커짐.
따라서 과소적합 위험성 커짐.</p></li>
</ul>
<ul class="simple">
<li><p><strong>참고:</strong> <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_bias_variance.html#sphx-glr-auto-examples-ensemble-plot-bias-variance-py">Single estimator versus bagging: bias-variance decomposition</a></p></li>
</ul>
</div>
<div class="section" id="id12">
<h3><span class="section-number">7.2.5. </span>예제: 사이킷런의 배깅/페이스팅<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>훈련세트(<code class="docutils literal notranslate"><span class="pre">X_train</span></code>) 크기: 500</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators=500</span></code>: 결정트리 500개 사용</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_samples=100</span></code>: 각 예측기가 100개 샘플 사용. 기본값은 1.0, 즉 전체 훈련 샘플 선택</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bootstrap=True</span></code>: 배깅 방식 사용(기본값). <code class="docutils literal notranslate"><span class="pre">False</span></code>면 페이스팅 방식 사용.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code>: 모든 사용가능한 cpu 사용하여 훈련을 __병렬처리__함. 양의 정수일 경우 정해진 수의 cpu 사용.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bag_clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> 
                            <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                            <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-06.png" width="600"/></div></div>
<div class="section" id="oob">
<h3><span class="section-number">7.2.6. </span>oob 평가<a class="headerlink" href="#oob" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>oob(out-of-bag) 샘플: 배깅 모델에 포함된 예측기로부터 선택되지 않은 훈련 샘플. 평균적으로 훈련 세트의 약 37% 정도.</p></li>
</ul>
<ul class="simple">
<li><p>각 예측기가 oob 샘플을 성능 검증에 활용.</p></li>
</ul>
<ul class="simple">
<li><p>앙상블 모델 자체의 성능 검증은 각 예측기의 oob 검증결과의 평균값 활용</p></li>
</ul>
</div>
<div class="section" id="id13">
<h3><span class="section-number">7.2.7. </span>앙상블 모델의 검증과 테스트<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BaggingClassifier</span></code> 의 <code class="docutils literal notranslate"><span class="pre">oob_score=True</span></code> 옵션</p>
<ul>
<li><p>훈련 종료 후 oob 평가 자동 실행</p></li>
<li><p>평가점수는 <code class="docutils literal notranslate"><span class="pre">oob_score_</span></code> 속성에 저정됨.</p></li>
<li><p>테스트세트에 대한 정확도와 비슷한 결과가 나옴.</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">bag_clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span> 
                            <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                            <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> 
                            <span class="n">oob_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id14">
<h2><span class="section-number">7.3. </span>7.3 랜덤 패치와 랜덤 서브스페이스<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BaggingClassifier</span></code>는 특성에 대한 샘플링 기능도 지원: <code class="docutils literal notranslate"><span class="pre">max_features</span></code>와 <code class="docutils literal notranslate"><span class="pre">bootstrap_features</span></code></p></li>
</ul>
<ul class="simple">
<li><p>이미지 등 매우 높은 차원의 데이터셋을 다룰 때 유용</p></li>
</ul>
<ul class="simple">
<li><p>더 다양한 예측기를 만들며, 편향이 커지지만 분산은 낮아짐</p></li>
</ul>
<div class="section" id="max-features">
<h3><span class="section-number">7.3.1. </span><code class="docutils literal notranslate"><span class="pre">max_features</span></code><a class="headerlink" href="#max-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>학습에 사용할 특성 수 지정</p></li>
</ul>
<ul class="simple">
<li><p>특성 선택은 무작위</p>
<ul>
<li><p>정수인 경우: 지정된 수만큼 특성 선택</p></li>
<li><p>부동소수점(<span class="math notranslate nohighlight">\(\in [0, 1]\)</span>)인 경우: 지정된 비율만큼 특성 선택</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>max_samples와 유사 기능 수행</p></li>
</ul>
</div>
<div class="section" id="bootstrap-features">
<h3><span class="section-number">7.3.2. </span><code class="docutils literal notranslate"><span class="pre">bootstrap_features</span></code><a class="headerlink" href="#bootstrap-features" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>학습에 사용할 특성을 선택할 때 중복 허용 여부 지정</p></li>
</ul>
<ul class="simple">
<li><p>기본값은 False. 즉, 중복 허용하지 않음.</p></li>
</ul>
<ul class="simple">
<li><p>botostrap과 유사 기능 수행</p></li>
</ul>
</div>
<div class="section" id="id15">
<h3><span class="section-number">7.3.3. </span>랜덤 패치 기법<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>훈련 샘플과 훈련 특성 모두를 대상으로 중복을 허용하며 임의의 샘플 수와 임의의 특성 수만큼을 샘플링해서 학습하는 기법</p></li>
</ul>
</div>
<div class="section" id="id16">
<h3><span class="section-number">7.3.4. </span>랜덤 서브스페이스 기법<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>전체 훈련 세트를 학습 대상으로 삼지만 훈련 특성은 임의의 특성 수만큼 샘플링해서 학습하는 기법</p></li>
</ul>
</div>
</div>
<div class="section" id="id17">
<h2><span class="section-number">7.4. </span>7.4 랜덤 포레스트<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>배깅/페이스팅 방법을 적용한 결정트리의 앙상블을 최적화한 모델</p>
<ul>
<li><p>분류 용도: <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code></p></li>
<li><p>회귀 용도: <code class="docutils literal notranslate"> <span class="pre">RandomForestRegressor</span></code></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>아래 두 모델은 기본적으로 동일한 모델임.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rnd_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                                 <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">bag_clf</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">splitter</span><span class="o">=</span><span class="s2">&quot;random&quot;</span><span class="p">,</span> 
                                                   <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> 
                                                   <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
                            <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">max_samples</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> 
                            <span class="n">bootstrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="id18">
<h3><span class="section-number">7.4.1. </span>랜덤 포레스트 하이퍼파라미터<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BaggingClassifier</span></code>와 <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>의 옵션을 거의 모두 가짐. 예외는 다음과 같음.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">DecisitionClassifier</span></code>의 옵션 중: <code class="docutils literal notranslate"><span class="pre">splitter='random'</span></code>, <code class="docutils literal notranslate"><span class="pre">presort=False</span></code>, <code class="docutils literal notranslate"><span class="pre">max_samples=1.0</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BaggingClassifier</span></code>의 옵션 중: <code class="docutils literal notranslate"><span class="pre">base_estimator=DecisionClassifier(...)</span></code></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">splitter='random'</span></code> 옵션: 특성 일부를 무작위적으로 선택한 후 최적의 임곗값 선택</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_features='auto'</span></code>가 <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>의 기본값임.
따라서 특성 선택에 무작위성 사용됨.</p>
<ul>
<li><p>선택되는 특성 수: 약 <span class="math notranslate nohighlight">\(\sqrt{\text{전체 특성 수}}\)</span></p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>결정트리에 비해 편향은 크게, 분산은 낮게.</p></li>
</ul>
</div>
<div class="section" id="id19">
<h3><span class="section-number">7.4.2. </span>엑스트라 트리<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><strong>익스트림 랜덤 트리(extremely randomized tree) 앙상블</strong> 이라고도 불림.</p></li>
</ul>
<ul class="simple">
<li><p>무작위로 선택된 일부 특성에 대해 특성 임곗값도 무작위로 몇 개 선택한 후 그중에서 최적 선택</p></li>
</ul>
<ul class="simple">
<li><p>일반적인 램덤포레스트보다 속도가 훨씬 빠름</p></li>
</ul>
<ul class="simple">
<li><p>이 방식을 사용하면 편향은 늘고, 분산은 줄어듦</p></li>
</ul>
<ul class="simple">
<li><p>참고: <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/15a949460dbf19e5e196b8ef48f9712b72a3b3c3/sklearn/tree/_classes.py#L1285">ExtraTreeClassifier 클래스 정의</a></p></li>
</ul>
<div class="section" id="id20">
<h4><span class="section-number">7.4.2.1. </span>예제<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">extra_clf</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> 
                                 <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> 
                                 <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id21">
<h3><span class="section-number">7.4.3. </span>특성 중요도<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>특성 중요도: 해당 특성을 사용한 마디가 평균적으로 불순도를 얼마나 감소시키는지를 측정</p>
<ul>
<li><p>즉, 불순도를 많이 줄이면 그만큼 중요도가 커짐</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>사이킷런의 <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code></p>
<ul>
<li><p>특성별 상대적 중요도를 측정해서 중요도의 전체 합이 1이 되도록 함.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> 속성에 저장됨.</p></li>
</ul>
</li>
</ul>
<div class="section" id="id22">
<h4><span class="section-number">7.4.3.1. </span>예제: 붓꽃 데이터셋<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h4>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:center head"><p>특성</p></th>
<th class="text-align:right head"><p>중요도(%)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:center"><p>꽃잎 길이</p></td>
<td class="text-align:right"><p>44.1</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>곷잎 너비</p></td>
<td class="text-align:right"><p>42.3</p></td>
</tr>
<tr class="row-even"><td class="text-align:center"><p>꽃받침 길이</p></td>
<td class="text-align:right"><p>11.3</p></td>
</tr>
<tr class="row-odd"><td class="text-align:center"><p>곷받침 너비</p></td>
<td class="text-align:right"><p>2.3</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="mnist">
<h4><span class="section-number">7.4.3.2. </span>예제: MNIST<a class="headerlink" href="#mnist" title="Permalink to this headline">¶</a></h4>
<p>아래 이미지는 각 픽셀의 중요도를 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-07.png" width="400"/></div></div>
</div>
</div>
<div class="section" id="id23">
<h2><span class="section-number">7.5. </span>7.5 부스팅<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>부스팅(boosting): 성능이 약한 학습기의 여러 개를 선형으로 연결하여 강한 성능의 학습기를 만드는 앙상블 기법.
대표적 알고리즘은 다음과 같음.</p>
<ul>
<li><p>에이다부스트(AdaBoost)</p></li>
<li><p>그레이디언트 부스팅(Gradient Boosting)</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>순차적으로 이전 학습기의 결과를 바탕으로 성능을 조금씩 높혀감. 즉, 편향을 줄여나감.</p></li>
</ul>
<ul class="simple">
<li><p>성능이 약한 예측기의 단점을 보완하여 좋은 성능의 예측기를 훈련해 나가는 것이 부스팅의 기본 아이디어</p></li>
</ul>
<ul class="simple">
<li><p>순차적으로 학습하기에 배깅/페이스팅에 비해 확장성이 떨어짐</p></li>
</ul>
<div class="section" id="adaboost">
<h3><span class="section-number">7.5.1. </span>에이다부스트(AdaBoost)<a class="headerlink" href="#adaboost" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>좀 더 나은 예측기를 생성하기 위해 잘못 적용된 가중치를 조정하여 새로운 예측기를 추가하는 앙상블 기법.
이전 모델이 제대로 학습하지 못한, 즉 과소적합했던 샘플들에 대한 가중치를 더 높이는 방식으로 새로운 모델 생성.</p></li>
</ul>
<ul class="simple">
<li><p>새로운 예측기는 학습하기 어려운 샘플에 조금씩 더 잘 적응하는 모델이 연속적으로 만들어져 감.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-08.png" width="500"/></div><div class="section" id="id24">
<h4><span class="section-number">7.5.1.1. </span>샘플 가중치<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>훈련중에 특정 샘플을 보다 강조하도록 유도하는 가중치를 가리킴.</p></li>
</ul>
<ul class="simple">
<li><p>사이킷런 모델의 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 메서드는 <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> 옵션인자를 추가로 사용하여
훈련 세트의 각 샘플에 대한 가중치를 지정할 수 있음.</p></li>
</ul>
<ul class="simple">
<li><p>샘플 가중치는 모든 샘플에 대해 주어지며, <code class="docutils literal notranslate"><span class="pre">sampe_weight</span></code> 옵션인자를 이용하여
각 샘플에 대한 가중치를 결정함.</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> 옵션인자를 지정하지 않으면 모든 샘플의 가중치를 동일하게 간주함.</p></li>
</ul>
<ul class="simple">
<li><p>참고: <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/15a949460/sklearn/svm/_base.py#L119">SVC의 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 메서드 정의</a></p></li>
</ul>
</div>
<div class="section" id="id25">
<h4><span class="section-number">7.5.1.2. </span>에이다부스트 알고리즘 작동 과정<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>moons 데이터셋에 rbf 커널을 사용하는 SVC 모델을 5번 연속 새로 생성하는
방식으로 학습한 결과를 보여줌.</p></li>
</ul>
<ul class="simple">
<li><p>새로운 예측기의 <code class="docutils literal notranslate"><span class="pre">fit()</span></code> 메서드는 이전 예측기의 경우와 다른 <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> 옵션값을 사용함.</p></li>
</ul>
<ul class="simple">
<li><p>새로운 예측기는 이전의 예측기의 예측값이 틀린 샘플을 보다 강조하도록 유도됨.</p></li>
</ul>
<ul class="simple">
<li><p>왼편과 오른편은 학습률만 다름.</p>
<ul>
<li><p><strong>주의사항:</strong> <code class="docutils literal notranslate"><span class="pre">learnign_rate</span></code>는 기존에 설명한 학습률과 다른 의미이며, 각 예측기의 기여도 조절에 사용됨.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-09.png" width="600"/></div></div>
<div class="section" id="id26">
<h4><span class="section-number">7.5.1.3. </span>사이키런의 에이다부스트<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>분류 모델: <code class="docutils literal notranslate"><span class="pre">AdaBoostClassifier</span></code></p></li>
<li><p>회귀 모델: <code class="docutils literal notranslate"><span class="pre">AdaBoostRegressor</span></code></p></li>
</ul>
</div>
<div class="section" id="id27">
<h4><span class="section-number">7.5.1.4. </span>예제: 에이다부스트 + 결정트리<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">AdaBoostClassifier</span></code> 의 기본 모델임.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ada_clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> 
                             <span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;SAMME.R&quot;</span><span class="p">,</span> 
                             <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>훈련 세트: moons 데이터셋</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-10.png" width="400"/></div></div>
</div>
<div class="section" id="id28">
<h3><span class="section-number">7.5.2. </span>그레이디언트 부스팅<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>이전 학습기에 의한 오차를 보정하도록 새로운 예측기를 순차적으로 추가하는 아이디어는 에이다부스트와 동일</p></li>
</ul>
<ul class="simple">
<li><p>샘플의 가중치를 수정하는 대신 이전 예측기가 만든 <strong>잔차</strong>(residual error)에 대해 새로운 예측기를 학습시킴</p></li>
</ul>
<ul class="simple">
<li><p>잔차(residual error): 예측값과 실제값 사이의 오차</p></li>
</ul>
<div class="section" id="id29">
<h4><span class="section-number">7.5.2.1. </span>사이킷런 그레이디언트 부스팅 모델<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>분류 모델: <code class="docutils literal notranslate"><span class="pre">GradientBoostingClassifier</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>와 비슷한 하이퍼파라미터를 제공</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>회귀 모델: <code class="docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code>와 비슷한 하이퍼파라미터를 제공</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="gbrt">
<h4><span class="section-number">7.5.2.2. </span>그레이디언트 부스티드 회귀 나무(GBRT) 예제: 그레이디언트 부스팅 (회귀)+ 결정트리<a class="headerlink" href="#gbrt" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>2차 다항식 데이터셋에 결정트리 3개를 적용한 효과와 동일하게 작동</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                                 <span class="n">n_estimators</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                 <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-11.png" width="500"/></div></div>
<div class="section" id="learning-rate">
<h4><span class="section-number">7.5.2.3. </span><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>(학습률)<a class="headerlink" href="#learning-rate" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">learnign_rate</span></code>는 기존에 설명한 학습률과 다른 의미의 학습률.</p>
<ul>
<li><p>각 결정트리의 기여도 조절에 사용</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>수축(shrinkage) 규제: 학습률을 낮게 정하면 많은 수의 결정트리 필요하지만 성능 좋아짐.</p></li>
</ul>
<ul class="simple">
<li><p>이전 결정트리에서 학습된 값을 전달할 때 사용되는 비율</p>
<ul>
<li><p>1.0이면 그대로 전달</p></li>
<li><p>1.0보다 작으면 해당 비율 만큼 조금만 전달</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id30">
<h4><span class="section-number">7.5.2.4. </span>최적의 결정트리 수 확인법<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>조기종료 기법 활용</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-12.png" width="500"/></div></div>
<div class="section" id="id31">
<h4><span class="section-number">7.5.2.5. </span>확률적 그레이디언트 부스팅<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>각 결정트리가 훈련에 사용할 훈련 샘플의 비율을 지정하여 학습: <code class="docutils literal notranslate"><span class="pre">subsample=0.25</span></code> 등 비율 지정</p></li>
</ul>
<ul class="simple">
<li><p>훈련 속도 빨라짐.</p></li>
</ul>
<ul class="simple">
<li><p>편향 높아지지만, 분산 낮아짐.</p></li>
</ul>
</div>
<div class="section" id="xgboost">
<h4><span class="section-number">7.5.2.6. </span>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Extreme Gradient Boosting의 줄임말.</p></li>
</ul>
<ul class="simple">
<li><p>빠른 속도, 확장성, 이식성 뛰어남.</p></li>
</ul>
<ul>
<li><p>조기종료 등 다양한 기능 제공.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span>
<span class="n">xgb_reg</span> <span class="o">=</span> <span class="n">xgboost</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">xgb_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
            <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)],</span> 
            <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="section" id="id32">
<h2><span class="section-number">7.6. </span>7.6 스태킹<a class="headerlink" href="#id32" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>배깅방식의 응용으로 볼 수 있는 기법</p></li>
</ul>
<ul class="simple">
<li><p>다수결을 이용하는 대신 여러 예측값을 훈련 데이터로 활용하는 예측기를 훈련시키는 기법</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-13.png" width="400"/></div><div class="section" id="id33">
<h3><span class="section-number">7.6.1. </span>스태킹 모델 훈련법<a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>책에서는 스태킹 기법을 소개만하고 코드 구현은 연습문제 9번에서 설명한다.</p></li>
</ul>
<ul class="simple">
<li><p>여기서는 사이킷런 0.22부터 지원하는 스태킹 모델을 활용하여 코드구현을 설명한다.</p></li>
</ul>
<ul class="simple">
<li><p>참조: <a class="reference external" href="https://scikit-learn.org/stable/modules/ensemble.html#stacked-generalization">Stacked generalization</a></p></li>
</ul>
<div class="section" id="id34">
<h4><span class="section-number">7.6.1.1. </span>1층 훈련<a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>먼저 훈련 세트를 훈련세트1과 훈련세트2로 이등분한다.</p></li>
</ul>
<ul class="simple">
<li><p>하나의 훈련세트1의 전체 샘플을 이용하여 주어진 예측기들을 각자 독립적으로 훈련시킨다.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-14.png" width="400"/></div></div>
<div class="section" id="id35">
<h4><span class="section-number">7.6.1.2. </span>2층 훈련<a class="headerlink" href="#id35" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>훈련세트2의 모든 샘플에 대해 훈련된 예측기별로 예측값을 생성한다.</p></li>
</ul>
<ul class="simple">
<li><p>예측값들로 이루어진 훈련세트를 이용하여 믹서기 모델(블렌더)을 훈련시킨다.</p>
<ul>
<li><p>2층 훈련에 사용되는 샘플의 차원은 1층에 사용되는 예측기 개수이다.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-15.png" width="400"/></div></div>
<div class="section" id="stackingregressor">
<h4><span class="section-number">7.6.1.3. </span>사이킷런의 <code class="docutils literal notranslate"><span class="pre">StackingRegressor</span></code> 모델 활용법<a class="headerlink" href="#stackingregressor" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">estimators</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;ridge&#39;</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">()),</span>
              <span class="p">(</span><span class="s1">&#39;lasso&#39;</span><span class="p">,</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
              <span class="p">(</span><span class="s1">&#39;knr&#39;</span><span class="p">,</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                          <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">))]</span>

<span class="n">final_estimator</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">max_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
                        <span class="n">final_estimator</span><span class="o">=</span><span class="n">final_estimator</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="stackingclassifier">
<h4><span class="section-number">7.6.1.4. </span>사이킷런의 <code class="docutils literal notranslate"><span class="pre">StackingClassifier</span></code> 모델 활용법<a class="headerlink" href="#stackingclassifier" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">estimators</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;rf&#39;</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)),</span>
              <span class="p">(</span><span class="s1">&#39;svr&#39;</span><span class="p">,</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                                    <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)))]</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span> 
                         <span class="n">final_estimator</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="section" id="id36">
<h4><span class="section-number">7.6.1.5. </span>스태킹 모델의 예측값<a class="headerlink" href="#id36" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>레이어를 차례대로 실행해서 믹서기(블렌더)가 예측한 값을 예측값으로 지정한다.</p></li>
</ul>
<ul class="simple">
<li><p>훈련된 스태킹 모델의 편향과 분산이 훈련에 사용된 모델들에 비해 모두 감소한다.</p></li>
</ul>
</div>
</div>
<div class="section" id="id37">
<h3><span class="section-number">7.6.2. </span>다층 스태킹<a class="headerlink" href="#id37" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>2층에서 여러 개의 믹서기(블렌더)를 사용하고,
그위 3층에 새로운 믹서기를 추가하는 방식으로 다층 스태킹을 훈련시킬 수 있다.</p></li>
</ul>
<ul class="simple">
<li><p>다층 스태킹의 훈련 방식은 2층 스태킹의 훈련 방식을 반복하면 된다.</p></li>
</ul>
<div class="section" id="id38">
<h4><span class="section-number">7.6.2.1. </span>예제: 3층 스태킹 모델 훈련과정<a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>훈련세트를 세 개의 부분 훈련세트로 나눈다.</p></li>
<li><p>훈련세트1은 1층 예측기 훈련에 사용한다.</p></li>
<li><p>훈련세트2은 2층 믹서기 훈련에 사용한다.</p></li>
<li><p>훈련세트3은 3층 믹서기 훈련에 사용한다.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch07/homl07-17.png" width="400"/></div></div>
</div>
</div>
<div class="section" id="id39">
<h2><span class="section-number">7.7. </span>연습문제<a class="headerlink" href="#id39" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="https://auto.gluon.ai/stable/index.html">AugoGluon</a> 활용하기</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="decision_trees.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">6. </span>결정트리</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="dimensionality_reduction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">8. </span>차원 축소</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 코딩알지<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>