

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>8. 차원 축소 &#8212; 핸즈온 머신러닝(3판)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'dimensionality_reduction';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="9. 비지도 학습" href="unsupervised_learning.html" />
    <link rel="prev" title="7. 앙상블 학습과 랜덤 포레스트" href="ensemble_learning_random_forests.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    <p class="title logo__title">핸즈온 머신러닝(3판)</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ml_landscape.html">1. 한눈에 보는 머신러닝</a></li>
<li class="toctree-l1"><a class="reference internal" href="end2end_ml_project.html">2. 머신러닝 프로젝트 처음부터 끝까지</a></li>
<li class="toctree-l1"><a class="reference internal" href="classification.html">3. 분류</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_models.html">4. 모델 훈련</a></li>
<li class="toctree-l1"><a class="reference internal" href="svm.html">5. 서포트 벡터 머신</a></li>
<li class="toctree-l1"><a class="reference internal" href="decision_trees.html">6. 결정트리</a></li>
<li class="toctree-l1"><a class="reference internal" href="ensemble_learning_random_forests.html">7. 앙상블 학습과 랜덤 포레스트</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">8. 차원 축소</a></li>
<li class="toctree-l1"><a class="reference internal" href="unsupervised_learning.html">9. 비지도 학습</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/jupyter-book/dimensionality_reduction.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/codingalzi/handson-ml3" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/codingalzi/handson-ml3/issues/new?title=Issue%20on%20page%20%2Fdimensionality_reduction.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/dimensionality_reduction.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>차원 축소</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">8.1. 차원의 저주</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">8.2. 차원 축소 기법</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">8.2.1. 사영 기법</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">8.2.2. 다양체 학습 기법</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pca">8.3. PCA(주성분 분석)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">8.3.1. 분산 보존</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svd">8.3.2. 주성분과 특잇값 분해(SVD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">8.3.3. 적절한 차원</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">8.3.4. PCA 활용 예제: 파일 압축</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">8.3.5. 랜덤 PCA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">8.3.6. 점진적 PCA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">8.4. 임의 사영</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lle">8.5. LLE(국소적 선형 임베딩)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">8.6. 부록: 기타 차원 축소 모델</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">8.7. 연습문제</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ch-dimensionalityreduction">
<span id="id1"></span><h1><span class="section-number">8. </span>차원 축소<a class="headerlink" href="#ch-dimensionalityreduction" title="Permalink to this heading">#</a></h1>
<p><strong>감사의 글</strong></p>
<p>자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>본문 내용의 일부를 파이썬으로 구현한 내용은
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/notebooks/code_dimensionality_reduction.ipynb">(구글코랩) 차원 축소</a>에서 확인할 수 있다.</p>
<p><strong>슬라이드</strong></p>
<p>본문 내용을 요약한
<a class="reference external" href="https://github.com/codingalzi/handson-ml3/raw/master/slides/slides-dimensionality_reduction.pdf">슬라이드</a>를
다운로드할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<p>샘플의 특성이 너무 많으면 학습이 매우 느리거나 어려워지는 현상를
<strong>차원의 저주</strong>라 한다.
이 문제를 해결하기 위해 특성 수를 (크게) 줄여서 학습 불가능한 문제를 학습 가능한 문제로 만드는 <strong>차원 축소</strong> 기법을 사용할 수 있다.
차원 축소로 인한 정보손실을 어느 정도 감안하면서 훈련 속도와 성능을 최대로 유지하는 것이 주요 목표다.</p>
<p>예를 들어, MNIST 데이터셋의 경우 사진의 중앙에만 집중하거나(<a class="reference internal" href="ensemble_learning_random_forests.html#exp-MNIST-feature-importance">Example 7.2</a>),
주성분 분석(PCA) 기법을 이용하여 손글씨 사진의 784개 픽셀 대신 154개만 대상으로 삼아도
별 문제 없이 숫자를 인식할 수 있다.</p>
<p>차원 축소 기법은 또한 데이터 시각화에도 활용된다.
데이터의 차원(특성 수)을 2, 3차원으로 줄이면 데이터셋을 시각화할 수 있다.
데이터 시각화는 데이터 군집 등의 시각적인 패턴을 감지하여 데이터에 대한 통찰을 얻거나
데이터에 대한 정보를 제3자에게 전달하는 데에 활용된다.</p>
<p>차원 축소를 위한 접근법은 크게 사영 기법과 다양체 학습 기법으로 나뉜다.
사영 기법 알고리즘으로 PCA(주성분 분석)와 임의 사영<font size='2'>Random Projection</font>을,
다양체 학습 알고리즘으로 LLE(국소적 선형 임베딩)를 소개한다.</p>
<section id="id2">
<h2><span class="section-number">8.1. </span>차원의 저주<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<p>벡터의 차원에 해당하는 특성 수가 아주 많은 경우, 훈련 샘플 사이의 거리가 매우 커서 과대적합 위험도가 커진다.
이유는 새로운 샘플이 주어졌을 때 해당 샘플과 훈련셋에 포함된 샘플 사이의
거리가 일반적으로 매우 멀어서 기존 값들을 이용한 추정이 매우 어렵기 때문이다.
훈련셋의 크기를 키우면 해결될 수 있지만 고차원 특성을 갖는 데이터 샘플을
과대적합을 피할 정도로 많은 샘플을 준비하는 일은 일반적으로 매우 어렵고 경우에 따라 사실상 불가능하다.
어런 현상을 <strong>차원의 저주</strong>라 부른다.</p>
</section>
<section id="id3">
<h2><span class="section-number">8.2. </span>차원 축소 기법<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h2>
<p>훈련 샘플이 고차원 공간의 일부인 저차원 부분공간에 가깝게 놓여 있는 경우가 일반적으로 발생한다.
이런 경우 고차원의 데이터셋을 저차원의 데이터셋으로 변환시켜도 정보의 손실이 크지 않다.
이것이 차원 축소 기법의 핵심이며 크게 사영 기법과 다양체 학습 기법으로 나뉜다.</p>
<section id="id4">
<h3><span class="section-number">8.2.1. </span>사영 기법<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(n\)</span>차원 데이터셋을 차원이 낮은 <span class="math notranslate nohighlight">\(d\)</span> 차원 데이터셋으로
<strong>사영</strong><font size='2'>projection</font>하는 기법이다.
아래 그림은
왼쪽 3차원에 존재하는 데이터셋을 적절한 2차원 평면으로 사영한 결과를 보여준다.
이때 오른쪽 이미지에 사용된 축 <span class="math notranslate nohighlight">\(z_1\)</span>과 <span class="math notranslate nohighlight">\(z_2\)</span>를 적절하게 찾는 게 주요 과제다.</p>
<table>
    <tr>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-02-1.png" width="400"/></div> </td>
        <td></td>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-02-2.png" width="400"/></div> </td>
    </tr>
</table><p>위의 경우는 사영을 통해 데이터셋 분석이 보다 간단해졌다.
하지만 경우에 따라 보다 복잡한 데이터셋이 만들어질 수도 있다.
예를 들어 아래 그림은 롤케이크를 <span class="math notranslate nohighlight">\(x_1\)</span>과 <span class="math notranslate nohighlight">\(x_2\)</span> 두 축으로
이루어진 평면에 사영하면 샘플 구분이 보다 어려워지는 것을 보여준다.</p>
<table>
    <tr>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-04.png" width="350"/></div> </td>
        <td></td>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-06.png" width="320"/></div> </td>
    </tr>
</table></section>
<section id="id5">
<h3><span class="section-number">8.2.2. </span>다양체 학습 기법<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p><strong>다양체</strong></p>
<p>고차원 공간에서 저차원 공간을 접거나 비틀어서 생성할 수 있는 공간을
<strong>다양체</strong><font size='2'>manifold</font>라 부른다.
예를 들어, 롤케이크<font size='2'>Swiss roll</font>는
2차원 평면을 돌돌 말아 만든 3차원 공간상에 존재하는 2D 다양체다.
실제로 롤케이크을 조심해서 펴면 보다 적절한 2차원 데이터셋으로 변환된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-07.png" width="310"/></div><p><strong>다양체 가설</strong></p>
<p>롤케이크와 같은 다양체의 경우 사영 보다는 접히거나 비틀어진 것을 잘 펼치면
보다 단순한 구조를 갖는 저차원의 데이터셋으로 변환된다.
이런 방식으로 숨겨진 저차원의 다양체를 찾는 과정이 <strong>다양체 학습</strong><font size='2'>Manifold learning</font>이다.</p>
<p>다양체 학습은 대부분의 고차원 데이터셋이 더 낮은 차원의 다양체에 가깝다는가설에
근거한다.
다양체 가설은 또한 저차원의 다양체 공간으로 차원 축소를 진행하면 보다
단순한 모양의 다양체가 된다라는
가설과 함께 사용되곤 한다.
하지만 이 가설은 경우에 따라 성립하거나 그렇지 않을 수 있다.
예를 들어, 아래 그림의 위쪽 데이터셋의 경우는 보다 간단해지지만,
아랫쪽 데이터셋의 경우는 차원 축소를 진행하면 데이터셋이 보다 복잡해진다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-08.png" width="600"/></div></section>
</section>
<section id="pca">
<h2><span class="section-number">8.3. </span>PCA(주성분 분석)<a class="headerlink" href="#pca" title="Permalink to this heading">#</a></h2>
<p>훈련 데이터셋을 특정 초평면<font size='2'>hyperplane</font>에 사영하는 기법이다.
초평면은 <strong>주성분 분석</strong><font size='2'>principal component analysis</font>(PCA)을
이용하여 결정한다.
초평면 지정에 사용되는 <strong>주성분</strong>은 <strong>분산 보존</strong> 개념과 밀접하게 연관된다.</p>
<div class="info admonition">
<p class="admonition-title">초평면</p>
<p>초평면<font size='2'>hyperplane</font>은 3차원 이상의 고차원에 존재하며
아래의 방정식을 만족하는 벡터들의 집합이다. 우리가 상상할 수 있는 평면의 개념과는 다른 모양을 갖는다.</p>
<div class="math notranslate nohighlight">
\[
a_1 x_1 + a_2 x_2 + \cdots + a_n x_n + c = 0
\]</div>
<p>위 식을 설명하면 다음과 같다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n=1</span></code> 인 경우: 1차원 공간에 존재하는 점</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n=2</span></code> 인 경우: 2차원 공간에 존재하는 직선</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n=3</span></code> 인 경우: 3차원 공간에 존재하는 평면</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n&gt;=</span> <span class="pre">4</span></code> 인 경우: n차원 공간에 존재하는 초평면</p></li>
</ul>
</div>
<section id="id6">
<h3><span class="section-number">8.3.1. </span>분산 보존<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h3>
<p>저차원으로 사영할 때 데이터셋의 분산이 최대한 유지되도록 축을 지정해야 한다.
아래 그림에서 <span class="math notranslate nohighlight">\(c_1\)</span> 벡터가 위치한 실선 축으로 사영하는 경우가 분산을 최대한 보존한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-09.png" width="500"/></div></section>
<section id="svd">
<h3><span class="section-number">8.3.2. </span>주성분과 특잇값 분해(SVD)<a class="headerlink" href="#svd" title="Permalink to this heading">#</a></h3>
<p>주성분은 다음 과정으로 차례대로 찾아야 한다.</p>
<ul class="simple">
<li><p>첫째 주성분: 분산을 최대한 보존하는 축</p></li>
<li><p>둘째 주성분: 첫째 주성분과 수직을 이루면서
첫재 주성분이 담당하지 않는 분산을 최대한 보존하는 축</p></li>
<li><p>셋째 주성분: 첫째, 둘째 주성분과 수직을 이루면서
첫째, 둘째 주성분이 담당하지 않는 분산을 최대한 보존하는 축</p></li>
<li><p>…</p></li>
</ul>
<p>사영에 사용되는 초평면은 주성분으로 구성된 축을 이용하는 공간으로 지정한다.
예를 들어, 첫째와 둘째 주성분만을 축으로 사용하면 2차원 초평면이 생성된다.</p>
<p>데이터셋의 주성분은 선형대수의 <strong>특잇값 분해</strong>(SVD) 기법을 이용하여
수학적으로 쉽게 찾을 수 있으며,
찾아진 초평면으로의 사영 또한 쉽게 계산된다.
단, 데이터셋이 크거나 특성이 많으면 계산이 매우 오래 걸릴 수 있다.</p>
<p><strong>사이킷런의 <code class="docutils literal notranslate"><span class="pre">PCA</span></code> 모델</strong></p>
<p>사이킷런의 <code class="docutils literal notranslate"><span class="pre">PCA</span></code> 모델은 SVD 기법을 활용한다.
예를 들어 아래 코드는 데이터셋의 차원을 2로 줄인다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X2D</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>설명 분산 비율</strong></p>
<p>훈련된 모델의 <code class="docutils literal notranslate"><span class="pre">explained_variance_ratio_</span></code> 속성 변수에 각 주성분에 대한 원 데이터셋의 분산 비율이 저장된다.
예를 들어 아래 사영 그림에서 그려진 3차원 데이터셋의 경우,
새로운 축 <span class="math notranslate nohighlight">\(z_1\)</span>과 <span class="math notranslate nohighlight">\(z_2\)</span>를 기준으로 원 데이터셋에 대해 차지하는
분산 비율은 다음과 같다.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(z_1\)</span> 축: 75.8%</p></li>
<li><p><span class="math notranslate nohighlight">\(z_2\)</span> 축: 15.2%</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
<span class="go">array([0.7578477 , 0.15186921])</span>
</pre></div>
</div>
<table>
    <tr>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-02-1.png" width="400"/></div> </td>
        <td></td>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-02-2.png" width="400"/></div> </td>
    </tr>
</table></section>
<section id="id7">
<h3><span class="section-number">8.3.3. </span>적절한 차원<a class="headerlink" href="#id7" title="Permalink to this heading">#</a></h3>
<p>설명된 분산 비율의 합이 95% 정도 되도록 하는 주성분들로 구성되도록
차원을 정하는 것이 좋다.
반면에 데이터 시각화가 목적인 경우엔 2개 또는 3개의 주성분만을 사용해야 한다.</p>
<p><strong>설명 분산 비율 활용</strong></p>
<p>적절한 차원을 결정하기 위해 설명 분산 비율의 합과 차원 사이의 그래프를 활용할 수도 있다.
예를 들어 설명 분산의 비율의 합의 증가가 완만하게 변하는 지점(elbow)에 주시하면 좋다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-10.png" width="400"/></div><p>위 그래프를 통해 설명 분산 비율의 합이 95% 정도가 되려면 154개의 차원이 필요함을 확인할 수 있다.
따라서 <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">=</span> <span class="pre">154</span></code> 를 하이퍼파라미터로 지정할 수 있으나
이보다는 <code class="docutils literal notranslate"><span class="pre">n_components</span> <span class="pre">=</span> <span class="pre">0.95</span></code> 로 지정하는 것이 보다 편리하다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">n_components</span></code> 하이퍼파라미터에 정수를 사용하면 차원을,
0과 1사이의 부동소수점을 지정하면 설명분산비율을 지정하는 것이다.</p>
<p><strong>파이프라인과 랜덤 탐색 활용</strong></p>
<p>적절한 차원을 찾기 위해 <code class="docutils literal notranslate"><span class="pre">PCA</span></code> 를 전처리로 사용하는 파이프라인을 생성하여
랜덤 탐색을 이용할 수 있다.
예를 들어, 아래 코드는 차원 축소와 랜덤 포레스트 모델을 파이프라인으로 엮은 후
랜덤 탐색을 이용하여 적절한 차원을 찾는다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PCA</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">),</span>
                    <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
<span class="n">param_distrib</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;pca__n_components&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span>
    <span class="s2">&quot;randomforestclassifier__n_estimators&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
    <span class="p">}</span>

<span class="n">rnd_search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">param_distrib</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">rnd_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">1000</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">1000</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="id8">
<h3><span class="section-number">8.3.4. </span>PCA 활용 예제: 파일 압축<a class="headerlink" href="#id8" title="Permalink to this heading">#</a></h3>
<p>파일 압축 용도로 PCA를 활용할 수 있다.
MNIST 데이터셋의 경우 784차원을 154 차원으로 줄이면
데이터셋의 크기가 원래의 20% 수준에 불과해져서
훈련 속도가 훨씬 빨라진다.
하지만 정보는 5% 정도만 잃는다.
정보 손실이 크지 않음을 아래 두 그림이 확인해준다.
왼쪽이 원본이고 오른쪽이 압축된 데이터를 재구성한 결과다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-11.png" width="400"/></div></section>
<section id="id9">
<h3><span class="section-number">8.3.5. </span>랜덤 PCA<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h3>
<p>주성분 선택을 위해 사용되는 SVD 알고리즘을 확률적으로 작동하도록 만드는 기법이다.
보다 빠르게 지정된 개수의 주성분에 대한 근삿값을 찾아준다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rnd_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">154</span><span class="p">,</span> <span class="n">svd_solver</span><span class="o">=</span><span class="s2">&quot;randomized&quot;</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">rnd_pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id10">
<h3><span class="section-number">8.3.6. </span>점진적 PCA<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>훈련세트를 미니배치로 나눈 후 IPCA(Incremental PCA)에 하나씩 주입하는 모델이며,
온라인 학습에 활용될 수 있다.
단, 훈련에 <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code> 을 사용한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_batches</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">inc_pca</span> <span class="o">=</span> <span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">154</span><span class="p">)</span>

<span class="k">for</span> <span class="n">X_batch</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">):</span>
    <span class="n">inc_pca</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>

<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">inc_pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">memmap</span></code> 클래스 활용</strong></p>
<p>넘파이의 <code class="docutils literal notranslate"><span class="pre">memmap</span></code> 클래스는
바이너리 파일로 저장된 (매우 큰) 데이터셋을 마치 메모리에 들어있는 것처럼 취급할 수 있는 도구를
제공하며, 이를 이용하여 미니배치/온라인 학습이 가능하다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># memmap 생성</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;my_mnist.mmap&quot;</span>
<span class="n">X_mmap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;write&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">X_mmap</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">X_train</span>
<span class="n">X_mmap</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

<span class="c1"># memmap 활용</span>
<span class="n">X_mmap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;readonly&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="n">X_mmap</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">n_batches</span>
<span class="n">inc_pca</span> <span class="o">=</span> <span class="n">IncrementalPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">154</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">inc_pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_mmap</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="id11">
<h2><span class="section-number">8.4. </span>임의 사영<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h2>
<p><strong>존슨-린덴슈트라우스 정리</strong></p>
<p>존슨-린덴슈트라우스<font size='2'>Johnson-Lindenstrauss</font> 정리는
고차원의 데이터를 적절한 크기의 저차원으로 임의로 사영하더라도
데이터셋의 정보를 많이 잃어버리지 않음을 보장한다.
적절한 크기의 차원 <span class="math notranslate nohighlight">\(d\)</span>는 정보를 얼마나 잃어도 되는가에 따라 결정되며,
아래 값을 만족하면 된다.
<span class="math notranslate nohighlight">\(m\)</span> 은 훈련셋의 크기를 나타내며,
<span class="math notranslate nohighlight">\(\varepsilon\)</span> 은 허용된 정보손실 정도를 가리킨다.</p>
<div class="math notranslate nohighlight">
\[
d \ge \frac{4 \log(m)}{\frac{1}{2} \varepsilon^2 - \frac{1}{3} \varepsilon^3}
\]</div>
<div class="info admonition">
<p class="admonition-title"><span class="math notranslate nohighlight">\(\varepsilon\)</span> 의 역할</p>
<p>예를 들어 <span class="math notranslate nohighlight">\(\varepsilon=0.1\)</span> 로 지정하면
사영된 두 데이터 사이의 거리의 제곱이 두 데이터의 원래 거리의 제곱에 비해  10% 정도의 차이를 갖도록 한다는 의미다.</p>
</div>
<p><strong>임의 사영</strong><font size='2'>Random Projection</font>은 존슨-린덴슈트라우스 정리를
이용하며, 사이킷런에서 두 개의 모델을 제공한다.</p>
<p><strong>사이킷런의 <code class="docutils literal notranslate"><span class="pre">GaussianRandomProjection</span></code> 모델</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">GaussianRandomProjection</span></code> 모델이 앞서 언급한 존슨-린덴슈트라우스 정리를 이용한
임의 사영을 실행한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian_rnd_proj</span> <span class="o">=</span> <span class="n">GaussianRandomProjection</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">gaussian_rnd_proj</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>사이킷런의 <code class="docutils literal notranslate"><span class="pre">SparseRandomProjection</span></code> 모델</strong></p>
<p>희소 행렬<font size='2'>sparse matrix</font>을 사용하는
<code class="docutils literal notranslate"><span class="pre">GaussianRandomProjection</span></code> 모델이며 보다 빠르고 메모리 효율적이다. 대용량 데이터셋이 주어진 경우 유용하다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian_rnd_proj</span> <span class="o">=</span> <span class="n">SparseRandomProjection</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">gaussian_rnd_proj</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="lle">
<h2><span class="section-number">8.5. </span>LLE(국소적 선형 임베딩)<a class="headerlink" href="#lle" title="Permalink to this heading">#</a></h2>
<p>대표적인 다양체 학습 기법이다.
롤케이크 데이터셋의 경우처럼 전체적으론 비선형인 다양체이지만 국소적으로는 데이터가 선형적으로 연관되어
있다는 가설을 이용한다.
국소적 관계가 가장 잘 보존되는 훈련 세트의 저차원 표현을 찾는다.</p>
<p>아래 코드는 롤케이크에 대해 LLE 를 적용한 결과를 보여준다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X_swiss</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">make_swiss_roll</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lle</span> <span class="o">=</span> <span class="n">LocallyLinearEmbedding</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_unrolled</span> <span class="o">=</span> <span class="n">lle</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_swiss</span><span class="p">)</span>
</pre></div>
</div>
<table>
    <tr>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-04.png" width="350"/></div> </td>
        <td></td>
        <td> <div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-14.png" width="370"/></div> </td>
    </tr>
</table></section>
<section id="id12">
<h2><span class="section-number">8.6. </span>부록: 기타 차원 축소 모델<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h2>
<p>사이킷런에서 제공하는 기타 차원 축소 모델은 다음과 같다.</p>
<ul class="simple">
<li><p>다차원 스케일링<font size='2'>Multidimensional Scaling</font>(MDS)</p></li>
<li><p>Isomap</p></li>
<li><p>t-SNE(t-Distributed Stochasting Neighbor Embedding)</p></li>
<li><p>선형 판별 분석<font size='2'>Linear Discriminant Analysis</font>(LDA)</p></li>
<li><p>커널 PCA</p></li>
</ul>
<p>아래 그림은 롤케이크를 각각 MDS, Isomap, t-SNE 방식으로 2차원으로 변환한 결과를 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-15.png" width="700"/></div><p>아래 그림은 롤케이크를 다양한 커널을 이용하여 커널 PCA로 2차원 데이터셋으로 변환한 결과를 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch08/homl08-16.png" width="730"/></div></section>
<section id="id13">
<h2><span class="section-number">8.7. </span>연습문제<a class="headerlink" href="#id13" title="Permalink to this heading">#</a></h2>
<p>참고: <a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/practices/practice_dimensionality_reduction.ipynb">(실습) 차원 축소</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="ensemble_learning_random_forests.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">7. </span>앙상블 학습과 랜덤 포레스트</p>
      </div>
    </a>
    <a class="right-next"
       href="unsupervised_learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">9. </span>비지도 학습</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">8.1. 차원의 저주</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">8.2. 차원 축소 기법</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">8.2.1. 사영 기법</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">8.2.2. 다양체 학습 기법</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pca">8.3. PCA(주성분 분석)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">8.3.1. 분산 보존</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#svd">8.3.2. 주성분과 특잇값 분해(SVD)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">8.3.3. 적절한 차원</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">8.3.4. PCA 활용 예제: 파일 압축</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">8.3.5. 랜덤 PCA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">8.3.6. 점진적 PCA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">8.4. 임의 사영</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lle">8.5. LLE(국소적 선형 임베딩)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">8.6. 부록: 기타 차원 축소 모델</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">8.7. 연습문제</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 코딩알지
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>