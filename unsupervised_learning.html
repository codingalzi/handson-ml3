
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>9. 비지도 학습 &#8212; 핸즈온 머신러닝(3판)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="8. 차원축소" href="dimensionality_reduction.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">핸즈온 머신러닝(3판)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ml_landscape.html">
   1. 한눈에 보는 머신러닝
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="end2end_ml_project.html">
   2. 머신러닝 프로젝트 처음부터 끝까지
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classification.html">
   3. 분류
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="training_models.html">
   4. 모델 훈련
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="svm.html">
   5. 서포트 벡터 머신
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="decision_trees.html">
   6. 결정트리
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_learning_random_forests.html">
   7. 앙상블 학습과 랜덤 포레스트
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dimensionality_reduction.html">
   8. 차원축소
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   9. 비지도 학습
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/unsupervised_learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/codingalzi/handson-ml3"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/codingalzi/handson-ml3/issues/new?title=Issue%20on%20page%20%2Funsupervised_learning.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/codingalzi/handson-ml3/master?urlpath=tree/jupyter-book/unsupervised_learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   9.1. 군집화
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k">
   9.2. K-평균
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     9.2.1. K-평균 알고리즘
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     9.2.2. 최적의 군집수 찾기
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     9.2.3. K-평균의 한계
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     9.2.4. 군집화 활용
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dbscan">
   9.3. DBSCAN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   9.4. 가우시안 혼합 모델
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     9.4.1. 가우시안 혼합 모델 활용: 이상치 탐지
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     9.4.2. 가우션 혼합모델 군집수 지정
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     9.4.3. 베이즈 가우시안 혼합 모델
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     9.4.4. 이상치 탐지와 특이치 탐지를 위한 다른 알고리즘
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>비지도 학습</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   9.1. 군집화
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k">
   9.2. K-평균
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     9.2.1. K-평균 알고리즘
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     9.2.2. 최적의 군집수 찾기
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     9.2.3. K-평균의 한계
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     9.2.4. 군집화 활용
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dbscan">
   9.3. DBSCAN
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   9.4. 가우시안 혼합 모델
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     9.4.1. 가우시안 혼합 모델 활용: 이상치 탐지
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     9.4.2. 가우션 혼합모델 군집수 지정
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     9.4.3. 베이즈 가우시안 혼합 모델
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     9.4.4. 이상치 탐지와 특이치 탐지를 위한 다른 알고리즘
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="ch-unsupervisedlearning">
<span id="id1"></span><h1><span class="section-number">9. </span>비지도 학습<a class="headerlink" href="#ch-unsupervisedlearning" title="Permalink to this headline">¶</a></h1>
<p><strong>감사의 글</strong></p>
<p>자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다.</p>
<p>비지도 학습은 레이블이 없는 데이터를 학습하는 기법이며,
주로 아래 분야에서 활용된다.</p>
<ul class="simple">
<li><p>군집화: 비슷한 샘플끼리의 군집을 형성하는 것이며,
아래 용도에 활용된다.</p>
<ul>
<li><p>데이터 분석</p></li>
<li><p>고객분류</p></li>
<li><p>추천 시스템</p></li>
<li><p>검색 엔진</p></li>
<li><p>이미지 분할</p></li>
<li><p>차원 축소</p></li>
<li><p>준지도 학습</p></li>
</ul>
</li>
<li><p>이상치 탐지: 정상 테이터와 이상치를 구분하는 데에 활용된다.</p>
<ul>
<li><p>생산라인에서 결함제품 탐지</p></li>
<li><p>새로운 트렌드 찾기</p></li>
</ul>
</li>
<li><p>데이터 밀도 추정: 데이터셋의 확률밀도를 추정한다.</p>
<ul>
<li><p>이상치 분류: 밀도가 낮은 지역에 위치한 샘플</p></li>
<li><p>데이터 분석</p></li>
<li><p>데이터 시각화</p></li>
</ul>
</li>
</ul>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>군집화</p></li>
<li><p>k-평균</p></li>
<li><p>DBSCAN</p></li>
<li><p>가우시안 혼합</p></li>
</ul>
<div class="section" id="id2">
<h2><span class="section-number">9.1. </span>군집화<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><strong>군집과 군집화</strong></p>
<p><strong>군집</strong><font size='2'>cluster</font>은 유사한 대상들의 모음을 가리킨다.
예를 들어, 산이나 공원에서 볼 수 있는 이름은 모르지만 동일 품종의 꽃으로 이루어진 군집 등을
생각하면 된다.
<strong>군집화</strong><font size='2'>clustering</font>은 대상들을 나누어 군집을
형성하는 것을 말한다.</p>
<p><strong>분류 대 군집화</strong></p>
<p>각 샘플에 하나의 그룹을 할당한다는 점에서 유사하다.
하지만 군집화는 군집이 미리 레이블(타깃)로 지정되지 않고 예측기 스스로 적절한 군집을
찾아내야 한다는 점에서 다르다.</p>
<p>아래 왼쪽 그림은 붓꽃의 꽃잎 길이와 너비를 특성으로 사용해서 품종을 분류한 결과를
보여주지만, 왼쪽 그림은 군집화의 결과를 보여준다.
분류는 세 개의 품종을 매우 잘 분류하지만 군집은 세토사 군집과 나머지 군집으로 구분할 뿐이다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-01.png" width="600"/></div><p>반면에 <strong>가우시안 혼합 모델</strong><font size='2'>Gaussian Mixture Model</font>(GMM)을
꽃잎의 길이와 너비 뿐만 아니라
꽃받침의 길이와 너비 특성까지 적용항 붓꽃 데이터셋에 대해 적용하면
세 개의 군집을 매우 정확하게 생성한다.</p>
<div align="center"><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_gmm_covariances_001.png" width="500"/></div>
<p>&lt;그림 출처: <a class="reference external" href="https://scikit-learn.org/stable/modules/mixture.html#gmm">사이킷런의 가우시안 혼합 모델</a>&gt;</p>
<p>군집에 대한 보편적 정의는 없다. 사용되는 알고리즘에 따라 다른 형식의 군집을 생성한다.</p>
<ul class="simple">
<li><p>K-평균: 센트로이드(중심)라는 특정 샘플을 중심으로 모인 샘플들의 집합</p></li>
<li><p>DBSCAN: 밀집된 샘플들의 연속으로 이루어진 집합</p></li>
<li><p>가우시안 혼합: 특정 가우시안 분포를 따르는 샘플들의 집합</p></li>
</ul>
</div>
<div class="section" id="k">
<h2><span class="section-number">9.2. </span>K-평균<a class="headerlink" href="#k" title="Permalink to this headline">¶</a></h2>
<p>각 군집의 중심인 센트로이드<font size='2'>centroid</font>을 찾고
각 샘플에 대해 가장 가까운 센트로이드를 중심으로 군집을 형성하는 기법이다.</p>
<p><strong>예제: 사이킷런의 <code class="docutils literal notranslate"><span class="pre">KMeans</span></code> 모델</strong></p>
<p>아래 그림은 다섯 개의 샘플 덩어리로 이루어진 데이터셋을 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-03.png" width="450"/></div><p>위 데이터셋에 대해 다섯 개의 군집을 형성하는 K-평균 알고리즘은 다음과 같이 적용한다.
군집 수를 몇 개로 지정하는가는 미리 알 수 없다.
나중에 몇 개의 군집이 적절한가를 판단하는 여러 방식을 살펴볼 것이다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">predict()</span></code> 함수의 반환값은 0, 1, 2, 3, 4 등의 인덱스이다.
하지만 이는 임의로 지정된 군집의 인덱스를 가리키며, 클래스 분류와는 아무 상관이 없다.</p>
<p><strong>보로노이 다이어그램</strong></p>
<p>평면을 특정 점(센트로이드)까지의 거리가 가장 가까운 점의 집합으로 분할한 그림이다.
경계 부분의 일부 샘플을 제외하고 기본적으로 군집을 잘 구성한다.</p>
<img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-04.png" width="450"/><div class="section" id="id3">
<h3><span class="section-number">9.2.1. </span>K-평균 알고리즘<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>먼저 k 개의 센트로이드를 무작위로 선택한 후 수렴할 때까지 다음 과정 반복한다.</p>
<ul class="simple">
<li><p>각 샘플을 가장 가까운 센트로이드에 할당</p></li>
<li><p>군집별로 샘플의 평균을 계산하여 새로운 센트로이드 지정</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-05.png" width="700"/></div><p><strong>K-평균 알고리즘의 단점</strong></p>
<p>군집의 크기가 서로 많이 다르면 잘 작동하지 않는다.
이유는 샘플과 센트로이드까지의 거리만 고려되기 때문이다.
또한 임의로 선택된 초기 센트로이드에 따라 매우 다른 군집이 생성될 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-06.png" width="750"/></div><p><strong>K-평균 모델 평가 기준: 관성</strong></p>
<p><strong>관성</strong><font size='2'>intertia</font>은 각 샘플과 가장 가까운 센트로이드와의 거리의 제곱의 합이며,
각 군집이 센트로이드에 얼마나 가까이 모여있는가를 측정한다.
따라서 관성이 작을 수록 군집이 잘 구성되었다고 평가한다.</p>
<p>훈련된 KMeans 모델의 경우 <code class="docutils literal notranslate"><span class="pre">inertia_</span></code> 속성에 관성 값이 저징되며,
<code class="docutils literal notranslate"><span class="pre">score()</span></code> 메서드가 관성의 음숫값을 반환한다.
이유는 점수(score)는 높을 수록 좋은 모델을 나타내도록 해야 하기 때문이다.
KMeans 모델은 훈련 과정 중에 다양한 초기화 과정을 실험하고 그 중에 가장
좋은 군집 모델을 선택한다.</p>
<p><strong>K-평균++ 초기화 알고리즘</strong></p>
<p>센트로이드를 무작위로 초기화하는 대신 특정 확률분포를 이용하여 선택하여
센트로이드들 사이의 거리를 가능한 크게 선택하는 알고리즘이며,
KMeans 모델의 기본 알고리즘으로 사용된다.</p>
<p><strong>미니배치 k-평균</strong></p>
<p>미니배치를 사용해서 센트로이드를 조금씩 이동하는 k-평균 알고리즘이다.
사이킷런의 <code class="docutils literal notranslate"><span class="pre">MiniBatchMeans</span></code> 모델이 지원한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">minibatch_kmeans</span> <span class="o">=</span> <span class="n">MiniBatchKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                   <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">minibatch_kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_memmap</span><span class="p">)</span>
</pre></div>
</div>
<p>군집수가 많아질 수록 k-평균보다 서너 배 정도 빠르게 훈련되지만, 성능은 조금 낮다.
하지만 아래 왼쪽 그림에서 보면 군집수 k 가 커져도 성능 차이가 유지되지만
성능 자체가 좋아지므로 두 모델의 상대적 성능 차이는 점점 벌어짐을 의미한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-07.png" width="700"/></div></div>
<div class="section" id="id4">
<h3><span class="section-number">9.2.2. </span>최적의 군집수 찾기<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>군집수가 적절하지 않으면 좋지 않은 모델로 수렴할 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-08.png" width="700"/></div><p><strong>방법 1: 관성과 군집수</strong></p>
<p>군집수 k가 증가할 수록 관성은 기본적으로 줄어들기에 관성만으로 모델을 평가할 수는 없다.
예를 들어 관성이 더 이상 획기적으로 줄어들지 않는 지점을 선택할 수는 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-09.png" width="600"/></div><p>하지만 아래 그림에서 보듯이 반드시 좋은 모델을 보장하지는 않는다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-10.png" width="400"/></div><p><strong>방법 2: 실루엣 점수와 군집수</strong></p>
<p><strong>실루엣 점수</strong><font size='2'>silhouette score</font> 샘플별 실루엣 계수의 평균값이다.
샘플의 <strong>실루엣 계수</strong><font size='2'>silhouette coefficient</font>는
다음 식으로 계산된다.</p>
<div class="math notranslate nohighlight">
\[\frac{b - a}{\max(a, b)}\]</div>
<p><span class="math notranslate nohighlight">\(a\)</span>는 동일 군집 내의 다른 샘플과의 거리의 평균값이며,
<span class="math notranslate nohighlight">\(b\)</span> 가장 가까운 타 군집에 속하는 샘플들과의 거리의 평균값이다.
실루엣 계수는 -1과 1사이의 값이며, 다음 특성을 보여준다.</p>
<ul class="simple">
<li><p>1에 가까운 값: 적절한 군집에 포함됨.</p></li>
<li><p>0에 가까운 값: 군집 경계에 위치</p></li>
<li><p>-1에 가까운 값: 잘못된 군집에 포함됨</p></li>
</ul>
<p>실루엣 점수가 높은 모델을 선택할 수 있다.
아래 그림에 따르면 <code class="docutils literal notranslate"><span class="pre">k=4</span></code>도 좋은 선택이 될 수 있다.
하지만 여기서는 <code class="docutils literal notranslate"><span class="pre">k=5</span></code> 가 가장 좋은 선택이다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-11.png" width="600"/></div><p><strong>방법 3: 실루엣 다이어그램과 군집수</strong></p>
<p><strong>실루엣 다이어그램</strong>은 군집별로 실루엣 계수들의 모아 놓은 그래프다.
군집별로 실루엣 계수를 내림차순으로 정렬하면 칼날 모양이 형성된다.</p>
<ul class="simple">
<li><p>칼날 두께: 군집에 포함된 샘플 수</p></li>
<li><p>칼날 길이: 군집에 포함된 각 샘플의 실루엣 계수</p></li>
<li><p>빨강 파선: 실루엣 점수, 즉 실루엣 계수의 평균값이다.</p></li>
</ul>
<p>좋은 군집 모델은 대부분의 칼날이 빨간 파선보다 길어야 하며,
칼날의 두께가 서로 비슷해야 한다.
즉, 군집별 크기가 비슷해야 좋은 모델이다.
이런 기준으로 볼 때 <code class="docutils literal notranslate"><span class="pre">k=5</span></code> 가 가장 좋은 모델이다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-12.png" width="700"/></div></div>
<div class="section" id="id5">
<h3><span class="section-number">9.2.3. </span>K-평균의 한계<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>최적의 모델을 구하기 위해 여러 번 학습해야 함.</p></li>
<li><p>군집수를 미리 지정해야 함.</p></li>
<li><p>군집의 크기나 밀집도가 다르거나, 원형이 아닐 경우 잘 작동하지 않음.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-13.png" width="600"/></div></div>
<div class="section" id="id6">
<h3><span class="section-number">9.2.4. </span>군집화 활용<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p><strong>활용 예제 1: 이미지 색상 분할</strong></p>
<p><strong>색상 분할</strong>은 유사 색상으로 이루어진 군집으로 분할하는 것을 의미한다.
아래 그림은 무당벌레가 포함된 이미지를 대상으로 색상 수를 다르게 하면서
색상 분할을 시도한 결과를 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-14.png" width="600"/></div><p><strong>활용 예제 2: 차원축소</strong></p>
<p>샘플에 대해 각 센트로이드부터의 거리로 이루어진 어레이를 생성하면
<code class="docutils literal notranslate"><span class="pre">n</span></code> 차원의 데이터셋을 <code class="docutils literal notranslate"><span class="pre">k</span></code> 차원의 데이터셋으로 변환한다.</p>
<p>이렇게 새로운 특성을 생성하여 다른 목적의 모델 훈련에 활용한다.
예를 들어, <a class="reference internal" href="end2end_ml_project.html#ch-end2end"><span class="std std-ref">머신러닝 프로젝트 처음부터 끝까지</span></a> 에서 다룬 캘리포니아 주택 데이터셋의
위도, 경도 정보를 이용하여 가까운 구역으로 이루어진 군집을 생성하는 모델
<code class="docutils literal notranslate"><span class="pre">ClusterSimilarity</span></code> 에 KMeans 모델이 활용되었다.</p>
<p><strong>활용 예제 3: 준지도 학습</strong></p>
<p>레이블이 있는 데이터가 적고, 레이블이 없는 데이터가 많을 때 활용한다.</p>
<div class="proof example admonition" id="example-0">
<p class="admonition-title"><span class="caption-number">Example 9.1 </span> (미니 MNIST 데이터셋)</p>
<div class="example-content section" id="proof-content">
<p>미니 MNist 데이터셋은 1,797 개의 8x8 크기의 손글씨 이미지로 구성된다.</p>
</div>
</div><p>예를 들어, 미니 MNIST 데이터셋을 50개의 군집으로 나눈 후 각 군집에서
센트로이드에 가장 가까운 샘플 50개를 대표 이미지로 선정한다.
선정된 50개 샘플만을 이용하여 분류 모델을 훈련해도 84.9%의 정확도가 달성된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-15.png" width="600"/></div><p><strong>활용 예제 4: 레이블 전파</strong></p>
<p>대표 이미지의 레이블을 해당 군집의 모든 샘플로 전파한다.
하지만 동일한 군집에 속하지만
센트로이드에서 샘플에 동일한 레이블을 전파하면
전파된 레이블의 정확도가 매우 낮을 수 있다.</p>
<p>따라서 센트로이드에 가장 멀리 떨어진 1%의 데이터를 이상치로 취급하여
제외시킨 다음에 레이블 전파를 진행하면
보다 좋은 성능이 분류 모델을 얻게 된다.</p>
<p><code class="docutils literal notranslate"><span class="pre">sklearn.semi_supervised</span></code> 패키지는 다양한 레이블 전파 모델을 제공한다.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LabelSpreading</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LabelPropagation</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SelfTrainingClassifier</span></code></p></li>
</ul>
</div>
</div>
<div class="section" id="dbscan">
<h2><span class="section-number">9.3. </span>DBSCAN<a class="headerlink" href="#dbscan" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>연속적인 밀집 지역을 하나의 군집으로 설정.</p></li>
</ul>
<p><strong>사이킷런의 DBSCAN 모델</strong></p>
<ul class="simple">
<li><p>두 개의 하이퍼파라미터 사용</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">eps</span></code>: <span class="math notranslate nohighlight">\(\varepsilon\)</span>-이웃 범위</p>
<ul>
<li><p>주어진 기준값 <span class="math notranslate nohighlight">\(\varepsilon\)</span> 반경 내에 위치한 샘플</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples</span></code>: <span class="math notranslate nohighlight">\(\varepsilon\)</span> 반경 내에 위치하는 이웃의 수</p></li>
</ul>
</li>
</ul>
<p><strong>핵심샘플과 군집</strong></p>
<ul class="simple">
<li><p>핵심샘플: <span class="math notranslate nohighlight">\(\varepsilon\)</span> 반경 내에 자신을 포함해서 <code class="docutils literal notranslate"><span class="pre">min-samples</span></code>개의 이웃을 갖는 샘플</p></li>
<li><p>군집: 핵심샘플로 이루어진 이웃들로 구성된 그룹</p></li>
</ul>
<p><strong>이상치</strong></p>
<ul class="simple">
<li><p>핵심샘플이 아니면서 동시에 핵심샘플의 이웃도 아닌 샘플.</p></li>
</ul>
<p><strong>예제:</strong> 반달모양 데이터 활용</p>
<hr class="docutils" />
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>

<span class="n">dbscan</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">dbscan</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-16.png" width="600"/></div><p><strong>DBSCAN과 예측</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">predict()</span></code> 메서드 지원하지 않음.</p></li>
<li><p>이유: <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> 등 보다 좋은 성능의 분류 알고리즘 활용 가능.</p></li>
<li><p>아래 코드: 핵심샘플 대상 훈련.</p></li>
</ul>
<hr class="docutils" />
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dbscan</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">dbscan</span><span class="o">.</span><span class="n">labels_</span><span class="p">[</span><span class="n">dbscan</span><span class="o">.</span><span class="n">core_sample_indices_</span><span class="p">])</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p>이후 새로운 샘플에 대한 예측 가능</p></li>
<li><p>아래 그림은 새로운 4개의 샘플에 대한 예측을 보여줌.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-17.png" width="450"/></div><p><strong>이상치 판단</strong></p>
<ul class="simple">
<li><p>위 예제에서, 두 군집으로부터 일정거리 이상 떨어진 샘플을 이상치로 간주 가능.</p></li>
<li><p>예를 들어, 양편 끝쪽에 위치한 두 개의 샘플이 이상치로 간주될 수 있음.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-17a.png" width="450"/></div><p><strong>DBSCAN의 장단점</strong></p>
<ul class="simple">
<li><p>매우 간단하면서 매우 강력한 알고리즘.</p>
<ul>
<li><p>하이퍼파라미터: 단 2개</p></li>
</ul>
</li>
<li><p>군집의 모양과 개수에 상관없음.</p></li>
<li><p>이상치에 안정적임.</p></li>
<li><p>군깁 간의 밀집도가 크게 다르면 모든 군집 파악 불가능.</p></li>
</ul>
<p><strong>계산복잡도</strong></p>
<ul class="simple">
<li><p>시간복잡도: 약 <span class="math notranslate nohighlight">\(O(m\, \log m)\)</span>. 단, <span class="math notranslate nohighlight">\(m\)</span>은 샘플 수</p></li>
<li><p>공간복잡도: 사이킷런의 DBSCAN 모델은 <span class="math notranslate nohighlight">\(O(m^2)\)</span>의 메모리 요구.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">eps</span></code>가 커질 경우.</p></li>
</ul>
</li>
</ul>
<p><strong>기타 군집 알고리즘</strong></p>
<ul class="simple">
<li><p>응집 군집(병합 군집, agglomerative clustering)</p></li>
<li><p>BIRCH</p></li>
<li><p>평균-이동</p></li>
<li><p>유사도 전파</p></li>
<li><p>스펙트럼 군집</p></li>
</ul>
</div>
<div class="section" id="id7">
<h2><span class="section-number">9.4. </span>가우시안 혼합 모델<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>데이터셋이 여러 개의 혼합된 가우시안 분포를 따르는 샘플들로 구성되었다고 가정.</p></li>
<li><p>가우시안 분포 = 정규분포</p></li>
</ul>
<p><strong>정규분포 소개</strong></p>
<ul class="simple">
<li><p>종 모양의 확률밀도함수를 갖는 확률분포</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-18.png" width="400"/></div><p><strong>군집</strong></p>
<ul class="simple">
<li><p>하나의 가우시안 분포에서 생생된 모든 샘플들의 그룹</p></li>
<li><p>일반적으로 타원형 모양.</p></li>
</ul>
<p><strong>예제</strong></p>
<ul class="simple">
<li><p>아래 그림에서처럼 일반적으로 모양, 크기, 밀집도, 방향이 다름.</p></li>
<li><p>따라서 각 샘플이 어떤 정규분포를 따르는지를 파악하는 게 핵심.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-13.png" width="600"/></div><p><strong>GMM 활용</strong></p>
<ul class="simple">
<li><p>위 데이터셋에 <code class="docutils literal notranslate"><span class="pre">GaussianMixture</span></code> 모델 적용</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_components</span></code>: 군집수 지정</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_init</span></code>: 모델 학습 반복 횟수.</p>
<ul>
<li><p>파라미터(평균값, 공분산 등)를 무작위로 추정한 후 수렴할 때까지 학습시킴.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>

<span class="n">gm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">gm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p>아래 그림은 학습된 모델을 보여줌.</p>
<ul>
<li><p>군집 평균, 결정 경계, 밀도 등고선</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-19.png" width="500"/></div><p><strong>GMM 모델 규제</strong></p>
<ul class="simple">
<li><p>특성수가 크거나, 군집수가 많거나, 샘플이 적은 경우 최적 모델 학습 어려움.</p></li>
<li><p>공분산(covariance)에 규제를 가해서 학습을 도와줄 수 있음.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">covariance_type</span></code> 설정.</p></li>
</ul>
</li>
</ul>
<p><strong>covariance_type 옵션값</strong></p>
<ul class="simple">
<li><p>full</p>
<ul>
<li><p>아무런 제한 없음.</p></li>
<li><p>기본값임.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>spherical</p>
<ul>
<li><p>군집이 원형이라 가정.</p></li>
<li><p>지름(분산)은 다를 수 있음.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>diag</p>
<ul>
<li><p>어떤 타원형도 가능.</p></li>
<li><p>단. 타원의 축이 좌표축과 평행하다고 가정.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>tied</p>
<ul>
<li><p>모든 군집의 동일 모양, 동일 크기, 동일 방향을 갖는다고 가정.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-20.png" width="600"/></div><div class="section" id="id8">
<h3><span class="section-number">9.4.1. </span>가우시안 혼합 모델 활용: 이상치 탐지<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>밀도가 임곗값보다 낮은 지역에 있는 샘플을 이상치로 간주 가능.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-21.png" width="500"/></div></div>
<div class="section" id="id9">
<h3><span class="section-number">9.4.2. </span>가우션 혼합모델 군집수 지정<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>k-평균에서 사용했던 관성 또는 실루엣 점수 사용 불가.</p>
<ul>
<li><p>군집이 타원형일 때 값이 일정하지 않기 때문.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>대신에 <strong>이론적 정보 기준</strong> 을 최소화 하는 모델 선택 가능.</p></li>
</ul>
<p><strong>이론적 정보 기준</strong></p>
<ul>
<li><p>BIC: Bayesian information criterion</p>
<div class="math notranslate nohighlight">
\[ \log(m)\, p - 2 \log (\hat L)\]</div>
</li>
</ul>
<ul>
<li><p>AIC: Akaike information criterion</p>
<div class="math notranslate nohighlight">
\[ 2\, p - 2 \log (\hat L)\]</div>
</li>
</ul>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(m\)</span>: 샘플 수</p></li>
<li><p><span class="math notranslate nohighlight">\(p\)</span>: 모델이 학습해야 할 파라미터 수</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat L\)</span>: 모델의 가능도 함수의 최댓값</p></li>
</ul>
<ul class="simple">
<li><p>학습해야 할 파라미터가 많을 수록 벌칙이 가해짐.</p></li>
<li><p>데이터에 잘 학습하는 모델일 수록 보상을 더해줌.</p></li>
</ul>
<p><strong>군집수와 정보조건</strong></p>
<ul class="simple">
<li><p>아래 그림은 군집수 <span class="math notranslate nohighlight">\(k\)</span>와 AIC, BIC의 관계를 보여줌.</p></li>
<li><p><span class="math notranslate nohighlight">\(k=3\)</span>이 최적으로 보임.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-22.png" width="600"/></div></div>
<div class="section" id="id10">
<h3><span class="section-number">9.4.3. </span>베이즈 가우시안 혼합 모델<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>베이즈 확률통계론 활용</p></li>
</ul>
<p><strong>BayesianGaussianMixture 모델</strong></p>
<ul class="simple">
<li><p>최적의 군집수를 자동으로 찾아줌.</p></li>
<li><p>단, 최적의 군집수보다 큰 수를 <code class="docutils literal notranslate"><span class="pre">n_components</span></code>에 전달해야 함.</p>
<ul>
<li><p>즉, 군집에 대한 최소한의 정보를 알고 있다고 가정.</p></li>
</ul>
</li>
<li><p>자동으로 불필요한 군집 제거</p></li>
</ul>
<hr class="docutils" />
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">BayesianGaussianMixture</span>

<span class="n">bgm</span> <span class="o">=</span> <span class="n">BayesianGaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">bgm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p>결과는 군집수 3개를 사용한 이전 결과와 거의 동일.</p></li>
<li><p>군집수 확인 가능</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">bgm</span><span class="o">.</span><span class="n">weights_</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">array([0.4 , 0.21, 0.4 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ])</span>
</pre></div>
</div>
<p><strong>사전 믿음</strong></p>
<ul class="simple">
<li><p>군집수가 어느 정도일까를 나타내는 지수</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_concentration_prior</span></code> 하이퍼파라미터</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">n_components</span></code>에 설정된 군집수에 대한 규제로 사용됨.</p></li>
<li><p>작은 값이면 특정 군집의 가중치를 0에 가깝게 만들어 군집수를 줄이도록 함.</p></li>
<li><p>즉, 큰 값일 수록 <code class="docutils literal notranslate"><span class="pre">n_components</span></code>에 설정된 군집수가 유지되도록 함.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-24.png" width="600"/></div><p><strong>가우시안 혼합 모델의 장단점</strong></p>
<ul class="simple">
<li><p>타원형 군집에 잘 작동.</p></li>
<li><p>하지만 다른 모양을 가진 데이터셋에서는 성능 좋지 않음.</p></li>
<li><p>예제: 달모양 데이터에 적용하는 경우</p>
<ul>
<li><p>억지로 타원을 찾으려 시도함.</p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch09/homl09-23.png" width="700"/></div></div>
<div class="section" id="id11">
<h3><span class="section-number">9.4.4. </span>이상치 탐지와 특이치 탐지를 위한 다른 알고리즘<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>PCA</p></li>
<li><p>Fast-MCD</p></li>
<li><p>아이솔레이션 포레스트</p></li>
<li><p>LOF</p></li>
<li><p>one-class SVM</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="dimensionality_reduction.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">8. </span>차원축소</p>
        </div>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 코딩알지<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>