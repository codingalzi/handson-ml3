
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5. 서포트 벡터 머신 &#8212; 핸즈온 머신러닝(3판)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. 결정트리" href="decision_trees.html" />
    <link rel="prev" title="4. 모델 훈련" href="training_models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">핸즈온 머신러닝(3판)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ml_landscape.html">
   1. 한눈에 보는 머신러닝
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="end2end_ml_project.html">
   2. 머신러닝 프로젝트 처음부터 끝까지
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classification.html">
   3. 분류
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="training_models.html">
   4. 모델 훈련
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5. 서포트 벡터 머신
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="decision_trees.html">
   6. 결정트리
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_learning_random_forests.html">
   7. 앙상블 학습과 랜덤 포레스트
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dimensionality_reduction.html">
   8. 차원 축소
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="unsupervised_learning.html">
   9. 비지도 학습
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/svm.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/codingalzi/handson-ml3"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/codingalzi/handson-ml3/issues/new?title=Issue%20on%20page%20%2Fsvm.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/codingalzi/handson-ml3/master?urlpath=tree/jupyter-book/svm.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm">
   5.1. 선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     5.1.1. 하드 마진 분류
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     5.1.2. 소프트 마진 분류
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   5.2. 비선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     5.2.1. 다항 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     5.2.2. 유사도 특성
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rbf">
     5.2.3. 가우시안 RBF 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     5.2.4. 계산 복잡도
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   5.3. SVM 회귀
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     5.3.1. 선형 SVM 회귀
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     5.3.2. 비선형 SVM 회귀
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   5.4. SVM 이론
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     5.4.1. SVM 분류기의 결정 함수, 예측, 결정 경계, 목적함수
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     5.4.2. 커널 SVM 작동 원리
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     5.4.3. 온라인 SVM
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>서포트 벡터 머신</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm">
   5.1. 선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     5.1.1. 하드 마진 분류
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     5.1.2. 소프트 마진 분류
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   5.2. 비선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     5.2.1. 다항 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     5.2.2. 유사도 특성
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rbf">
     5.2.3. 가우시안 RBF 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     5.2.4. 계산 복잡도
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   5.3. SVM 회귀
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     5.3.1. 선형 SVM 회귀
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     5.3.2. 비선형 SVM 회귀
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   5.4. SVM 이론
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     5.4.1. SVM 분류기의 결정 함수, 예측, 결정 경계, 목적함수
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     5.4.2. 커널 SVM 작동 원리
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     5.4.3. 온라인 SVM
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="ch-svm">
<span id="id1"></span><h1><span class="section-number">5. </span>서포트 벡터 머신<a class="headerlink" href="#ch-svm" title="Permalink to this headline">¶</a></h1>
<p><strong>감사의 글</strong></p>
<p>자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>본문 내용의 일부를 파이썬으로 구현한 내용은
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/notebooks/code_svm.ipynb">(구글코랩) 서포트 벡터 머신</a>에서
확인할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>선형 SVM 분류</p></li>
<li><p>비선형 SVM 분류</p></li>
<li><p>SVM 회귀</p></li>
<li><p>SVM 이론</p></li>
</ul>
<p><strong>목표</strong></p>
<p>수 백에서 수 천개의 데이터로 구성된 작은 훈련 데이터셋을 대상으로 선형과 비선형 분류 모델을
매우 잘 훈련시키는 서포트 벡터 머신의 주요 개념, 사용법, 작동법을 알아본다.</p>
<div class="section" id="svm">
<h2><span class="section-number">5.1. </span>선형 SVM 분류<a class="headerlink" href="#svm" title="Permalink to this headline">¶</a></h2>
<p>선형 <strong>서포트 벡터 머신</strong><font size="2">support vector machine</font>(SVM)은
두 클래스 사이를 최대한으로 경계 도로를 최대한 넓게 잡으려고 시도한다.
이때 두 클래스 사이에 놓을 수 있는 결정 경계 도로의 폭의 <strong>마진</strong><font size='2'>margin</font>이라 하며,
마진을 최대로 하는 분류가 <strong>큰 마진 분류</strong><font size='2'>large maring classication</font>이다.</p>
<p>아래 그림은 붓꽃 데이터셋을 대상으로 해서 선형 분류와 큰 마진 분류의 차이점을 보여준다.
선형 분류(왼쪽 그래프)의 경우 두 클래스를 분류하기만 해도 되는 반면에 큰 마진 분류(오른쪽 그래프)의
결정 경계(검은 실선)는 두 클래스와 거리를 최대한 크게 두려는 방향으로 정해진다.
즉, 마진은 가능한 최대로 유지하려 한다.
큰 마진 분류의 결정 경계는 결정 경계 도로의 가장자리에 위치한
<strong>서포트 벡터</strong><font size='2'>support vector</font>에만 의존하며 다른 데이터와는 전혀 상관 없다.
아래 오른쪽 그래프에서 서포트 벡터는 동그라미로 감싸져 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-01.png" width="700"/></div>
<div class="info admonition">
<p class="admonition-title">스케일링과 마진</p>
<p>특성의 스케일을 조정하면 결정 경계가 훨씬 좋아진다.
두 특성의 스케일에 차이가 많이 나는 경우(아래 왼쪽 그래프) 보다
표준화된 특성을 사용할 때(아래 오른쪽 그래프) 훨씬 좋은 결정 경계가 찾아진다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-02.png" width="700"/></div>
</div>
<div class="section" id="id2">
<h3><span class="section-number">5.1.1. </span>하드 마진 분류<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>모든 훈련 샘플이 도로 바깥쪽에 올바르게 분류되도록 하는 마진 분류가
<strong>하드 마진 분류</strong><font size='2'>hard margin classification</font>이다.
하지만 두 클래스가 선형적으로 구분되는 경우에만 적용 가능하다.</p>
<p>또한 이상치에 매우 민감하다.
하나의 이상치가 추가되면 선형 분류가 불가능하거나(아래 왼편 그래프)
일반화가 매우 어려운 분류 모델(아래 오른편 그래프)이 얻어질 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-03.png" width="700"/></div></div>
<div class="section" id="id3">
<h3><span class="section-number">5.1.2. </span>소프트 마진 분류<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p><strong>소프트 마진 분류</strong><font size='2'>soft margin classification</font>는 어느 정도의 마진 오류를 허용하면서
결정 경계 도로의 폭을 최대로 하는 방향으로 유도한다.
<strong>마진 오류</strong><font size='2'>margin violations</font>는 결정 경계 도로 상에 또는 결정 경계를 넘어 해당 클래스 반대편에 위치하는 샘플을 의미한다.</p>
<p>예를 들어 꽃잎 길이와 너비 기준으로 붓꽃의 버지니카와 버시컬러 품종을 하드 마진 분류하기는 불가능하며,
아래 그래프에서처럼 어느 정도의 마진 오류를 허용해야 한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-03b.png" width="400"/></div><p><strong><code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 클래스</strong></p>
<p>사이킷런의 <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 클래스는 선형 SVM 분류기를 생성한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">C</span></code> 는 규제 강조를 지정하는 하이퍼파라미터이며 클 수록 적은 규제를 의미한다.
<code class="docutils literal notranslate"><span class="pre">C</span></code> 가 너무 작으면(아래 왼편 그래프) 마진 오류를 너무 많이 허용하는 과소 적합이
발생하며, <code class="docutils literal notranslate"><span class="pre">C</span></code> 를 키우면(아래 오른편 그래프) 결정 경계 도로 폭이 좁아진다.
여기서는 <code class="docutils literal notranslate"><span class="pre">C=100</span></code> 이 일반화 성능이 좋은 모델을 유도하는 것으로 보인다.
또한 <code class="docutils literal notranslate"><span class="pre">C=float(&quot;inf&quot;)</span></code>로 지정하면 하드 마진 분류 모델이 된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-04.png" width="800"/></div><div class="info admonition">
<p class="admonition-title">선형 SVM 지원 모델</p>
<p><code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 모델은 대용량 훈련 데이터셋을 이용해서도 빠르게 학습한다.
이외에 <code class="docutils literal notranslate"><span class="pre">SVC</span></code> 모델과 <code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code> 모델도 선형 SVM 분류 모델로 활용될 수 있다.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">SVC</span></code> 클래스 활용</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code> 클래스 활용</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;hinge&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">m</span><span class="o">*</span><span class="n">C</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ul>
<p>hinge 손실 함수는 어긋난 예측 정도에 비례하여 손실값이 선형적으로 커진다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-06c.png" width="400"/></div>
</div>
</div>
</div>
<div class="section" id="id4">
<h2><span class="section-number">5.2. </span>비선형 SVM 분류<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>선형적으로 구분되지 못하는 데이터셋을 대상으로 분류 모델을 훈련시키는 두 가지 방식을 소개한다.</p>
<ul class="simple">
<li><p>방식 1: 특성 추가 + 선형 SVC</p>
<ul>
<li><p>다항 특성 활용: 다항 특성을 추가한 후 선형 SVC 적용</p></li>
<li><p>유사도 특성 활용: 유사도 특성을 추가한 후 선형 SVC 적용</p></li>
</ul>
</li>
<li><p>방식 2: <code class="docutils literal notranslate"><span class="pre">SVC</span></code> + 커널 트릭</p>
<ul>
<li><p>커널 트릭: 새로운 특성을 실제로 추가하지 않으면서 동일한 결과를 유도하는 방식</p></li>
<li><p>예제 1: 다항 커널</p></li>
<li><p>예제 2: 가우시안 RBF(방사 기저 함수) 커널</p></li>
</ul>
</li>
</ul>
<p><strong>다항 특성 추가 + 선형 SVM</strong></p>
<p><a class="reference internal" href="training_models.html#sec-poly-reg"><span class="std std-numref">4.3절</span></a>에서 설명한 다항 회귀 기법에서 다항 특성을 추가한 후에
선형 회귀를 적용한 방식과 동일하다.
아래 그래프는 특성 <span class="math notranslate nohighlight">\(x_1\)</span> 하나만 갖는 데이터셋에 특성 <span class="math notranslate nohighlight">\(x_1^2\)</span>을 추가한 후 선형 회귀 모델을
적용한 결과를 보여준다.</p>
<div class="math notranslate nohighlight">
\[\hat y = \theta_0 + \theta_1\, x_1 + \theta_2\, x_1^{2}\]</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-07.png" width="500"/></div><p>동일한 아이디어를 특성 <span class="math notranslate nohighlight">\(x_1\)</span> 하나만 갖는 데이터셋(아래 왼편 그래프)에 적용하면
비선형 SVM 모델(아래 오른편 그래프)을 얻게 된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-05.png" width="700"/></div><div class="info admonition">
<p class="admonition-title">2차 다항 특성 추가 후 선형 SVM 분류 모델 훈련</p>
<p>아래 동영상은 두 개의 특성을 갖는 데이터셋에 2차 다항 특성을 추가한 후에 선형 SVM 분류 모델을
적용하는 과정을 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/svm-poly-kernel.gif" width="600"/></div>
<p>&lt;동영상 출처: <a class="reference external" href="https://www.youtube.com/watch?v=OdlNM96sHio">SVM with polynomial kernel visualization</a>&gt;</p>
<p>참고로 3차원 상에서의 선형 방정식의 그래프는 평면으로 그려진다.</p>
<div class="math notranslate nohighlight">
\[z = \frac{3}{5} x + \frac{1}{5}y + 5 \quad\Longleftrightarrow\quad 3x + y - 5z + 25 = 0\]</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-06d.png" width="500"/></div>
<p>&lt;그림 출처: <a class="reference external" href="https://www.geogebra.org/3d">지오지브라(GeoGebra)</a>&gt;</p>
</div>
<div class="proof example admonition" id="exp:moons_dataset">
<p class="admonition-title"><span class="caption-number">Example 5.1 </span> (moons 데이터셋)</p>
<div class="example-content section" id="proof-content">
<p>moons 데이터셋은 마주보는 두 개의 반원 모양의 클래스로 구분되는 데이터셋을 가리킨다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-06.png" width="500"/></div>
<p>위 데이터셋에 선형 SVM 분류 모데를 적용하기 위해 먼저 3차 항에 해당하는 특성을 추가하면
비선형 분류 모델을 얻게 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3차 항까지 추가</span>
<span class="n">polynomial_svm_clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-07.png" width="500"/></div>
</div>
</div><div class="section" id="id5">
<h3><span class="section-number">5.2.1. </span>다항 커널<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>다항 특성을 추가하는 기법은 그만큼 비용을 지불해야 한다.
특히 축가해야 하는 특성이 많다면 시간과 메모리 사용 비용이 엄청날 수 있다.
반면에 <strong>커널 트릭</strong><font size='2'>kernel trick</font>을 사용하면
다항 특성을 실제로는 추가하지 않지만 추가한 경우와 동일한 결과를 만들어 낼 수 있다.
다만 이것은 SVM을 적용하는 경우에만 해당한다.
이와 달리 다항 특성을 추가하는 기법은 어떤 모델과도 함께 사용될 수 있다.</p>
<p>아래 두 그래프는 커널 기법을 사용하는 SVC 모델을 moons 데이터셋에 대해 훈련시킨 결과를 보여준다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">poly_kernel_svm_clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                                    <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;poly&quot;</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
<p>위 코드는 3차 다항 커널을 적용한 모델이며 아래 왼편 그래프와 같은 분류 모델을 학습한다.
반면에 아래 오른편 그래프는 10차 다항 커널을 적용한 모델이다.
<code class="docutils literal notranslate"><span class="pre">coef0</span></code> 하이퍼파라미터는 고차항의 중요도를 지정하며, 아래 그래프에서는 <span class="math notranslate nohighlight">\(r\)</span> 이 동일한
하이퍼파라미터를 가리킨다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-09.png" width="800"/></div><div class="tip admonition">
<p class="admonition-title">하이퍼파라미터 이해의 중요성</p>
<p>다항 커널 모델이 과대 적합이면 차수를 줄여야 하고, 과소 적합이면 차수를 늘려야 한다.
적절한 하이퍼파라미터는 그리드 탐색 등을 이용하여 찾으면 되지만,
그럼에도 불구하고 하이퍼파라미터의 의미를 잘 알고 있으면 탐색 구간을 줄일 수 있다.</p>
</div>
</div>
<div class="section" id="id6">
<h3><span class="section-number">5.2.2. </span>유사도 특성<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p><strong>유사도 함수</strong></p>
<ul>
<li><p>유사도 함수: <strong>랜드마크</strong>(landmark)라는 특정 샘플과 각 샘플 사이의 유사도(similarity)를 측정하는 함수</p></li>
<li><p>유사도 함수 예제: <strong>가우시안 방사 기저 함수</strong>(RBF, radial basis function)</p>
<div class="math notranslate nohighlight">
\[
    \phi(\mathbf x, \ell) = \exp(-\gamma\, \lVert \mathbf x - \ell \lVert^2)
    \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\ell\)</span>: 랜드마크</p></li>
<li><p><span class="math notranslate nohighlight">\(\gamma\)</span>: 랜드마크에서 멀어질 수록 0에 수렴하는 속도를 조절함</p></li>
<li><p><span class="math notranslate nohighlight">\(\gamma\)</span> 값이 클수록 가까운 샘플 선호, 즉 샘플들 사이의 영향을 보다 적게 고려하여
모델의 자유도를 높이게 되어 과대적합 위험 커짐.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>예제</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\exp(-5\, \lVert \mathbf x - 1 \lVert^2) \qquad\qquad\qquad \exp(-100\, \lVert \mathbf x - 1 \lVert^2)
\]</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-08b.png" width="1200"/></div>
<p>&lt;그림 출처: <a class="reference external" href="https://www.desmos.com/calculator?lang=ko">데스모스(desmos)</a>&gt;</p>
<p><strong>유사도 특성 추가 + 선형 SVC</strong></p>
<ul class="simple">
<li><p>모든 샘플을 랜드마크로 지정 후 각 랜드마크에 대한 유사도를 새로운 특성으로 추가하는 방식이 가장 간단함.</p></li>
<li><p>(<span class="math notranslate nohighlight">\(n\)</span> 개의 특성을 가진 <span class="math notranslate nohighlight">\(m\)</span> 개의 샘플) <span class="math notranslate nohighlight">\(\Rightarrow\)</span> (<span class="math notranslate nohighlight">\(n + m\)</span> 개의 특성을 가진 <span class="math notranslate nohighlight">\(m\)</span> 개의 샘플)</p></li>
<li><p>장점: 차원이 커지면서 선형적으로 구분될 가능성이 높아짐.</p></li>
<li><p>단점: 훈련 세트가 매우 클 경우 동일한 크기의 아주 많은 특성이 생성됨.</p></li>
<li><p>예제</p>
<ul>
<li><p>랜드마크: -2와 1</p></li>
<li><p><span class="math notranslate nohighlight">\(x_2\)</span>와 <span class="math notranslate nohighlight">\(x_3\)</span>: 각각 -2와 1에 대한 가우시안 RBF 함수로 계산한 유사도 특성</p></li>
<li><p>화살표가 가리키는 점: <span class="math notranslate nohighlight">\(\mathbf x = -1\)</span></p></li>
</ul>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-08.png" width="800"/></div></div>
<div class="section" id="rbf">
<h3><span class="section-number">5.2.3. </span>가우시안 RBF 커널<a class="headerlink" href="#rbf" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>SVM 모델을 훈련시킬 때 유사도 특성을 실제로는 추가 하지 않으면서 수학적으로는 추가한 효과를 내는 성질 이용</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rbf_kernel_svm_clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
        <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="s2">&quot;svm_clf&quot;</span><span class="p">,</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span> <span class="p">])</span>
</pre></div>
</div>
<p><strong>SVC + RBF 커널 예제: moons 데이터셋</strong></p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-10.png" width="600"/></div>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p>상단 그래프</p></th>
<th class="text-align:left head"><p>하단 그래프</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>gamma</p></td>
<td class="text-align:left"><p>랜드마크에 조금 집중</p></td>
<td class="text-align:left"><p>랜드마크에 많이 집중</p></td>
</tr>
</tbody>
</table>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:left head"><p>왼편 그래프                   </p></th>
<th class="text-align:left head"><p>오른편 그래프</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>C</p></td>
<td class="text-align:left"><p>규제 많이</p></td>
<td class="text-align:left"><p>규제 적게</p></td>
</tr>
</tbody>
</table>
<p><strong>추천 커널</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SVC</span></code>의 <code class="docutils literal notranslate"><span class="pre">kernel</span></code> 기본값은 <code class="docutils literal notranslate"><span class="pre">&quot;rbf&quot;</span></code> =&gt; 대부분의 경우 이 커널이 잘 맞음</p></li>
<li><p>선형 모델이 예상되는 경우 <code class="docutils literal notranslate"><span class="pre">SVC</span></code>의 <code class="docutils literal notranslate"><span class="pre">&quot;linear&quot;</span></code> 커널을 사용할 수 있음
하지만 훈련 세트가 크거나 특성이 아주 많을 경우 <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code>가 빠름</p></li>
<li><p>시간과 컴퓨팅 성능이 허락한다면 교차 검증, 그리드 탐색을 이용하여 적절한 커널을 찾아볼 수 있음</p></li>
<li><p>훈련 세트에 특화된 커널이 알려져 있다면 해당 커널을 사용</p></li>
</ul>
</div>
<div class="section" id="id7">
<h3><span class="section-number">5.2.4. </span>계산 복잡도<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>분류기</p></th>
<th class="head"><p>시간 복잡도(m 샘플 수, n 특성 수)</p></th>
<th class="head"><p>외부 메모리 학습</p></th>
<th class="head"><p>스케일 조정</p></th>
<th class="head"><p>커널 트릭</p></th>
<th class="head"><p>다중 클래스 분류</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>LinearSVC</p></td>
<td><p><span class="math notranslate nohighlight">\(O(m \times n)\)</span></p></td>
<td><p>미지원</p></td>
<td><p>필요</p></td>
<td><p>미지원</p></td>
<td><p>OvR 기본</p></td>
</tr>
<tr class="row-odd"><td><p>SGDClassifier</p></td>
<td><p><span class="math notranslate nohighlight">\(O(m \times n)\)</span></p></td>
<td><p>지원</p></td>
<td><p>필요</p></td>
<td><p>미지원</p></td>
<td><p>지원</p></td>
</tr>
<tr class="row-even"><td><p>SVC</p></td>
<td><p><span class="math notranslate nohighlight">\(O(m^2 \times n) \sim O(m^3 \times n)\)</span></p></td>
<td><p>미지원</p></td>
<td><p>필요</p></td>
<td><p>지원</p></td>
<td><p>OvR 기본</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="id8">
<h2><span class="section-number">5.3. </span>SVM 회귀<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p><strong>SVM 분류 vs. SVM 회귀</strong></p>
<ul class="simple">
<li><p>SVM 분류</p>
<ul>
<li><p>목표: 마진 오류 발생 정도를 조절(<code class="docutils literal notranslate"><span class="pre">C</span></code> 이용)하면서 두 클래스 사이의 도로폭을 최대한 넓게 하기</p></li>
<li><p>마진 오류: 도로 위에 위치한 샘플</p></li>
</ul>
</li>
<li><p>SVM 회귀</p>
<ul>
<li><p>목표: 마진 오류 발생 정도를 조절(<code class="docutils literal notranslate"><span class="pre">C</span></code> 이용)하면서 지정된 폭의 도로 안에 가능한 많은 샘플 포함하기</p></li>
<li><p>마진 오류: 도로 밖에 위치한 샘플</p></li>
<li><p>참고: <a class="reference external" href="https://kr.mathworks.com/help/stats/understanding-support-vector-machine-regression.html">MathWorks: SVM 회귀 이해하기</a></p></li>
</ul>
</li>
</ul>
<div class="section" id="id9">
<h3><span class="section-number">5.3.1. </span>선형 SVM 회귀<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>선형 회귀 모델을 SVM을 이용하여 구현</p></li>
</ul>
<ul>
<li><p>예제: LinearSVR 활용. <code class="docutils literal notranslate"><span class="pre">epsilon</span></code>은 도로폭 결정</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVR</span>
<span class="n">svm_reg</span> <span class="o">=</span> <span class="n">LinearSVR</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<ul class="simple">
<li><p>마진 안, 즉 결정 경계 도로 위에 포함되는 샘플를 추가해도 예측에 영향 주지 않음. 즉 <code class="docutils literal notranslate"><span class="pre">epsilon</span></code>에 둔감함.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-11.png" width="600"/></div></div>
<div class="section" id="id10">
<h3><span class="section-number">5.3.2. </span>비선형 SVM 회귀<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>SVC와 동일한 커널 트릭을 활용하여 비선형 회귀 모델 구현</p></li>
<li><p>예제: SVR + 다항 커널</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># SVR + 다항 커널</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>

<span class="n">svm_poly_reg</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;poly&quot;</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="s2">&quot;scale&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-12.png" width="800"/></div>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:right head"><p>왼편 그래프(C=100)</p></th>
<th class="text-align:right head"><p>오른편 그래프(C=0.01)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:right"><p>규제 보다 약함</p></td>
<td class="text-align:right"><p>규제 보다 강함</p></td>
</tr>
<tr class="row-odd"><td class="text-align:right"><p>샘플에 덜 민감</p></td>
<td class="text-align:right"><p>샘플에 더 민감</p></td>
</tr>
<tr class="row-even"><td class="text-align:right"><p>마진 오류 보다 적게</p></td>
<td class="text-align:right"><p>마진 오류 보다 많이</p></td>
</tr>
</tbody>
</table>
<p><strong>회귀 모델 시간 복잡도</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LinearSVR</span></code>: <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code>의 회귀 버전</p>
<ul>
<li><p>시간 복잡도가 훈련 세트의 크기에 비례해서 선형적으로 증가</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">SVR</span></code>: <code class="docutils literal notranslate"><span class="pre">SVC</span></code>의 회귀 버전</p>
<ul>
<li><p>훈련 세트가 커지면 매우 느려짐</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id11">
<h2><span class="section-number">5.4. </span>SVM 이론<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id12">
<h3><span class="section-number">5.4.1. </span>SVM 분류기의 결정 함수, 예측, 결정 경계, 목적함수<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p><strong>결정 함수와 예측</strong></p>
<ul class="simple">
<li><p>결정 함수: 아래 값을 이용하여 클래스 분류</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
h(\mathbf x) = \mathbf w^T \mathbf x + b = w_1 x_1 + \cdots + w_n x_n + b
\]</div>
<ul class="simple">
<li><p>예측값: 결정 함수의 값이 양수이면 양성, 음수이면 음성으로 분류</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat y = \begin{cases}
            0 &amp; \text{if } h(\mathbf x) &lt; 0\\
            1 &amp; \text{if } h(\mathbf x) \ge 0
         \end{cases}
\end{split}\]</div>
<p><strong>결정 경계</strong></p>
<ul class="simple">
<li><p>결정 경계: 결정 함수의 값이 0인 점들의 집합</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\{\mathbf x \mid h(\mathbf x)=0  \}\]</div>
<ul class="simple">
<li><p>결정 경계 도로의 경계: 결정 함수의 값이 1 또는 -1인 샘플들의 집합</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\{\mathbf{x} \mid h(\mathbf x)= \pm 1 \}\]</div>
<p><strong>예제</strong></p>
<p>붓꽃 분류. 꽃잎 길이와 너비를 기준으로 버지니카(Iris-Virginica, 초록 삼각형) 품종 여부 판단</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-13.png" width="600"/></div><p><strong>결정 함수의 기울기</strong></p>
<ul class="simple">
<li><p>결정 경계면(결정 함수의 그래프, 하이퍼플레인)의 기울기가 작아질 수록 도로 경계 폭이 커짐.</p></li>
<li><p>결정 경계면 기울기가 <span class="math notranslate nohighlight">\(\| \mathbf w \|\)</span>에 비례함.
따라서 결정 경계 도로의 폭을 크게 하기 위해 <span class="math notranslate nohighlight">\(\| \mathbf w \|\)</span>를 최소화해야 함.</p></li>
</ul>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-14.png" width="600"/></div>
<ul class="simple">
<li><p>하드 마진 모델 훈련: 모든 양성(음성) 샘플이 결정 경계 도로 밖에 위치하도록 하는 기울기 찾기.</p></li>
<li><p>소프트 마진 모델 훈련: 결정 경계 도로 위에 위치하는 샘플의 수를 제한하면서 결정 경계 도로의 폭이 최대가 되도록 하는 기울기 찾기.</p></li>
</ul>
<p><strong>목적함수</strong></p>
<ul class="simple">
<li><p>결정 경계면의 기울기 <span class="math notranslate nohighlight">\(\| \mathbf w \|\)</span>를 최소화하는 것과 아래 식을 최소화하는 것이 동일한 의미임.
따라서 아래 식을 목적함수로 지정함.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac 1 2 \| \mathbf w \|^2 = \frac 1 2 \mathbf w^T \mathbf w\]</div>
<ul class="simple">
<li><p>이유: 함수의 미분가능성 때문에 수학적으로 다루기가 보다 쉬움. <span class="math notranslate nohighlight">\(1/2\)</span> 또한 계산의 편의를 위해 추가됨.</p></li>
</ul>
<p><strong>하드 마진 선형 SVM 분류기의 목적 함수</strong></p>
<ul class="simple">
<li><p>목적함수를 최소화하는 파라미터 벡터 <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>를 구하기 위해 다음 __최적화 문제__를 해결해야 함.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac 1 2 \mathbf w^T \mathbf w\]</div>
<div class="math notranslate nohighlight">
\[
\text{(조건)}\quad t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) \ge 1
\]</div>
<ul class="simple">
<li><p>즉, 모든 샘플 <span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\)</span>에 대해 만족시켜야 하는 조건이 추가되었음.
<span class="math notranslate nohighlight">\(t^{(i)}\)</span>는 <span class="math notranslate nohighlight">\(i\)</span> 번째 샘플의 클래스(양성/음성)를 가리킴.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
t^{(i)} = 
\begin{cases}
-1 &amp; \text{$x^{(i)}$가 음성인 경우} \\
1 &amp; \text{$x^{(i)}$가 양성인 경우} 
\end{cases}
\end{split}\]</div>
<p><strong>조건식의 의미</strong></p>
<div class="math notranslate nohighlight">
\[
\text{(조건)}\quad t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) \ge 1
\]</div>
<p>위 조건식의 의미는 다음과 같다.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf x^{(i)}\)</span>가 양성인 경우</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(t^{(i)} = 1\)</span></p></li>
<li><p>따라서 <span class="math notranslate nohighlight">\(\mathbf w^T \mathbf x^{(i)} + b \ge 1\)</span>, 즉 양성으로 예측해야 함.</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf x^{(i)}\)</span>가 음성인 경우</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(t^{(i)} = -1\)</span></p></li>
<li><p>따라서 <span class="math notranslate nohighlight">\(\mathbf w^T \mathbf x^{(i)} + b \le -1\)</span>, 즉 음성으로 예측해야 함.</p></li>
</ul>
</li>
</ul>
<p><strong>소프트 마진 선형 SVM 분류기의 목적 함수</strong></p>
<ul class="simple">
<li><p>목적함수와 조건이 다음과 같음.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\frac 1 2 \mathbf w^T \mathbf w + C \sum_{i=0}^{m-1} \zeta^{(i)}\]</div>
<div class="math notranslate nohighlight">
\[\text{(조건)}\quad t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) \ge 1 - \zeta^{(i)}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\zeta^{(i)}\ge 0\)</span>: <strong>슬랙 변수</strong>. <span class="math notranslate nohighlight">\(i\)</span> 번째 샘플에 대한 마진 오류 허용 정도 지정.
(<span class="math notranslate nohighlight">\(\zeta\)</span>는 그리스어 알파벳이며 ‘체타(zeta)’라고 발음함.)</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span>: 아래 두 목표 사이의 트레이드오프를 조절하는 하이퍼파라미터</p>
<ul>
<li><p>목표 1: 결정 경계 도로의 폭을 가능하면 크게 하기 위해 <span class="math notranslate nohighlight">\(\|\mathbf w\|\)</span> 값을 가능하면 작게 만들기.</p></li>
<li><p>목표 2: 마진 오류 수를 제한하기, 즉 슬랙 변수의 값을 작게 유지하기.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p><strong>참고:</strong> 결정 경계 도로의 폭, 즉 마진 폭은 결정 경계면(<span class="math notranslate nohighlight">\(\hat y = \mathbf{w}^T \mathbf{x} + b\)</span>)의 기울기 <span class="math notranslate nohighlight">\(\|\mathbf w\|\)</span> 에 의해 결정됨</p></li>
</ul>
<p><strong><span class="math notranslate nohighlight">\(\zeta\)</span>의 역할</strong></p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\zeta^{(i)} &gt; 0\)</span>이면 해당 샘플 <span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\)</span>에 대해 다음이 성립하여 마진 오류가 될 수 있음.</p>
<div class="math notranslate nohighlight">
\[1 - \zeta^{(i)} \le t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) &lt; 1\]</div>
</li>
<li><p>이유: 결정 경계면(하이퍼플레인) 상에서 보면 결정 함숫값이 <span class="math notranslate nohighlight">\(1\)</span>보다 작은 샘플이기에
실제 데이터셋의 공간에서는 결정 경계 도로 안에 위치하게 됨.
(결정 경계 도로의 양 경계는 결정 함숫값이 <span class="math notranslate nohighlight">\(1\)</span>인 샘플들로 이루어졌음.)</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">C</span></code>와 마진 폭의 관계</strong></p>
<div class="math notranslate nohighlight">
\[\frac 1 2 \mathbf w^T \mathbf w + C \sum_{i=0}^{m-1} \zeta^{(i)}\]</div>
<div class="math notranslate nohighlight">
\[\text{(조건)}\quad t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) \ge 1 - \zeta^{(i)}\]</div>
<ul class="simple">
<li><p>가정: 보다 간단한 설명을 위해 편향 <span class="math notranslate nohighlight">\(b\)</span>는 <span class="math notranslate nohighlight">\(0\)</span>이거나 무시될 정도로 작다고 가정. (표준화 전처리를 사용하면 됨.)</p></li>
<li><p><span class="math notranslate nohighlight">\(C\)</span>가 매우 큰 경우</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\zeta\)</span>는 <span class="math notranslate nohighlight">\(0\)</span>에 매우 가까울 정도로 아주 작아짐.</p></li>
<li><p>예를 들어 양성 샘플 <span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\)</span>에 대해, 즉 <span class="math notranslate nohighlight">\(t^{(i)} = 1\)</span>,
<span class="math notranslate nohighlight">\(\mathbf{w}^T \mathbf{x}^{(i)}\)</span> 가 <span class="math notranslate nohighlight">\(1\)</span>보다 크거나 아니면 <span class="math notranslate nohighlight">\(1\)</span>보다 아주 조금만 작아야 함.
즉, 결정 경계면의 기울기 <span class="math notranslate nohighlight">\(\|w\|\)</span>가 어느 정도 커야 함.</p></li>
<li><p>결정 경계의 도로폭이 좁아짐.</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(C\)</span>가 매우 작은 경우</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\zeta\)</span>가 어느 정도 커도 됨.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{w}^T \mathbf{x}^{(i)}\)</span> 가 1보다 많이 작아도 됨. 즉, <span class="math notranslate nohighlight">\(\|w\|\)</span> 가 작아도 됨.</p></li>
<li><p>결정 경계의 도로폭이 넓어짐.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id13">
<h3><span class="section-number">5.4.2. </span>커널 SVM 작동 원리<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p><strong>쌍대 문제</strong></p>
<ul class="simple">
<li><p>쌍대 문제(dual problem): 주어진 문제의 답과 동일한 답을 갖는 문제</p></li>
<li><p>선형 SVM 목적 함수의 쌍대 문제: 아래 식을 최소화하는 <span class="math notranslate nohighlight">\(\alpha\)</span> 찾기(단, <span class="math notranslate nohighlight">\(\alpha^{(i)} &gt; 0\)</span>).</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha^{(i)}\alpha^{(j)} t^{(i)} t^{(j)} {\mathbf{x}^{(i)}}^T\mathbf{x}^{(j)} - \sum_{j=1}^{m} \alpha^{(i)}
\]</div>
<p><strong>쌍대 문제 활용 예제: 다항 커널</strong></p>
<ul class="simple">
<li><p>원래 <span class="math notranslate nohighlight">\(d\)</span>차 다항식 함수 <span class="math notranslate nohighlight">\(\phi()\)</span>를 적용한 후에 쌍대 목적 함수의 최적화 문제를 해결해야 함.
즉, 아래 문제를 최소화하는 <span class="math notranslate nohighlight">\(\alpha\)</span>를 찾는 게 쌍대문제임.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha^{(i)}\alpha^{(j)} t^{(i)} t^{(j)} \phi(\mathbf{x}^{(i)})^T \phi(\mathbf{x}^{(j)}) - \sum_{j=1}^{m} \alpha^{(i)}
\]</div>
<ul class="simple">
<li><p>하지만 다음이 성립함.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\phi(\mathbf a)^T \phi(\mathbf b) = ({\mathbf a}^T \mathbf b)^d
\]</div>
<ul class="simple">
<li><p>따라서 다항식 함수 <span class="math notranslate nohighlight">\(\phi\)</span>를 적용할 필요 없이, 즉 다항 특성을 전혀 추가할 필요 없이
아래 함수에 대한 최적화 문제를 해결하면 다항 특성을 추가한 효과를 얻게 됨.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{1}{2} \sum_{i=1}^{m} \sum_{j=1}^{m} \alpha^{(i)}\alpha^{(j)} t^{(i)} t^{(j)} \left({\mathbf{x}^{(i)}}^T\mathbf{x}^{(j)}\right)^d - \sum_{j=1}^{m} \alpha^{(i)}
\]</div>
<p><strong>예제: 지원되는 커널</strong></p>
<ul class="simple">
<li><p>다항식:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[K(\mathbf a, \mathbf b) = \big( \gamma \mathbf a^T  \mathbf b + r \big)^d\]</div>
<ul class="simple">
<li><p>가우시안 RBF:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[K(\mathbf a, \mathbf b) = \exp \big( \!-\! \gamma \| \mathbf a -  \mathbf b \|^2 \big )\]</div>
</div>
<div class="section" id="id14">
<h3><span class="section-number">5.4.3. </span>온라인 SVM<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>경사하강법을 이용하여 선형 SVM 분류기를 직접 구현할 수 있음.</p></li>
<li><p>비용함수는 아래와 같음.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\mathbf{w}, b) = \dfrac{1}{2} \mathbf{w}^T \mathbf{w} \,+\, C {\displaystyle \sum_{i=1}^{m}\max\left(0, 1 - t^{(i)}(\mathbf{w}^T \mathbf{x}^{(i)} + b) \right)}
\]</div>
<ul class="simple">
<li><p>자세한 내용은 주피터 노트북의 부록 B 참조: <a class="reference external" href="https://codingalzi.github.io/handson-ml2/notebooks/handson-ml2-05.html">[html]</a>, <a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml2/blob/master/notebooks/handson-ml2-05.ipynb">[구글 코랩]</a></p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="training_models.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4. </span>모델 훈련</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="decision_trees.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>결정트리</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 코딩알지<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>