
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>5. 서포트 벡터 머신 &#8212; 핸즈온 머신러닝(3판)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6. 결정트리" href="decision_trees.html" />
    <link rel="prev" title="4. 모델 훈련" href="training_models.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">핸즈온 머신러닝(3판)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ml_landscape.html">
   1. 한눈에 보는 머신러닝
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="end2end_ml_project.html">
   2. 머신러닝 프로젝트 처음부터 끝까지
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classification.html">
   3. 분류
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="training_models.html">
   4. 모델 훈련
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5. 서포트 벡터 머신
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="decision_trees.html">
   6. 결정트리
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ensemble_learning_random_forests.html">
   7. 앙상블 학습과 랜덤 포레스트
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dimensionality_reduction.html">
   8. 차원 축소
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="unsupervised_learning.html">
   9. 비지도 학습
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/svm.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/codingalzi/handson-ml3"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/codingalzi/handson-ml3/issues/new?title=Issue%20on%20page%20%2Fsvm.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/codingalzi/handson-ml3/master?urlpath=tree/jupyter-book/svm.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm">
   5.1. 선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     5.1.1. 하드 마진 분류
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     5.1.2. 소프트 마진 분류
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   5.2. 비선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     5.2.1. 다항 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     5.2.2. 유사도 특성
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rbf">
     5.2.3. 가우시안 RBF 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     5.2.4. SVM 클래스의 계산 복잡도
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   5.3. SVM 회귀
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   5.4. SVM 이론
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>서포트 벡터 머신</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#svm">
   5.1. 선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     5.1.1. 하드 마진 분류
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     5.1.2. 소프트 마진 분류
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   5.2. 비선형 SVM 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     5.2.1. 다항 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     5.2.2. 유사도 특성
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rbf">
     5.2.3. 가우시안 RBF 커널
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     5.2.4. SVM 클래스의 계산 복잡도
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   5.3. SVM 회귀
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   5.4. SVM 이론
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="ch-svm">
<span id="id1"></span><h1><span class="section-number">5. </span>서포트 벡터 머신<a class="headerlink" href="#ch-svm" title="Permalink to this headline">¶</a></h1>
<p><strong>감사의 글</strong></p>
<p>자료를 공개한 저자 오렐리앙 제롱과 강의자료를 지원한 한빛아카데미에게 진심어린 감사를 전합니다.</p>
<p><strong>소스코드</strong></p>
<p>본문 내용의 일부를 파이썬으로 구현한 내용은
<a class="reference external" href="https://colab.research.google.com/github/codingalzi/handson-ml3/blob/master/notebooks/code_svm.ipynb">(구글코랩) 서포트 벡터 머신</a>에서
확인할 수 있다.</p>
<p><strong>주요 내용</strong></p>
<ul class="simple">
<li><p>선형 SVM 분류</p></li>
<li><p>비선형 SVM 분류</p></li>
<li><p>SVM 회귀</p></li>
<li><p>SVM 이론</p></li>
</ul>
<p><strong>목표</strong></p>
<p>서포트 벡터 머신의 주요 개념, 사용법, 작동법을 알아본다.</p>
<div class="section" id="svm">
<h2><span class="section-number">5.1. </span>선형 SVM 분류<a class="headerlink" href="#svm" title="Permalink to this headline">¶</a></h2>
<p>선형 <strong>서포트 벡터 머신</strong><font size="2">support vector machine</font>(SVM)은
두 클래스 사이를 최대한으로 경계 도로를 최대한 넓게 잡으려고 시도한다.
이때 두 클래스 사이에 놓을 수 있는 결정 경계 도로의 폭의 <strong>마진</strong><font size='2'>margin</font>이라 하며,
마진을 최대로 하는 분류가 <strong>큰 마진 분류</strong><font size='2'>large margin classication</font>이다.</p>
<p>아래 그림은 붓꽃 데이터셋을 대상으로 해서 선형 분류와 큰 마진 분류의 차이점을 보여준다.
선형 분류(왼쪽 그래프)의 경우 두 클래스를 분류하기만 해도 되는 반면에 큰 마진 분류(오른쪽 그래프)의
결정 경계(검은 실선)는 두 클래스와 거리를 최대한 크게 두려는 방향으로 정해진다.
즉, 마진은 가능한 최대로 유지하려 한다.
큰 마진 분류의 결정 경계는 결정 경계 도로의 가장자리에 위치한
<strong>서포트 벡터</strong><font size='2'>support vector</font>에만 의존하며 다른 데이터와는 전혀 상관 없다.
아래 오른쪽 그래프에서 서포트 벡터는 동그라미로 감싸져 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-01.png" width="700"/></div>
<div class="info admonition">
<p class="admonition-title">스케일링과 마진</p>
<p>특성의 스케일을 조정하면 결정 경계가 훨씬 좋아진다.
두 특성의 스케일에 차이가 많이 나는 경우(아래 왼쪽 그래프) 보다
표준화된 특성을 사용할 때(아래 오른쪽 그래프) 훨씬 좋은 결정 경계가 찾아진다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-02.png" width="700"/></div>
</div>
<div class="section" id="id2">
<h3><span class="section-number">5.1.1. </span>하드 마진 분류<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>모든 훈련 샘플이 도로 바깥쪽에 올바르게 분류되도록 하는 마진 분류가
<strong>하드 마진 분류</strong><font size='2'>hard margin classification</font>이다.
하지만 두 클래스가 선형적으로 구분되는 경우에만 적용 가능하다.</p>
<p>또한 이상치에 매우 민감하다.
하나의 이상치가 추가되면 선형 분류가 불가능하거나(아래 왼편 그래프)
일반화가 매우 어려운 분류 모델(아래 오른편 그래프)이 얻어질 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-03.png" width="700"/></div></div>
<div class="section" id="id3">
<h3><span class="section-number">5.1.2. </span>소프트 마진 분류<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p><strong>소프트 마진 분류</strong><font size='2'>soft margin classification</font>는 어느 정도의 마진 오류를 허용하면서
결정 경계 도로의 폭을 최대로 하는 방향으로 유도한다.
<strong>마진 오류</strong><font size='2'>margin violations</font>는 결정 경계 도로 상에 또는 결정 경계를 넘어 해당 클래스 반대편에 위치하는 샘플을 의미한다.</p>
<p>예를 들어 꽃잎 길이와 너비 기준으로 붓꽃의 버지니카와 버시컬러 품종을 하드 마진 분류하기는 불가능하며,
아래 그래프에서처럼 어느 정도의 마진 오류를 허용해야 한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-03b.png" width="400"/></div><p><strong><code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 클래스</strong></p>
<p>사이킷런의 <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 클래스는 선형 SVM 분류기를 생성한다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">C</span></code> 는 규제 강조를 지정하는 하이퍼파라미터이며 클 수록 적은 규제를 의미한다.
<code class="docutils literal notranslate"><span class="pre">C</span></code> 가 너무 작으면(아래 왼편 그래프) 마진 오류를 너무 많이 허용하는 과소 적합이
발생하며, <code class="docutils literal notranslate"><span class="pre">C</span></code> 를 키우면(아래 오른편 그래프) 결정 경계 도로 폭이 좁아진다.
여기서는 <code class="docutils literal notranslate"><span class="pre">C=100</span></code> 이 일반화 성능이 좋은 모델을 유도하는 것으로 보인다.
또한 <code class="docutils literal notranslate"><span class="pre">C=float(&quot;inf&quot;)</span></code>로 지정하면 하드 마진 분류 모델이 된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-04.png" width="800"/></div><div class="info admonition">
<p class="admonition-title">선형 SVM 지원 모델</p>
<p><code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 모델은 대용량 훈련 데이터셋을 이용해서도 빠르게 학습한다.
이외에 <code class="docutils literal notranslate"><span class="pre">SVC</span></code> 모델과 <code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code> 모델도 선형 SVM 분류 모델로 활용될 수 있다.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">SVC</span></code> 클래스 활용</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code> 클래스 활용</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;hinge&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">m</span><span class="o">*</span><span class="n">C</span><span class="p">))</span>
</pre></div>
</div>
</li>
</ul>
<p>hinge 손실 함수는 어긋난 예측 정도에 비례하여 손실값이 선형적으로 커진다.</p>
</div>
</div>
</div>
<div class="section" id="id4">
<h2><span class="section-number">5.2. </span>비선형 SVM 분류<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>선형적으로 구분되지 못하는 데이터셋을 대상으로 분류 모델을 훈련시키는 두 가지 방식을 소개한다.</p>
<ul class="simple">
<li><p>방식 1: 특성 추가 + 선형 SVC</p>
<ul>
<li><p>다항 특성 활용: 다항 특성을 추가한 후 선형 SVC 적용</p></li>
<li><p>유사도 특성 활용: 유사도 특성을 추가한 후 선형 SVC 적용</p></li>
</ul>
</li>
<li><p>방식 2: <code class="docutils literal notranslate"><span class="pre">SVC</span></code> + 커널 트릭</p>
<ul>
<li><p>커널 트릭: 새로운 특성을 실제로 추가하지 않으면서 동일한 결과를 유도하는 방식</p></li>
<li><p>예제 1: 다항 커널</p></li>
<li><p>예제 2: 가우시안 RBF(방사 기저 함수) 커널</p></li>
</ul>
</li>
</ul>
<p><strong>다항 특성 추가 + 선형 SVM</strong></p>
<p><a class="reference internal" href="training_models.html#sec-poly-reg"><span class="std std-numref">4.3절</span></a>에서 설명한 다항 회귀 기법에서 다항 특성을 추가한 후에
선형 회귀를 적용한 방식과 동일하다.
아래 그래프는 특성 <span class="math notranslate nohighlight">\(x_1\)</span> 하나만 갖는 데이터셋에 특성 <span class="math notranslate nohighlight">\(x_1^2\)</span>을 추가한 후 선형 회귀 모델을
적용한 결과를 보여준다.</p>
<div class="math notranslate nohighlight">
\[\hat y = \theta_0 + \theta_1\, x_1 + \theta_2\, x_1^{2}\]</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch04/homl04-07.png" width="500"/></div><p>동일한 아이디어를 특성 <span class="math notranslate nohighlight">\(x_1\)</span> 하나만 갖는 데이터셋(아래 왼편 그래프)에 적용하면
비선형 SVM 모델(아래 오른편 그래프)을 얻게 된다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-05.png" width="700"/></div><div class="info admonition">
<p class="admonition-title">2차 다항 특성 추가 후 선형 SVM 분류 모델 훈련</p>
<p>아래 사진은 두 개의 특성을 갖는 데이터셋에 2차 다항 특성을 추가한 후에 선형 SVM 분류 모델을
적용하는 과정을 보여준다.</p>
<table>
<tr>
<td><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/svm_01.png" alt=""/></td>
<td><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/svm_01a.png" alt=""/></td>
</tr>
<tr>
<td><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/svm_02.png" alt=""/></td>
<td><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/svm_03.png" alt=""/></td>
</tr>
</table>
<p>&lt;그림 출처: <a class="reference external" href="https://www.youtube.com/watch?v=OdlNM96sHio">SVM with polynomial kernel visualization(유튜브)</a>&gt;</p>
<p>참고로 3차원 상에서의 선형 방정식의 그래프는 평면으로 그려진다.
예를 들어, 방정식 <span class="math notranslate nohighlight">\(3x + y - 5z + 25 = 0\)</span> 의 그래프는 아래와 같다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-06d.png" width="300"/></div>
<p>&lt;그림 출처: <a class="reference external" href="https://www.geogebra.org/3d">지오지브라(GeoGebra)</a>&gt;</p>
</div>
<div class="proof example admonition" id="exp:moons_dataset">
<p class="admonition-title"><span class="caption-number">Example 5.1 </span> (초승달 데이터셋<font size='2'>moons dataset</font>)</p>
<div class="example-content section" id="proof-content">
<p>초승달 데이터셋은 마주보는 두 개의 초승달 모양의 클래스로 구분되는 데이터셋을 가리킨다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-06.png" width="500"/></div>
<p>위 데이터셋에 선형 SVM 분류 모데를 적용하기 위해 먼저 3차 항에 해당하는 특성을 추가하면
비선형 분류 모델을 얻게 된다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3차 항까지 추가</span>
<span class="n">polynomial_svm_clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">StandardScaler</span><span class="p">(),</span>
    <span class="n">LinearSVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-07.png" width="500"/></div>
</div>
</div><div class="section" id="id5">
<h3><span class="section-number">5.2.1. </span>다항 커널<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>다항 특성을 추가하는 기법은 그만큼 비용을 지불해야 한다.
특히 축가해야 하는 특성이 많다면 시간과 메모리 사용 비용이 엄청날 수 있다.
반면에 <strong>커널 트릭</strong><font size='2'>kernel trick</font>을 사용하면
다항 특성을 실제로는 추가하지 않지만 추가한 경우와 동일한 결과를 만들어 낼 수 있다.
다만 이것은 SVM을 적용하는 경우에만 해당한다.
이와 달리 다항 특성을 추가하는 기법은 어떤 모델과도 함께 사용될 수 있다.</p>
<p>아래 두 그래프는 커널 기법을 사용하는 SVC 모델을 초승달 데이터셋에 대해 훈련시킨 결과를 보여준다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">poly_kernel_svm_clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                                    <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;poly&quot;</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</div>
<p>위 코드는 3차 다항 커널을 적용한 모델이며 아래 왼편 그래프와 같은 분류 모델을 학습한다.
반면에 아래 오른편 그래프는 10차 다항 커널을 적용한 모델이다.
<code class="docutils literal notranslate"><span class="pre">coef0</span></code> 하이퍼파라미터는 고차항의 중요도를 지정하며, 아래 그래프에서는 <span class="math notranslate nohighlight">\(r\)</span> 이 동일한
하이퍼파라미터를 가리킨다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-09.png" width="800"/></div><div class="tip admonition">
<p class="admonition-title">하이퍼파라미터 이해의 중요성</p>
<p>다항 커널 모델이 과대 적합이면 차수를 줄여야 하고, 과소 적합이면 차수를 늘려야 한다.
적절한 하이퍼파라미터는 그리드 탐색 등을 이용하여 찾으면 되지만,
그럼에도 불구하고 하이퍼파라미터의 의미를 잘 알고 있으면 탐색 구간을 줄일 수 있다.</p>
</div>
</div>
<div class="section" id="id6">
<h3><span class="section-number">5.2.2. </span>유사도 특성<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p><strong>유사도 특성</strong><font size='2'>similarity feature</font>은
<strong>랜드마크</strong><font size='2'>landmark</font>로 지정된 특정 샘플과
각 샘플이 얼마나 유사한가를 나타내는 값이다.</p>
<p>예를 들어, <strong>가우시안 방사 기저 함수</strong><font size='2'>Gaussian radial basis function</font>(Gaussian RBF)는
다음과 같이 정의된다.</p>
<div class="math notranslate nohighlight">
\[
\phi(\mathbf x, m) = \exp(-\gamma\, \lVert \mathbf x - m \lVert^2)
\]</div>
<p>위 식에서 <span class="math notranslate nohighlight">\(m\)</span>은 랜드마크를 나타낸다.
<span class="math notranslate nohighlight">\(\gamma\)</span>는 랜드마크에서 멀어질 수록 0에 수렴하는 속도를 조절하며,
<span class="math notranslate nohighlight">\(\gamma\)</span> 값이 클수록 가까운 샘플을 보다 선호하게 된다.</p>
<p>아래 두 그래프는 <span class="math notranslate nohighlight">\(\gamma\)</span> 에 따른 차이를 잘 보여준다.</p>
<div class="math notranslate nohighlight">
\[
\exp(-5\, \lVert \mathbf x - 1 \lVert^2) \qquad\qquad\qquad\qquad \exp(-100\, \lVert \mathbf x - 1 \lVert^2)
\]</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-08b.png" width="1200"/></div>
<p>&lt;그림 출처: <a class="reference external" href="https://www.desmos.com/calculator?lang=ko">데스모스(desmos)</a>&gt;</p>
<div class="proof example admonition" id="exp:sim_features_linearSVC">
<p class="admonition-title"><span class="caption-number">Example 5.2 </span> (유사도 특성 추가와 선형 SVC)</p>
<div class="example-content section" id="proof-content">
<p>아래 왼쪽 그래프는 -2와 1을 두 개의 랜드마크로 지정한 다음에
가우시안 RBF 함수로 계산한 유사도 특성값을 보여준다.
<span class="math notranslate nohighlight">\(x_2\)</span>와 <span class="math notranslate nohighlight">\(x_3\)</span>는 각각 -2와 1를 랜드마크로 사용한 유사도이며,
오른쪽 그래프는 이들을 이용하면 선형 분류가 가능해짐을 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-08.png" width="800"/></div>
</div>
</div></div>
<div class="section" id="rbf">
<h3><span class="section-number">5.2.3. </span>가우시안 RBF 커널<a class="headerlink" href="#rbf" title="Permalink to this headline">¶</a></h3>
<p>일반적으로 모든 훈련 샘플을 랜드마크로 지정한 후에
각 랜드마크에 대한 유사도를 새로운 특성으로 추가하는 방식이 사용된다.
그런데 그러면 훈련셋의 크기 만큼의 특성이 새로 추가된다.
따라서 훈련 세트가 매우 크다면 새로운 특성을 계산하는 데에 아주 많은 시간과 비용이 들게 된다.</p>
<p>다행히도 SVM 모델을 이용하면 유사도 특성을 실제로는 추가 하지 않으면서
추가한 효과를 내는 결과를 얻도록 훈련을 유도할 수 있다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rbf_kernel_svm_clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                                   <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;rbf&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>
</pre></div>
</div>
<p>아래 네 개의 그래프는 초승달 데이터셋에 가우시안 RBF 커널을 다양한 <code class="docutils literal notranslate"><span class="pre">gamma</span></code> 와 <code class="docutils literal notranslate"><span class="pre">C</span></code> 규제 옵션과
함께 적용한 결과를 보여준다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-10.png" width="600"/></div>
<p>위 그래프에 따르면 <code class="docutils literal notranslate"><span class="pre">gamma</span></code> 또한 나름 규제 역할을 수행함을 볼 수 있다.
<code class="docutils literal notranslate"><span class="pre">gamma</span></code> 값을 키우면 각 샘플의 영향력이 보다 작은 영역으로 제한되어 경계 구분선이 보다 좁고 복잡하게 움직인다.
반면에 <code class="docutils literal notranslate"><span class="pre">gamma</span></code> 값을 줄이면 각 샘플의 영향력이 보다 넓은 영역까지 전해지게 되어 경계 구분선이 보다 부드러워진다.</p>
<p><code class="docutils literal notranslate"><span class="pre">SVC</span></code> 클래스의 의 <code class="docutils literal notranslate"><span class="pre">kernel</span></code> 기본값은 <code class="docutils literal notranslate"><span class="pre">&quot;rbf&quot;</span></code>이며 대부분의 경우 이 커널이 잘 맞는다.
하지만 교차 검증, 그리드 탐색 등을 이용하여 적절한 커널을 찾아볼 수 있다.
특히 훈련 세트에 특화된 커널이 알려져 있다면 해당 커널을 먼저 사용해봐야 한다.</p>
</div>
<div class="section" id="id7">
<h3><span class="section-number">5.2.4. </span>SVM 클래스의 계산 복잡도<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code> 클래스는 확률적 경사하강법을 적용하기에 온라인 학습에 활용될 수 있다.
아래 표에서 ‘외부 메모리 학습’<font size='2'>out-of-core learning</font> 항목이
온라인 학습 지원 여부를 표시한다.
또한 <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 클래스와 거의 동일한 결과를 내도록 하이퍼파라미터를 조정할 수 있다.
하지만 <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 클래스는 배치학습과 다른 옵티마이저 알고리즘을 사용한다.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>클래스</p></th>
<th class="text-align:left head"><p>시간 복잡도(m 샘플 수, n 특성 수)</p></th>
<th class="text-align:left head"><p>외부 메모리 학습</p></th>
<th class="text-align:left head"><p>스케일 조정</p></th>
<th class="text-align:left head"><p>커널</p></th>
<th class="text-align:left head"><p>다중 클래스 분류</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>LinearSVC</p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(O(m \times n)\)</span></p></td>
<td class="text-align:left"><p>미지원</p></td>
<td class="text-align:left"><p>필요</p></td>
<td class="text-align:left"><p>미지원</p></td>
<td class="text-align:left"><p>OvR</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>SVC</p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(O(m^2 \times n) \sim O(m^3 \times n)\)</span></p></td>
<td class="text-align:left"><p>미지원</p></td>
<td class="text-align:left"><p>필요</p></td>
<td class="text-align:left"><p>지원</p></td>
<td class="text-align:left"><p>OvR</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>SGDClassifier</p></td>
<td class="text-align:left"><p><span class="math notranslate nohighlight">\(O(m \times n)\)</span></p></td>
<td class="text-align:left"><p>지원</p></td>
<td class="text-align:left"><p>필요</p></td>
<td class="text-align:left"><p>미지원</p></td>
<td class="text-align:left"><p>지원</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="id8">
<h2><span class="section-number">5.3. </span>SVM 회귀<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>SVM 아이디어를 조금 다르게 적용하면 회귀 모델이 생성된다.</p>
<ul class="simple">
<li><p>목표: 마진 오류 발생 정도를 조절(<code class="docutils literal notranslate"><span class="pre">C</span></code> 이용)하면서 지정된 폭의 도로 안에 가능한 많은 샘플 포함하기</p></li>
<li><p>마진 오류: 도로 밖에 위치한 샘플</p></li>
<li><p>결정 경계 도로의 폭: <code class="docutils literal notranslate"><span class="pre">epsilon</span></code> 하이퍼파라미터로 지정</p></li>
</ul>
<p>보다 자세한 설명은 <a class="reference external" href="https://kr.mathworks.com/help/stats/understanding-support-vector-machine-regression.html">SVM 회귀 이해하기</a>를 참고한다.</p>
<p>참고로 SVM 분류 모델의 특징은 다음과 같다.</p>
<ul class="simple">
<li><p>목표: 마진 오류 발생 정도를 조절(<code class="docutils literal notranslate"><span class="pre">C</span></code> 이용)하면서 두 클래스 사이의 도로폭을 최대한 넓게 하기</p></li>
<li><p>마진 오류: 도로 위 또는 자신의 클래스 반대편에 위치한 샘플</p></li>
</ul>
<p><strong>선형 SVM 회귀</strong></p>
<p>아래 그래프는 LinearSVR 클래스를 이용한 결과를 보여준다.
<code class="docutils literal notranslate"><span class="pre">epsilon</span></code>(<span class="math notranslate nohighlight">\(\varepsilon\)</span>)이 작을 수록(왼쪽 그래프) 도로폭이 좁아진다.
따라서 보다 많은 서포트 벡터가 지정된다.
반면에 결정 경계 도로 위에 포함되는 샘플를 추가해도 예측에 영향 주지 않는다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">svm_reg</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                        <span class="n">LinearSVR</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
</pre></div>
</div>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-11.png" width="600"/></div><p><strong>비선형 SVM 회귀</strong></p>
<p>SVC에 커널 트릭을 적용하는 아이디어를 동일하게 활용하여 비선형 회귀 모델을 구현한다.
아래 그래프는 SVR 클래스에 2차 다항 커널을 적용한 결과를 보여준다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># SVR + 다항 커널</span>
<span class="n">svm_poly_reg2</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                             <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;poly&quot;</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">C</span></code>와 <code class="docutils literal notranslate"><span class="pre">epsilon</span></code> 두 하이퍼파라미터의 의미는 SVC 모델의 경우와 동일하다.
즉, <code class="docutils literal notranslate"><span class="pre">C</span></code> 는 클 수록 적은 규제를 가하고 <code class="docutils literal notranslate"><span class="pre">epsilon</span></code>은 도로폭을 결정한다.
<code class="docutils literal notranslate"><span class="pre">C=100</span></code> 인 경우(오른쪽 그래프)가 <code class="docutils literal notranslate"><span class="pre">C=0.01</span></code> 인 경우(왼쪽 그래프) 보다 마진 오류가 적음을
볼 수 있다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-12.png" width="800"/></div><p><strong>회귀 모델 시간 복잡도</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">LinearSVR</span></code> 은 <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 의 회귀 버전이며 시간 복잡도 또한 비슷하다.
또한 훈련 세트의 크기에 비례해서 선형적으로 증가한다.
<code class="docutils literal notranslate"><span class="pre">SVR</span></code>은 <code class="docutils literal notranslate"><span class="pre">SVC</span></code>의 회귀 버전이며, 훈련 세트가 커지면 매우 느려지는 점 또한 동일하다.</p>
</div>
<div class="section" id="id9">
<h2><span class="section-number">5.4. </span>SVM 이론<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>선형 SVM 분류의 작동 원리를 설명한다.</p>
<p><strong>결정 함수와 예측</strong></p>
<p>아래 결정 함숫값을 이용하여 클래스를 지정한다.</p>
<div class="math notranslate nohighlight">
\[
h(\mathbf x) = \mathbf w^T \mathbf x + b = w_1 x_1 + \cdots + w_n x_n + b
\]</div>
<p>결정 함숫값이 양수이면 양성, 음수이면 음성으로 분류한다.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat y = \begin{cases}
            0 &amp; \text{if } h(\mathbf x) &lt; 0\\
            1 &amp; \text{if } h(\mathbf x) \ge 0
         \end{cases}
\end{split}\]</div>
<p><strong>결정 경계</strong></p>
<p>결정 경계는 결정 함수의 값이 0인 점들의 집합이다.</p>
<div class="math notranslate nohighlight">
\[\{\mathbf x \mid h(\mathbf x)=0  \}\]</div>
<p>결정 경계 도로의 가장자리는 결정 함수의 값이 1 또는 -1인 샘플들의 집합이다.</p>
<div class="math notranslate nohighlight">
\[\{\mathbf{x} \mid h(\mathbf x)= \pm 1 \}\]</div>
<div class="proof example admonition" id="exp:iris_svm">
<p class="admonition-title"><span class="caption-number">Example 5.3 </span> (붓꽃 분류)</p>
<div class="example-content section" id="proof-content">
<p>꽃잎 길이와 너비를 기준으로 버지니카(Iris-Virginica, 초록 삼각형) 품종 여부를 판단하는 이진 분류
모델의 결정 함수는 다음과 같다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-13.png" width="600"/></div>
</div>
</div><p><strong>결정 함수의 기울기</strong></p>
<p>결정 경계 하이퍼플레인(결정 함수의 그래프)의 기울기가 작을 수록 도로 경계 폭이 커진다.
그리고 결정 경계면 기울기는 <span class="math notranslate nohighlight">\(\| \mathbf w \|\)</span>(<span class="math notranslate nohighlight">\(\mathbf w\)</span>의 <span class="math notranslate nohighlight">\(l_2\)</span>-노름)에 비례한다.
따라서 결정 경계 도로의 폭을 크게 하기 위해 <span class="math notranslate nohighlight">\(\| \mathbf w \|\)</span>를 최소화해야 한다.</p>
<div align="center"><img src="https://raw.githubusercontent.com/codingalzi/handson-ml3/master/jupyter-book/imgs/ch05/homl05-14.png" width="600"/></div><p><strong>목적 함수</strong></p>
<p>결정 경계면의 기울기 <span class="math notranslate nohighlight">\(\| \mathbf w \|\)</span>를 최소화하는 것과 아래 식을 최소화하는 것이 동일한 결과를 낳는다.
따라서 아래 식을 <strong>목적 함수</strong>로 지정한다.</p>
<div class="math notranslate nohighlight">
\[\frac 1 2 \| \mathbf w \|^2 = \frac 1 2 \mathbf w^T \mathbf w\]</div>
<p>이유는 함수의 미분가능성 때문에 수학적으로 보다 다루기 쉽기 때문이다.</p>
<p><strong>하드 마진 선형 SVM 분류기의 목표</strong></p>
<p>아래 조건식을 만족시키면서</p>
<div class="math notranslate nohighlight">
\[t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) \ge 1\]</div>
<p>다음 수식을 최소화하는 <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, <span class="math notranslate nohighlight">\(b\)</span> 를 찾아야 한다.</p>
<div class="math notranslate nohighlight">
\[\frac 1 2 \mathbf w^T \mathbf w\]</div>
<p><strong>소프트 마진 선형 SVM 분류기의 목표</strong></p>
<p>아래 조건식 <span class="math notranslate nohighlight">\((*)\)</span> 을 만족시키면서</p>
<div class="math notranslate nohighlight">
\[t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) \ge 1 - \zeta^{(i)}\tag{$*$}\]</div>
<p>다음 수식 <span class="math notranslate nohighlight">\((\dagger)\)</span> 을 최소화하는 <span class="math notranslate nohighlight">\(\mathbf{w}\)</span>, <span class="math notranslate nohighlight">\(b\)</span>, <span class="math notranslate nohighlight">\(\zeta^{(i)}\)</span> 를 찾아야 한다.</p>
<div class="math notranslate nohighlight">
\[\frac 1 2 \mathbf w^T \mathbf w + C \sum_{i=0}^{m-1} \zeta^{(i)}\tag{$\dagger$}\]</div>
<p>위 식에서 <span class="math notranslate nohighlight">\(\zeta^{(i)}\ge 0\)</span>는 <strong>슬랙 변수</strong> 변수라 불리며 <span class="math notranslate nohighlight">\(i\)</span> 번째 샘플의
마진 오류 허용 정도를 나타낸다.
<span class="math notranslate nohighlight">\(\zeta\)</span>는 그리스어 알파벳이며 체타<font size='2'>zeta</font>라고 발음한다.</p>
<div class="warning admonition">
<p class="admonition-title">슬랙 변수</p>
<p>슬랙 변수가 샘플마다 다름에 주의하라. 만약에 샘플과 무관한 하나의 <span class="math notranslate nohighlight">\(\zeta\)</span> 를 사용하면
하드 마진 분류와 기본적으로 동일한 문제가 된다.</p>
</div>
<p><strong>조건식의 의미</strong></p>
<p>조건식 <span class="math notranslate nohighlight">\((*)\)</span> 의 의미는 다음과 같다.</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf x^{(i)}\)</span> 가 양성, 즉 <span class="math notranslate nohighlight">\(t^{(i)} = 1\)</span> 인 경우:
아래 식이 성립해야 한다.
즉, <span class="math notranslate nohighlight">\(1-\zeta^{(i)}\)</span> 만큼의 오류를 허용하면서 가능한한 양성으로 예측해야 한다.</p>
<div class="math notranslate nohighlight">
\[\mathbf w^T \mathbf x^{(i)} + b \ge 1 - \zeta^{(i)}\]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf x^{(i)}\)</span>가 음성, 즉 <span class="math notranslate nohighlight">\(t^{(i)} = -1\)</span> 인 경우:
아래 식이 성립해야 한다.
즉, <span class="math notranslate nohighlight">\(1-\zeta^{(i)}\)</span> 만큼의 오류를 허용하면서 가능한한 음성으로 예측해야 한다.</p>
<div class="math notranslate nohighlight">
\[\mathbf w^T \mathbf x^{(i)} + b \le -1 + \zeta^{(i)}\]</div>
</li>
</ul>
<p><strong><span class="math notranslate nohighlight">\(C\)</span> 와 마진 폭의 관계</strong></p>
<p><span class="math notranslate nohighlight">\(C\)</span> 가 커지면 수식 <span class="math notranslate nohighlight">\((\dagger)\)</span> 의 값을 줄이기 위해 <span class="math notranslate nohighlight">\(\zeta^{(i)}\)</span> 가 작아져야 하며,
따라서 <span class="math notranslate nohighlight">\(\mathbf w^T \mathbf w\)</span> 값에 여유가 생긴다.
이는 조건식 <span class="math notranslate nohighlight">\((*)\)</span> 를 만족시키기 위해 결정경계 하이퍼플레인의 기울기, 즉 <span class="math notranslate nohighlight">\(\|\mathbf{w}\|\)</span>의 값을 키울 여력이 생기게 됨을 의미한다.
결국 <span class="math notranslate nohighlight">\(\|\mathbf{w}\|\)</span> 가 좀 더 커지도록 훈련되며 이는 결정경계 하이퍼플레인의 기울기가 커지게되어
결정 경계 도로의 폭이 좁아지게 된다.</p>
<p>선형 분류가 가능하다면, 즉 하드 마진 분류가 가능하다면 <span class="math notranslate nohighlight">\(\zeta^{(i)}\)</span> 는 자연스럽게 0으로 또는 매우
작은 값으로 유도되어, 결국 <span class="math notranslate nohighlight">\(\|\mathbf w\|\)</span> 가 아래 조선식을 만족시키면서 최소값을 갖도록,
즉 결정 경계 하이퍼플레인의 기울기가 최대한 작아지도록 유도된다.</p>
<div class="math notranslate nohighlight">
\[t^{(i)} (\mathbf w^T \mathbf x^{(i)} + b) \ge 1\]</div>
<p>참고로 <span class="math notranslate nohighlight">\(C\)</span> 를 무한으로 두는 경우에도 동일하게 작동한다. 즉, 하드 마진 분류가 이루어진다.</p>
<div class="info admonition">
<p class="admonition-title">쌍대 문제</p>
<p>어떤 문제의 <strong>쌍대 문제</strong><font size='2'>dual problem</font>는 주어진 문제와 동일한 답을 갖는 문제이며,
주어진 원래의 문제를 <strong>원 문제</strong><font size='2'>primal problem</font>라 부른다</p>
<p>여기서는 앞서 선형 SVM 분류기의 목표로 설명된 문제가 원 문제이며,
이에 대응하는 쌍대 문제가 알려져 있지만, 여기서는 자세히 다루지 않으며
대신 핸즈온 머신러닝의 5장을 참고할 것을 추천한다.</p>
<p>여기서는 다만 SVC와 SVR 의 커널 기법이 바로 이 쌍대 문제에 적용된다는 점과
<code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> 과 <code class="docutils literal notranslate"><span class="pre">LinearSVR</span></code> 은 <code class="docutils literal notranslate"><span class="pre">dual</span></code> 하이퍼파라미터를 이용하여 쌍대 문제를 이용하여
모델을 훈련시킬지 여부를 지정할 수 있다는 정도만 언급한다.
<code class="docutils literal notranslate"><span class="pre">dual=True</span></code> 가 기본값이지만 훈련 샘플의 수가 특성 수보다 큰 경우
<code class="docutils literal notranslate"><span class="pre">dual=False</span></code> 로 지정하여 원 문제를 이용하는 것을 추천한다.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="training_models.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4. </span>모델 훈련</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="decision_trees.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">6. </span>결정트리</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 코딩알지<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>